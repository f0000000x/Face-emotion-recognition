/usr/lib/python2.7/dist-packages/skimage/transform/__init__.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from ._hough_transform import (hough_ellipse, hough_line,
/usr/lib/python2.7/dist-packages/skimage/draw/__init__.py:3: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from ._draw import (line, line_aa, polygon, ellipse_perimeter,
/usr/lib/python2.7/dist-packages/skimage/measure/_marching_cubes.py:2: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from . import _marching_cubes_cy
/usr/lib/python2.7/dist-packages/skimage/measure/_label.py:1: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from ._ccomp import label as _label
/usr/lib/python2.7/dist-packages/skimage/morphology/grey.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from . import cmorph
/usr/lib/python2.7/dist-packages/skimage/filter/rank/generic.py:23: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from . import generic_cy
/usr/lib/python2.7/dist-packages/skimage/filter/rank/_percentile.py:27: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from . import percentile_cy
/usr/lib/python2.7/dist-packages/skimage/filter/rank/bilateral.py:29: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from . import bilateral_cy
/usr/lib/python2.7/dist-packages/skimage/restoration/_denoise.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from skimage.restoration._denoise_cy import _denoise_bilateral, \
/usr/lib/python2.7/dist-packages/skimage/morphology/watershed.py:33: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from . import _watershed
/usr/lib/python2.7/dist-packages/skimage/morphology/_skeletonize.py:8: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from ._skeletonize_cy import _skeletonize_loop, _table_lookup_index
/usr/lib/python2.7/dist-packages/skimage/morphology/convex_hull.py:4: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from ._pnpoly import grid_points_inside_poly
/usr/lib/python2.7/dist-packages/skimage/morphology/convex_hull.py:5: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from ._convex_hull import possible_hull
/usr/lib/python2.7/dist-packages/skimage/transform/radon_transform.py:20: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from ._warps_cy import _warp_fast
/usr/lib/python2.7/dist-packages/skimage/transform/radon_transform.py:21: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility
  from ._radon_transform import sart_projection_update
WARNING: Logging before InitGoogleLogging() is written to STDERR
I0409 03:30:23.021385 13743 solver.cpp:45] Initializing solver from parameters: 
test_iter: 56
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 60000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 20000
snapshot: 10000
snapshot_prefix: "./FaceEmotionNet_model"
solver_mode: GPU
net: "FaceEmotionNet_model.prototxt"
type: "SGD"
I0409 03:30:23.021495 13743 solver.cpp:102] Creating training net from net file: FaceEmotionNet_model.prototxt
I0409 03:30:23.021667 13743 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: FaceEmotionNet_model.prototxt
I0409 03:30:23.021687 13743 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0409 03:30:23.021767 13743 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0409 03:30:23.021790 13743 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0409 03:30:23.021941 13743 net.cpp:51] Initializing net from parameters: 
name: "FaceEmotionNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 42
    mean_file: "../../Preprocessing/data/train_mean.binaryproto"
  }
  data_param {
    source: "../../Preprocessing/data/img_train_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "fc1"
  top: "fc1"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "fc2"
  top: "fc2"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc3"
  type: "InnerProduct"
  bottom: "fc2"
  top: "fc3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc3"
  bottom: "label"
  top: "Softmax_loss"
}
I0409 03:30:23.022020 13743 layer_factory.hpp:77] Creating layer data
I0409 03:30:23.022119 13743 db_lmdb.cpp:35] Opened lmdb ../../Preprocessing/data/img_train_lmdb
I0409 03:30:23.022141 13743 net.cpp:84] Creating Layer data
I0409 03:30:23.022148 13743 net.cpp:380] data -> data
I0409 03:30:23.022159 13743 net.cpp:380] data -> label
I0409 03:30:23.022186 13743 data_transformer.cpp:25] Loading mean file from: ../../Preprocessing/data/train_mean.binaryproto
I0409 03:30:23.023705 13743 data_layer.cpp:45] output data size: 64,1,42,42
I0409 03:30:23.026144 13743 net.cpp:122] Setting up data
I0409 03:30:23.026167 13743 net.cpp:129] Top shape: 64 1 42 42 (112896)
I0409 03:30:23.026175 13743 net.cpp:129] Top shape: 64 (64)
I0409 03:30:23.026176 13743 net.cpp:137] Memory required for data: 451840
I0409 03:30:23.026181 13743 layer_factory.hpp:77] Creating layer conv1
I0409 03:30:23.026229 13743 net.cpp:84] Creating Layer conv1
I0409 03:30:23.026247 13743 net.cpp:406] conv1 <- data
I0409 03:30:23.026257 13743 net.cpp:380] conv1 -> conv1
I0409 03:30:23.541817 13743 net.cpp:122] Setting up conv1
I0409 03:30:23.541872 13743 net.cpp:129] Top shape: 64 32 42 42 (3612672)
I0409 03:30:23.541878 13743 net.cpp:137] Memory required for data: 14902528
I0409 03:30:23.541901 13743 layer_factory.hpp:77] Creating layer conv1/bn
I0409 03:30:23.541926 13743 net.cpp:84] Creating Layer conv1/bn
I0409 03:30:23.541931 13743 net.cpp:406] conv1/bn <- conv1
I0409 03:30:23.541939 13743 net.cpp:367] conv1/bn -> conv1 (in-place)
I0409 03:30:23.542167 13743 net.cpp:122] Setting up conv1/bn
I0409 03:30:23.542196 13743 net.cpp:129] Top shape: 64 32 42 42 (3612672)
I0409 03:30:23.542199 13743 net.cpp:137] Memory required for data: 29353216
I0409 03:30:23.542209 13743 layer_factory.hpp:77] Creating layer relu1
I0409 03:30:23.542238 13743 net.cpp:84] Creating Layer relu1
I0409 03:30:23.542243 13743 net.cpp:406] relu1 <- conv1
I0409 03:30:23.542248 13743 net.cpp:367] relu1 -> conv1 (in-place)
I0409 03:30:23.542649 13743 net.cpp:122] Setting up relu1
I0409 03:30:23.542676 13743 net.cpp:129] Top shape: 64 32 42 42 (3612672)
I0409 03:30:23.542680 13743 net.cpp:137] Memory required for data: 43803904
I0409 03:30:23.542685 13743 layer_factory.hpp:77] Creating layer pool1
I0409 03:30:23.542693 13743 net.cpp:84] Creating Layer pool1
I0409 03:30:23.542697 13743 net.cpp:406] pool1 <- conv1
I0409 03:30:23.542703 13743 net.cpp:380] pool1 -> pool1
I0409 03:30:23.542750 13743 net.cpp:122] Setting up pool1
I0409 03:30:23.542768 13743 net.cpp:129] Top shape: 64 32 21 21 (903168)
I0409 03:30:23.542771 13743 net.cpp:137] Memory required for data: 47416576
I0409 03:30:23.542774 13743 layer_factory.hpp:77] Creating layer conv2
I0409 03:30:23.542786 13743 net.cpp:84] Creating Layer conv2
I0409 03:30:23.542790 13743 net.cpp:406] conv2 <- pool1
I0409 03:30:23.542796 13743 net.cpp:380] conv2 -> conv2
I0409 03:30:23.545315 13743 net.cpp:122] Setting up conv2
I0409 03:30:23.545347 13743 net.cpp:129] Top shape: 64 32 20 20 (819200)
I0409 03:30:23.545352 13743 net.cpp:137] Memory required for data: 50693376
I0409 03:30:23.545359 13743 layer_factory.hpp:77] Creating layer conv2/bn
I0409 03:30:23.545372 13743 net.cpp:84] Creating Layer conv2/bn
I0409 03:30:23.545377 13743 net.cpp:406] conv2/bn <- conv2
I0409 03:30:23.545384 13743 net.cpp:367] conv2/bn -> conv2 (in-place)
I0409 03:30:23.545593 13743 net.cpp:122] Setting up conv2/bn
I0409 03:30:23.545611 13743 net.cpp:129] Top shape: 64 32 20 20 (819200)
I0409 03:30:23.545615 13743 net.cpp:137] Memory required for data: 53970176
I0409 03:30:23.545624 13743 layer_factory.hpp:77] Creating layer relu2
I0409 03:30:23.545629 13743 net.cpp:84] Creating Layer relu2
I0409 03:30:23.545634 13743 net.cpp:406] relu2 <- conv2
I0409 03:30:23.545639 13743 net.cpp:367] relu2 -> conv2 (in-place)
I0409 03:30:23.545979 13743 net.cpp:122] Setting up relu2
I0409 03:30:23.546017 13743 net.cpp:129] Top shape: 64 32 20 20 (819200)
I0409 03:30:23.546021 13743 net.cpp:137] Memory required for data: 57246976
I0409 03:30:23.546025 13743 layer_factory.hpp:77] Creating layer pool2
I0409 03:30:23.546033 13743 net.cpp:84] Creating Layer pool2
I0409 03:30:23.546037 13743 net.cpp:406] pool2 <- conv2
I0409 03:30:23.546046 13743 net.cpp:380] pool2 -> pool2
I0409 03:30:23.546093 13743 net.cpp:122] Setting up pool2
I0409 03:30:23.546110 13743 net.cpp:129] Top shape: 64 32 10 10 (204800)
I0409 03:30:23.546114 13743 net.cpp:137] Memory required for data: 58066176
I0409 03:30:23.546118 13743 layer_factory.hpp:77] Creating layer conv3
I0409 03:30:23.546130 13743 net.cpp:84] Creating Layer conv3
I0409 03:30:23.546134 13743 net.cpp:406] conv3 <- pool2
I0409 03:30:23.546140 13743 net.cpp:380] conv3 -> conv3
I0409 03:30:23.548480 13743 net.cpp:122] Setting up conv3
I0409 03:30:23.548511 13743 net.cpp:129] Top shape: 64 64 10 10 (409600)
I0409 03:30:23.548516 13743 net.cpp:137] Memory required for data: 59704576
I0409 03:30:23.548523 13743 layer_factory.hpp:77] Creating layer conv3/bn
I0409 03:30:23.548530 13743 net.cpp:84] Creating Layer conv3/bn
I0409 03:30:23.548534 13743 net.cpp:406] conv3/bn <- conv3
I0409 03:30:23.548542 13743 net.cpp:367] conv3/bn -> conv3 (in-place)
I0409 03:30:23.548740 13743 net.cpp:122] Setting up conv3/bn
I0409 03:30:23.548758 13743 net.cpp:129] Top shape: 64 64 10 10 (409600)
I0409 03:30:23.548761 13743 net.cpp:137] Memory required for data: 61342976
I0409 03:30:23.548768 13743 layer_factory.hpp:77] Creating layer relu3
I0409 03:30:23.548774 13743 net.cpp:84] Creating Layer relu3
I0409 03:30:23.548777 13743 net.cpp:406] relu3 <- conv3
I0409 03:30:23.548782 13743 net.cpp:367] relu3 -> conv3 (in-place)
I0409 03:30:23.549275 13743 net.cpp:122] Setting up relu3
I0409 03:30:23.549302 13743 net.cpp:129] Top shape: 64 64 10 10 (409600)
I0409 03:30:23.549322 13743 net.cpp:137] Memory required for data: 62981376
I0409 03:30:23.549330 13743 layer_factory.hpp:77] Creating layer pool3
I0409 03:30:23.549357 13743 net.cpp:84] Creating Layer pool3
I0409 03:30:23.549361 13743 net.cpp:406] pool3 <- conv3
I0409 03:30:23.549367 13743 net.cpp:380] pool3 -> pool3
I0409 03:30:23.549419 13743 net.cpp:122] Setting up pool3
I0409 03:30:23.549451 13743 net.cpp:129] Top shape: 64 64 5 5 (102400)
I0409 03:30:23.549454 13743 net.cpp:137] Memory required for data: 63390976
I0409 03:30:23.549458 13743 layer_factory.hpp:77] Creating layer fc1
I0409 03:30:23.549468 13743 net.cpp:84] Creating Layer fc1
I0409 03:30:23.549471 13743 net.cpp:406] fc1 <- pool3
I0409 03:30:23.549476 13743 net.cpp:380] fc1 -> fc1
I0409 03:30:23.573372 13743 net.cpp:122] Setting up fc1
I0409 03:30:23.573420 13743 net.cpp:129] Top shape: 64 2048 (131072)
I0409 03:30:23.573424 13743 net.cpp:137] Memory required for data: 63915264
I0409 03:30:23.573438 13743 layer_factory.hpp:77] Creating layer drop1
I0409 03:30:23.573447 13743 net.cpp:84] Creating Layer drop1
I0409 03:30:23.573451 13743 net.cpp:406] drop1 <- fc1
I0409 03:30:23.573459 13743 net.cpp:367] drop1 -> fc1 (in-place)
I0409 03:30:23.573487 13743 net.cpp:122] Setting up drop1
I0409 03:30:23.573503 13743 net.cpp:129] Top shape: 64 2048 (131072)
I0409 03:30:23.573508 13743 net.cpp:137] Memory required for data: 64439552
I0409 03:30:23.573510 13743 layer_factory.hpp:77] Creating layer fc2
I0409 03:30:23.573518 13743 net.cpp:84] Creating Layer fc2
I0409 03:30:23.573521 13743 net.cpp:406] fc2 <- fc1
I0409 03:30:23.573530 13743 net.cpp:380] fc2 -> fc2
I0409 03:30:23.588790 13743 net.cpp:122] Setting up fc2
I0409 03:30:23.588815 13743 net.cpp:129] Top shape: 64 1024 (65536)
I0409 03:30:23.588819 13743 net.cpp:137] Memory required for data: 64701696
I0409 03:30:23.588842 13743 layer_factory.hpp:77] Creating layer drop2
I0409 03:30:23.588862 13743 net.cpp:84] Creating Layer drop2
I0409 03:30:23.588867 13743 net.cpp:406] drop2 <- fc2
I0409 03:30:23.588873 13743 net.cpp:367] drop2 -> fc2 (in-place)
I0409 03:30:23.588903 13743 net.cpp:122] Setting up drop2
I0409 03:30:23.588935 13743 net.cpp:129] Top shape: 64 1024 (65536)
I0409 03:30:23.588955 13743 net.cpp:137] Memory required for data: 64963840
I0409 03:30:23.588958 13743 layer_factory.hpp:77] Creating layer fc3
I0409 03:30:23.588968 13743 net.cpp:84] Creating Layer fc3
I0409 03:30:23.588971 13743 net.cpp:406] fc3 <- fc2
I0409 03:30:23.588976 13743 net.cpp:380] fc3 -> fc3
I0409 03:30:23.589114 13743 net.cpp:122] Setting up fc3
I0409 03:30:23.589146 13743 net.cpp:129] Top shape: 64 7 (448)
I0409 03:30:23.589150 13743 net.cpp:137] Memory required for data: 64965632
I0409 03:30:23.589156 13743 layer_factory.hpp:77] Creating layer Softmax_loss
I0409 03:30:23.589162 13743 net.cpp:84] Creating Layer Softmax_loss
I0409 03:30:23.589166 13743 net.cpp:406] Softmax_loss <- fc3
I0409 03:30:23.589170 13743 net.cpp:406] Softmax_loss <- label
I0409 03:30:23.589179 13743 net.cpp:380] Softmax_loss -> Softmax_loss
I0409 03:30:23.589187 13743 layer_factory.hpp:77] Creating layer Softmax_loss
I0409 03:30:23.589630 13743 net.cpp:122] Setting up Softmax_loss
I0409 03:30:23.589653 13743 net.cpp:129] Top shape: (1)
I0409 03:30:23.589658 13743 net.cpp:132]     with loss weight 1
I0409 03:30:23.589668 13743 net.cpp:137] Memory required for data: 64965636
I0409 03:30:23.589673 13743 net.cpp:198] Softmax_loss needs backward computation.
I0409 03:30:23.589676 13743 net.cpp:198] fc3 needs backward computation.
I0409 03:30:23.589679 13743 net.cpp:198] drop2 needs backward computation.
I0409 03:30:23.589682 13743 net.cpp:198] fc2 needs backward computation.
I0409 03:30:23.589685 13743 net.cpp:198] drop1 needs backward computation.
I0409 03:30:23.589689 13743 net.cpp:198] fc1 needs backward computation.
I0409 03:30:23.589692 13743 net.cpp:198] pool3 needs backward computation.
I0409 03:30:23.589696 13743 net.cpp:198] relu3 needs backward computation.
I0409 03:30:23.589699 13743 net.cpp:198] conv3/bn needs backward computation.
I0409 03:30:23.589702 13743 net.cpp:198] conv3 needs backward computation.
I0409 03:30:23.589705 13743 net.cpp:198] pool2 needs backward computation.
I0409 03:30:23.589709 13743 net.cpp:198] relu2 needs backward computation.
I0409 03:30:23.589712 13743 net.cpp:198] conv2/bn needs backward computation.
I0409 03:30:23.589717 13743 net.cpp:198] conv2 needs backward computation.
I0409 03:30:23.589720 13743 net.cpp:198] pool1 needs backward computation.
I0409 03:30:23.589723 13743 net.cpp:198] relu1 needs backward computation.
I0409 03:30:23.589726 13743 net.cpp:198] conv1/bn needs backward computation.
I0409 03:30:23.589730 13743 net.cpp:198] conv1 needs backward computation.
I0409 03:30:23.589733 13743 net.cpp:200] data does not need backward computation.
I0409 03:30:23.589736 13743 net.cpp:242] This network produces output Softmax_loss
I0409 03:30:23.589756 13743 net.cpp:255] Network initialization done.
I0409 03:30:23.590013 13743 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: FaceEmotionNet_model.prototxt
I0409 03:30:23.590030 13743 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0409 03:30:23.590036 13743 solver.cpp:190] Creating test net (#0) specified by net file: FaceEmotionNet_model.prototxt
I0409 03:30:23.590065 13743 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0409 03:30:23.590201 13743 net.cpp:51] Initializing net from parameters: 
name: "FaceEmotionNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 42
    mean_file: "../../Preprocessing/data/val_mean.binaryproto"
  }
  data_param {
    source: "../../Preprocessing/data/img_val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv1/bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 4
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv2/bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "conv3/bn"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "pool3"
  top: "fc1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2048
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "fc1"
  top: "fc1"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 1024
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "drop2"
  type: "Dropout"
  bottom: "fc2"
  top: "fc2"
  dropout_param {
    dropout_ratio: 0.4
  }
}
layer {
  name: "fc3"
  type: "InnerProduct"
  bottom: "fc2"
  top: "fc3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  inner_product_param {
    num_output: 7
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "Softmax_loss"
  type: "SoftmaxWithLoss"
  bottom: "fc3"
  bottom: "label"
  top: "Softmax_loss"
}
I0409 03:30:23.590306 13743 layer_factory.hpp:77] Creating layer data
I0409 03:30:23.590378 13743 db_lmdb.cpp:35] Opened lmdb ../../Preprocessing/data/img_val_lmdb
I0409 03:30:23.590395 13743 net.cpp:84] Creating Layer data
I0409 03:30:23.590404 13743 net.cpp:380] data -> data
I0409 03:30:23.590414 13743 net.cpp:380] data -> label
I0409 03:30:23.590422 13743 data_transformer.cpp:25] Loading mean file from: ../../Preprocessing/data/val_mean.binaryproto
I0409 03:30:23.590595 13743 data_layer.cpp:45] output data size: 64,1,42,42
I0409 03:30:23.593070 13743 net.cpp:122] Setting up data
I0409 03:30:23.593096 13743 net.cpp:129] Top shape: 64 1 42 42 (112896)
I0409 03:30:23.593117 13743 net.cpp:129] Top shape: 64 (64)
I0409 03:30:23.593120 13743 net.cpp:137] Memory required for data: 451840
I0409 03:30:23.593155 13743 layer_factory.hpp:77] Creating layer label_data_1_split
I0409 03:30:23.593166 13743 net.cpp:84] Creating Layer label_data_1_split
I0409 03:30:23.593170 13743 net.cpp:406] label_data_1_split <- label
I0409 03:30:23.593180 13743 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0409 03:30:23.593189 13743 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0409 03:30:23.593355 13743 net.cpp:122] Setting up label_data_1_split
I0409 03:30:23.593376 13743 net.cpp:129] Top shape: 64 (64)
I0409 03:30:23.593380 13743 net.cpp:129] Top shape: 64 (64)
I0409 03:30:23.593384 13743 net.cpp:137] Memory required for data: 452352
I0409 03:30:23.593387 13743 layer_factory.hpp:77] Creating layer conv1
I0409 03:30:23.593400 13743 net.cpp:84] Creating Layer conv1
I0409 03:30:23.593405 13743 net.cpp:406] conv1 <- data
I0409 03:30:23.593411 13743 net.cpp:380] conv1 -> conv1
I0409 03:30:23.595562 13743 net.cpp:122] Setting up conv1
I0409 03:30:23.595600 13743 net.cpp:129] Top shape: 64 32 42 42 (3612672)
I0409 03:30:23.595610 13743 net.cpp:137] Memory required for data: 14903040
I0409 03:30:23.595625 13743 layer_factory.hpp:77] Creating layer conv1/bn
I0409 03:30:23.595635 13743 net.cpp:84] Creating Layer conv1/bn
I0409 03:30:23.595649 13743 net.cpp:406] conv1/bn <- conv1
I0409 03:30:23.595656 13743 net.cpp:367] conv1/bn -> conv1 (in-place)
I0409 03:30:23.595902 13743 net.cpp:122] Setting up conv1/bn
I0409 03:30:23.595922 13743 net.cpp:129] Top shape: 64 32 42 42 (3612672)
I0409 03:30:23.595927 13743 net.cpp:137] Memory required for data: 29353728
I0409 03:30:23.595937 13743 layer_factory.hpp:77] Creating layer relu1
I0409 03:30:23.595943 13743 net.cpp:84] Creating Layer relu1
I0409 03:30:23.595947 13743 net.cpp:406] relu1 <- conv1
I0409 03:30:23.595952 13743 net.cpp:367] relu1 -> conv1 (in-place)
I0409 03:30:23.596588 13743 net.cpp:122] Setting up relu1
I0409 03:30:23.596613 13743 net.cpp:129] Top shape: 64 32 42 42 (3612672)
I0409 03:30:23.596617 13743 net.cpp:137] Memory required for data: 43804416
I0409 03:30:23.596621 13743 layer_factory.hpp:77] Creating layer pool1
I0409 03:30:23.596637 13743 net.cpp:84] Creating Layer pool1
I0409 03:30:23.596642 13743 net.cpp:406] pool1 <- conv1
I0409 03:30:23.596665 13743 net.cpp:380] pool1 -> pool1
I0409 03:30:23.596732 13743 net.cpp:122] Setting up pool1
I0409 03:30:23.596763 13743 net.cpp:129] Top shape: 64 32 21 21 (903168)
I0409 03:30:23.596766 13743 net.cpp:137] Memory required for data: 47417088
I0409 03:30:23.596771 13743 layer_factory.hpp:77] Creating layer conv2
I0409 03:30:23.596781 13743 net.cpp:84] Creating Layer conv2
I0409 03:30:23.596786 13743 net.cpp:406] conv2 <- pool1
I0409 03:30:23.596793 13743 net.cpp:380] conv2 -> conv2
I0409 03:30:23.598912 13743 net.cpp:122] Setting up conv2
I0409 03:30:23.598942 13743 net.cpp:129] Top shape: 64 32 20 20 (819200)
I0409 03:30:23.598950 13743 net.cpp:137] Memory required for data: 50693888
I0409 03:30:23.598958 13743 layer_factory.hpp:77] Creating layer conv2/bn
I0409 03:30:23.598966 13743 net.cpp:84] Creating Layer conv2/bn
I0409 03:30:23.598971 13743 net.cpp:406] conv2/bn <- conv2
I0409 03:30:23.598976 13743 net.cpp:367] conv2/bn -> conv2 (in-place)
I0409 03:30:23.599236 13743 net.cpp:122] Setting up conv2/bn
I0409 03:30:23.599254 13743 net.cpp:129] Top shape: 64 32 20 20 (819200)
I0409 03:30:23.599258 13743 net.cpp:137] Memory required for data: 53970688
I0409 03:30:23.599268 13743 layer_factory.hpp:77] Creating layer relu2
I0409 03:30:23.599277 13743 net.cpp:84] Creating Layer relu2
I0409 03:30:23.599282 13743 net.cpp:406] relu2 <- conv2
I0409 03:30:23.599287 13743 net.cpp:367] relu2 -> conv2 (in-place)
I0409 03:30:23.599755 13743 net.cpp:122] Setting up relu2
I0409 03:30:23.599779 13743 net.cpp:129] Top shape: 64 32 20 20 (819200)
I0409 03:30:23.599784 13743 net.cpp:137] Memory required for data: 57247488
I0409 03:30:23.599787 13743 layer_factory.hpp:77] Creating layer pool2
I0409 03:30:23.599797 13743 net.cpp:84] Creating Layer pool2
I0409 03:30:23.599800 13743 net.cpp:406] pool2 <- conv2
I0409 03:30:23.599805 13743 net.cpp:380] pool2 -> pool2
I0409 03:30:23.599865 13743 net.cpp:122] Setting up pool2
I0409 03:30:23.599882 13743 net.cpp:129] Top shape: 64 32 10 10 (204800)
I0409 03:30:23.599885 13743 net.cpp:137] Memory required for data: 58066688
I0409 03:30:23.599889 13743 layer_factory.hpp:77] Creating layer conv3
I0409 03:30:23.599915 13743 net.cpp:84] Creating Layer conv3
I0409 03:30:23.599920 13743 net.cpp:406] conv3 <- pool2
I0409 03:30:23.599926 13743 net.cpp:380] conv3 -> conv3
I0409 03:30:23.601835 13743 net.cpp:122] Setting up conv3
I0409 03:30:23.601874 13743 net.cpp:129] Top shape: 64 64 10 10 (409600)
I0409 03:30:23.601879 13743 net.cpp:137] Memory required for data: 59705088
I0409 03:30:23.601886 13743 layer_factory.hpp:77] Creating layer conv3/bn
I0409 03:30:23.601896 13743 net.cpp:84] Creating Layer conv3/bn
I0409 03:30:23.601899 13743 net.cpp:406] conv3/bn <- conv3
I0409 03:30:23.601905 13743 net.cpp:367] conv3/bn -> conv3 (in-place)
I0409 03:30:23.602105 13743 net.cpp:122] Setting up conv3/bn
I0409 03:30:23.602123 13743 net.cpp:129] Top shape: 64 64 10 10 (409600)
I0409 03:30:23.602128 13743 net.cpp:137] Memory required for data: 61343488
I0409 03:30:23.602133 13743 layer_factory.hpp:77] Creating layer relu3
I0409 03:30:23.602139 13743 net.cpp:84] Creating Layer relu3
I0409 03:30:23.602142 13743 net.cpp:406] relu3 <- conv3
I0409 03:30:23.602147 13743 net.cpp:367] relu3 -> conv3 (in-place)
I0409 03:30:23.602463 13743 net.cpp:122] Setting up relu3
I0409 03:30:23.602488 13743 net.cpp:129] Top shape: 64 64 10 10 (409600)
I0409 03:30:23.602491 13743 net.cpp:137] Memory required for data: 62981888
I0409 03:30:23.602495 13743 layer_factory.hpp:77] Creating layer pool3
I0409 03:30:23.602502 13743 net.cpp:84] Creating Layer pool3
I0409 03:30:23.602505 13743 net.cpp:406] pool3 <- conv3
I0409 03:30:23.602510 13743 net.cpp:380] pool3 -> pool3
I0409 03:30:23.602560 13743 net.cpp:122] Setting up pool3
I0409 03:30:23.602576 13743 net.cpp:129] Top shape: 64 64 5 5 (102400)
I0409 03:30:23.602581 13743 net.cpp:137] Memory required for data: 63391488
I0409 03:30:23.602583 13743 layer_factory.hpp:77] Creating layer fc1
I0409 03:30:23.602592 13743 net.cpp:84] Creating Layer fc1
I0409 03:30:23.602596 13743 net.cpp:406] fc1 <- pool3
I0409 03:30:23.602602 13743 net.cpp:380] fc1 -> fc1
I0409 03:30:23.626232 13743 net.cpp:122] Setting up fc1
I0409 03:30:23.626263 13743 net.cpp:129] Top shape: 64 2048 (131072)
I0409 03:30:23.626268 13743 net.cpp:137] Memory required for data: 63915776
I0409 03:30:23.626281 13743 layer_factory.hpp:77] Creating layer drop1
I0409 03:30:23.626291 13743 net.cpp:84] Creating Layer drop1
I0409 03:30:23.626294 13743 net.cpp:406] drop1 <- fc1
I0409 03:30:23.626303 13743 net.cpp:367] drop1 -> fc1 (in-place)
I0409 03:30:23.626332 13743 net.cpp:122] Setting up drop1
I0409 03:30:23.626339 13743 net.cpp:129] Top shape: 64 2048 (131072)
I0409 03:30:23.626343 13743 net.cpp:137] Memory required for data: 64440064
I0409 03:30:23.626345 13743 layer_factory.hpp:77] Creating layer fc2
I0409 03:30:23.626358 13743 net.cpp:84] Creating Layer fc2
I0409 03:30:23.626374 13743 net.cpp:406] fc2 <- fc1
I0409 03:30:23.626380 13743 net.cpp:380] fc2 -> fc2
I0409 03:30:23.641683 13743 net.cpp:122] Setting up fc2
I0409 03:30:23.641723 13743 net.cpp:129] Top shape: 64 1024 (65536)
I0409 03:30:23.641728 13743 net.cpp:137] Memory required for data: 64702208
I0409 03:30:23.641736 13743 layer_factory.hpp:77] Creating layer drop2
I0409 03:30:23.641746 13743 net.cpp:84] Creating Layer drop2
I0409 03:30:23.641750 13743 net.cpp:406] drop2 <- fc2
I0409 03:30:23.641757 13743 net.cpp:367] drop2 -> fc2 (in-place)
I0409 03:30:23.641789 13743 net.cpp:122] Setting up drop2
I0409 03:30:23.641795 13743 net.cpp:129] Top shape: 64 1024 (65536)
I0409 03:30:23.641798 13743 net.cpp:137] Memory required for data: 64964352
I0409 03:30:23.641800 13743 layer_factory.hpp:77] Creating layer fc3
I0409 03:30:23.641809 13743 net.cpp:84] Creating Layer fc3
I0409 03:30:23.641813 13743 net.cpp:406] fc3 <- fc2
I0409 03:30:23.641818 13743 net.cpp:380] fc3 -> fc3
I0409 03:30:23.641973 13743 net.cpp:122] Setting up fc3
I0409 03:30:23.641993 13743 net.cpp:129] Top shape: 64 7 (448)
I0409 03:30:23.641996 13743 net.cpp:137] Memory required for data: 64966144
I0409 03:30:23.642001 13743 layer_factory.hpp:77] Creating layer fc3_fc3_0_split
I0409 03:30:23.642009 13743 net.cpp:84] Creating Layer fc3_fc3_0_split
I0409 03:30:23.642011 13743 net.cpp:406] fc3_fc3_0_split <- fc3
I0409 03:30:23.642019 13743 net.cpp:380] fc3_fc3_0_split -> fc3_fc3_0_split_0
I0409 03:30:23.642026 13743 net.cpp:380] fc3_fc3_0_split -> fc3_fc3_0_split_1
I0409 03:30:23.642071 13743 net.cpp:122] Setting up fc3_fc3_0_split
I0409 03:30:23.642097 13743 net.cpp:129] Top shape: 64 7 (448)
I0409 03:30:23.642102 13743 net.cpp:129] Top shape: 64 7 (448)
I0409 03:30:23.642104 13743 net.cpp:137] Memory required for data: 64969728
I0409 03:30:23.642108 13743 layer_factory.hpp:77] Creating layer accuracy
I0409 03:30:23.642122 13743 net.cpp:84] Creating Layer accuracy
I0409 03:30:23.642125 13743 net.cpp:406] accuracy <- fc3_fc3_0_split_0
I0409 03:30:23.642130 13743 net.cpp:406] accuracy <- label_data_1_split_0
I0409 03:30:23.642144 13743 net.cpp:380] accuracy -> accuracy
I0409 03:30:23.642153 13743 net.cpp:122] Setting up accuracy
I0409 03:30:23.642158 13743 net.cpp:129] Top shape: (1)
I0409 03:30:23.642159 13743 net.cpp:137] Memory required for data: 64969732
I0409 03:30:23.642163 13743 layer_factory.hpp:77] Creating layer Softmax_loss
I0409 03:30:23.642168 13743 net.cpp:84] Creating Layer Softmax_loss
I0409 03:30:23.642171 13743 net.cpp:406] Softmax_loss <- fc3_fc3_0_split_1
I0409 03:30:23.642175 13743 net.cpp:406] Softmax_loss <- label_data_1_split_1
I0409 03:30:23.642179 13743 net.cpp:380] Softmax_loss -> Softmax_loss
I0409 03:30:23.642189 13743 layer_factory.hpp:77] Creating layer Softmax_loss
I0409 03:30:23.642838 13743 net.cpp:122] Setting up Softmax_loss
I0409 03:30:23.642894 13743 net.cpp:129] Top shape: (1)
I0409 03:30:23.642899 13743 net.cpp:132]     with loss weight 1
I0409 03:30:23.642908 13743 net.cpp:137] Memory required for data: 64969736
I0409 03:30:23.642912 13743 net.cpp:198] Softmax_loss needs backward computation.
I0409 03:30:23.642916 13743 net.cpp:200] accuracy does not need backward computation.
I0409 03:30:23.642920 13743 net.cpp:198] fc3_fc3_0_split needs backward computation.
I0409 03:30:23.642923 13743 net.cpp:198] fc3 needs backward computation.
I0409 03:30:23.642927 13743 net.cpp:198] drop2 needs backward computation.
I0409 03:30:23.642930 13743 net.cpp:198] fc2 needs backward computation.
I0409 03:30:23.642932 13743 net.cpp:198] drop1 needs backward computation.
I0409 03:30:23.642935 13743 net.cpp:198] fc1 needs backward computation.
I0409 03:30:23.642940 13743 net.cpp:198] pool3 needs backward computation.
I0409 03:30:23.642942 13743 net.cpp:198] relu3 needs backward computation.
I0409 03:30:23.642946 13743 net.cpp:198] conv3/bn needs backward computation.
I0409 03:30:23.642948 13743 net.cpp:198] conv3 needs backward computation.
I0409 03:30:23.642952 13743 net.cpp:198] pool2 needs backward computation.
I0409 03:30:23.642956 13743 net.cpp:198] relu2 needs backward computation.
I0409 03:30:23.642958 13743 net.cpp:198] conv2/bn needs backward computation.
I0409 03:30:23.642961 13743 net.cpp:198] conv2 needs backward computation.
I0409 03:30:23.642964 13743 net.cpp:198] pool1 needs backward computation.
I0409 03:30:23.642967 13743 net.cpp:198] relu1 needs backward computation.
I0409 03:30:23.642971 13743 net.cpp:198] conv1/bn needs backward computation.
I0409 03:30:23.642973 13743 net.cpp:198] conv1 needs backward computation.
I0409 03:30:23.642977 13743 net.cpp:200] label_data_1_split does not need backward computation.
I0409 03:30:23.642982 13743 net.cpp:200] data does not need backward computation.
I0409 03:30:23.642987 13743 net.cpp:242] This network produces output Softmax_loss
I0409 03:30:23.642990 13743 net.cpp:242] This network produces output accuracy
I0409 03:30:23.643007 13743 net.cpp:255] Network initialization done.
I0409 03:30:23.643087 13743 solver.cpp:57] Solver scaffolding done.
I0409 03:30:23.643883 13743 solver.cpp:289] Solving FaceEmotionNet
I0409 03:30:23.643901 13743 solver.cpp:290] Learning Rate Policy: step
I0409 03:30:23.644897 13743 solver.cpp:347] Iteration 0, Testing net (#0)
I0409 03:30:24.021281 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:30:24.039345 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 77.7841 (* 1 = 77.7841 loss)
I0409 03:30:24.039376 13743 solver.cpp:414]     Test net output #1: accuracy = 0.109375
I0409 03:30:24.075598 13743 solver.cpp:239] Iteration 0 (0 iter/s, 0.43165s/100 iters), loss = 2.92118
I0409 03:30:24.075644 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 2.92118 (* 1 = 2.92118 loss)
I0409 03:30:24.075654 13743 sgd_solver.cpp:112] Iteration 0, lr = 0.01
I0409 03:30:25.998733 13743 solver.cpp:239] Iteration 100 (52.0001 iter/s, 1.92307s/100 iters), loss = 2.21727
I0409 03:30:25.998806 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 2.21727 (* 1 = 2.21727 loss)
I0409 03:30:25.998822 13743 sgd_solver.cpp:112] Iteration 100, lr = 0.01
I0409 03:30:27.897222 13743 solver.cpp:239] Iteration 200 (52.6758 iter/s, 1.89841s/100 iters), loss = 1.74422
I0409 03:30:27.897286 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.74422 (* 1 = 1.74422 loss)
I0409 03:30:27.897295 13743 sgd_solver.cpp:112] Iteration 200, lr = 0.01
I0409 03:30:29.795928 13743 solver.cpp:239] Iteration 300 (52.6698 iter/s, 1.89862s/100 iters), loss = 2.25824
I0409 03:30:29.795989 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 2.25824 (* 1 = 2.25824 loss)
I0409 03:30:29.795997 13743 sgd_solver.cpp:112] Iteration 300, lr = 0.01
I0409 03:30:31.693914 13743 solver.cpp:239] Iteration 400 (52.6891 iter/s, 1.89793s/100 iters), loss = 1.8839
I0409 03:30:31.693975 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.8839 (* 1 = 1.8839 loss)
I0409 03:30:31.693984 13743 sgd_solver.cpp:112] Iteration 400, lr = 0.01
I0409 03:30:32.530952 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:30:33.589602 13743 solver.cpp:239] Iteration 500 (52.753 iter/s, 1.89563s/100 iters), loss = 1.99778
I0409 03:30:33.589679 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.99778 (* 1 = 1.99778 loss)
I0409 03:30:33.589687 13743 sgd_solver.cpp:112] Iteration 500, lr = 0.01
I0409 03:30:35.488155 13743 solver.cpp:239] Iteration 600 (52.6741 iter/s, 1.89847s/100 iters), loss = 1.97286
I0409 03:30:35.488250 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.97286 (* 1 = 1.97286 loss)
I0409 03:30:35.488258 13743 sgd_solver.cpp:112] Iteration 600, lr = 0.01
I0409 03:30:37.385839 13743 solver.cpp:239] Iteration 700 (52.6988 iter/s, 1.89758s/100 iters), loss = 1.91717
I0409 03:30:37.385912 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.91717 (* 1 = 1.91717 loss)
I0409 03:30:37.385921 13743 sgd_solver.cpp:112] Iteration 700, lr = 0.01
I0409 03:30:39.274724 13743 solver.cpp:239] Iteration 800 (52.9434 iter/s, 1.88881s/100 iters), loss = 1.87908
I0409 03:30:39.274796 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.87908 (* 1 = 1.87908 loss)
I0409 03:30:39.274806 13743 sgd_solver.cpp:112] Iteration 800, lr = 0.01
I0409 03:30:41.042135 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:30:41.172250 13743 solver.cpp:239] Iteration 900 (52.7026 iter/s, 1.89744s/100 iters), loss = 2.08282
I0409 03:30:41.172350 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 2.08282 (* 1 = 2.08282 loss)
I0409 03:30:41.172359 13743 sgd_solver.cpp:112] Iteration 900, lr = 0.01
I0409 03:30:43.052407 13743 solver.cpp:347] Iteration 1000, Testing net (#0)
I0409 03:30:43.343197 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:30:43.358860 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.80003 (* 1 = 1.80003 loss)
I0409 03:30:43.358906 13743 solver.cpp:414]     Test net output #1: accuracy = 0.259766
I0409 03:30:43.375845 13743 solver.cpp:239] Iteration 1000 (45.3822 iter/s, 2.20351s/100 iters), loss = 1.94375
I0409 03:30:43.375895 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.94375 (* 1 = 1.94375 loss)
I0409 03:30:43.375905 13743 sgd_solver.cpp:112] Iteration 1000, lr = 0.01
I0409 03:30:45.267829 13743 solver.cpp:239] Iteration 1100 (52.8562 iter/s, 1.89193s/100 iters), loss = 1.81803
I0409 03:30:45.267928 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.81803 (* 1 = 1.81803 loss)
I0409 03:30:45.267941 13743 sgd_solver.cpp:112] Iteration 1100, lr = 0.01
I0409 03:30:47.164039 13743 solver.cpp:239] Iteration 1200 (52.7396 iter/s, 1.89611s/100 iters), loss = 1.86924
I0409 03:30:47.164109 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.86924 (* 1 = 1.86924 loss)
I0409 03:30:47.164119 13743 sgd_solver.cpp:112] Iteration 1200, lr = 0.01
I0409 03:30:49.058492 13743 solver.cpp:239] Iteration 1300 (52.788 iter/s, 1.89437s/100 iters), loss = 1.80231
I0409 03:30:49.058552 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.80231 (* 1 = 1.80231 loss)
I0409 03:30:49.058559 13743 sgd_solver.cpp:112] Iteration 1300, lr = 0.01
I0409 03:30:49.840658 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:30:50.960212 13743 solver.cpp:239] Iteration 1400 (52.5857 iter/s, 1.90166s/100 iters), loss = 1.8817
I0409 03:30:50.960296 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.8817 (* 1 = 1.8817 loss)
I0409 03:30:50.960305 13743 sgd_solver.cpp:112] Iteration 1400, lr = 0.01
I0409 03:30:52.859141 13743 solver.cpp:239] Iteration 1500 (52.6636 iter/s, 1.89884s/100 iters), loss = 1.94484
I0409 03:30:52.859225 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.94484 (* 1 = 1.94484 loss)
I0409 03:30:52.859233 13743 sgd_solver.cpp:112] Iteration 1500, lr = 0.01
I0409 03:30:54.763864 13743 solver.cpp:239] Iteration 1600 (52.5043 iter/s, 1.90461s/100 iters), loss = 1.66323
I0409 03:30:54.764011 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.66323 (* 1 = 1.66323 loss)
I0409 03:30:54.764024 13743 sgd_solver.cpp:112] Iteration 1600, lr = 0.01
I0409 03:30:56.670101 13743 solver.cpp:239] Iteration 1700 (52.4629 iter/s, 1.90611s/100 iters), loss = 1.61931
I0409 03:30:56.670166 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.61931 (* 1 = 1.61931 loss)
I0409 03:30:56.670197 13743 sgd_solver.cpp:112] Iteration 1700, lr = 0.01
I0409 03:30:58.391628 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:30:58.578984 13743 solver.cpp:239] Iteration 1800 (52.3884 iter/s, 1.90882s/100 iters), loss = 1.65322
I0409 03:30:58.579061 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.65322 (* 1 = 1.65322 loss)
I0409 03:30:58.579068 13743 sgd_solver.cpp:112] Iteration 1800, lr = 0.01
I0409 03:31:00.487802 13743 solver.cpp:239] Iteration 1900 (52.3904 iter/s, 1.90875s/100 iters), loss = 1.91857
I0409 03:31:00.487874 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.91857 (* 1 = 1.91857 loss)
I0409 03:31:00.487884 13743 sgd_solver.cpp:112] Iteration 1900, lr = 0.01
I0409 03:31:02.377393 13743 solver.cpp:347] Iteration 2000, Testing net (#0)
I0409 03:31:02.671211 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:02.686949 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.79531 (* 1 = 1.79531 loss)
I0409 03:31:02.687002 13743 solver.cpp:414]     Test net output #1: accuracy = 0.282087
I0409 03:31:02.703830 13743 solver.cpp:239] Iteration 2000 (45.1271 iter/s, 2.21597s/100 iters), loss = 1.83282
I0409 03:31:02.703884 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.83282 (* 1 = 1.83282 loss)
I0409 03:31:02.703896 13743 sgd_solver.cpp:112] Iteration 2000, lr = 0.01
I0409 03:31:04.615075 13743 solver.cpp:239] Iteration 2100 (52.3235 iter/s, 1.91119s/100 iters), loss = 1.97023
I0409 03:31:04.615147 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.97023 (* 1 = 1.97023 loss)
I0409 03:31:04.615159 13743 sgd_solver.cpp:112] Iteration 2100, lr = 0.01
I0409 03:31:06.522611 13743 solver.cpp:239] Iteration 2200 (52.4256 iter/s, 1.90747s/100 iters), loss = 1.77007
I0409 03:31:06.522681 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.77007 (* 1 = 1.77007 loss)
I0409 03:31:06.522689 13743 sgd_solver.cpp:112] Iteration 2200, lr = 0.01
I0409 03:31:07.253404 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:08.435497 13743 solver.cpp:239] Iteration 2300 (52.2789 iter/s, 1.91282s/100 iters), loss = 1.80975
I0409 03:31:08.435559 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.80975 (* 1 = 1.80975 loss)
I0409 03:31:08.435569 13743 sgd_solver.cpp:112] Iteration 2300, lr = 0.01
I0409 03:31:10.347978 13743 solver.cpp:239] Iteration 2400 (52.2898 iter/s, 1.91242s/100 iters), loss = 1.9042
I0409 03:31:10.348044 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.9042 (* 1 = 1.9042 loss)
I0409 03:31:10.348054 13743 sgd_solver.cpp:112] Iteration 2400, lr = 0.01
I0409 03:31:12.257516 13743 solver.cpp:239] Iteration 2500 (52.3705 iter/s, 1.90947s/100 iters), loss = 1.76356
I0409 03:31:12.257603 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.76356 (* 1 = 1.76356 loss)
I0409 03:31:12.257611 13743 sgd_solver.cpp:112] Iteration 2500, lr = 0.01
I0409 03:31:14.168582 13743 solver.cpp:239] Iteration 2600 (52.3291 iter/s, 1.91098s/100 iters), loss = 1.7214
I0409 03:31:14.168648 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.7214 (* 1 = 1.7214 loss)
I0409 03:31:14.168658 13743 sgd_solver.cpp:112] Iteration 2600, lr = 0.01
I0409 03:31:15.839687 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:16.083812 13743 solver.cpp:239] Iteration 2700 (52.2147 iter/s, 1.91517s/100 iters), loss = 1.96864
I0409 03:31:16.083878 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.96864 (* 1 = 1.96864 loss)
I0409 03:31:16.083887 13743 sgd_solver.cpp:112] Iteration 2700, lr = 0.01
I0409 03:31:17.996361 13743 solver.cpp:239] Iteration 2800 (52.2879 iter/s, 1.91249s/100 iters), loss = 1.61925
I0409 03:31:17.996440 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.61925 (* 1 = 1.61925 loss)
I0409 03:31:17.996449 13743 sgd_solver.cpp:112] Iteration 2800, lr = 0.01
I0409 03:31:19.910548 13743 solver.cpp:239] Iteration 2900 (52.2439 iter/s, 1.9141s/100 iters), loss = 1.73762
I0409 03:31:19.910626 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.73762 (* 1 = 1.73762 loss)
I0409 03:31:19.910637 13743 sgd_solver.cpp:112] Iteration 2900, lr = 0.01
I0409 03:31:21.804111 13743 solver.cpp:347] Iteration 3000, Testing net (#0)
I0409 03:31:22.097874 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:22.112680 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.74862 (* 1 = 1.74862 loss)
I0409 03:31:22.112723 13743 solver.cpp:414]     Test net output #1: accuracy = 0.30692
I0409 03:31:22.129863 13743 solver.cpp:239] Iteration 3000 (45.0604 iter/s, 2.21925s/100 iters), loss = 1.57347
I0409 03:31:22.129905 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.57347 (* 1 = 1.57347 loss)
I0409 03:31:22.129932 13743 sgd_solver.cpp:112] Iteration 3000, lr = 0.01
I0409 03:31:24.043795 13743 solver.cpp:239] Iteration 3100 (52.2496 iter/s, 1.91389s/100 iters), loss = 1.75691
I0409 03:31:24.043877 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.75691 (* 1 = 1.75691 loss)
I0409 03:31:24.043898 13743 sgd_solver.cpp:112] Iteration 3100, lr = 0.01
I0409 03:31:24.737293 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:25.960806 13743 solver.cpp:239] Iteration 3200 (52.1666 iter/s, 1.91693s/100 iters), loss = 1.56904
I0409 03:31:25.960882 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.56904 (* 1 = 1.56904 loss)
I0409 03:31:25.960891 13743 sgd_solver.cpp:112] Iteration 3200, lr = 0.01
I0409 03:31:27.871327 13743 solver.cpp:239] Iteration 3300 (52.3437 iter/s, 1.91045s/100 iters), loss = 1.69756
I0409 03:31:27.871405 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.69756 (* 1 = 1.69756 loss)
I0409 03:31:27.871413 13743 sgd_solver.cpp:112] Iteration 3300, lr = 0.01
I0409 03:31:29.783673 13743 solver.cpp:239] Iteration 3400 (52.2939 iter/s, 1.91227s/100 iters), loss = 1.81688
I0409 03:31:29.783753 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.81688 (* 1 = 1.81688 loss)
I0409 03:31:29.783764 13743 sgd_solver.cpp:112] Iteration 3400, lr = 0.01
I0409 03:31:31.695453 13743 solver.cpp:239] Iteration 3500 (52.3093 iter/s, 1.9117s/100 iters), loss = 1.84838
I0409 03:31:31.695510 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.84838 (* 1 = 1.84838 loss)
I0409 03:31:31.695519 13743 sgd_solver.cpp:112] Iteration 3500, lr = 0.01
I0409 03:31:33.304527 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:33.605592 13743 solver.cpp:239] Iteration 3600 (52.3539 iter/s, 1.91008s/100 iters), loss = 1.43846
I0409 03:31:33.605666 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.43846 (* 1 = 1.43846 loss)
I0409 03:31:33.605675 13743 sgd_solver.cpp:112] Iteration 3600, lr = 0.01
I0409 03:31:35.517714 13743 solver.cpp:239] Iteration 3700 (52.2998 iter/s, 1.91205s/100 iters), loss = 1.81425
I0409 03:31:35.517777 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.81425 (* 1 = 1.81425 loss)
I0409 03:31:35.517786 13743 sgd_solver.cpp:112] Iteration 3700, lr = 0.01
I0409 03:31:37.432942 13743 solver.cpp:239] Iteration 3800 (52.2148 iter/s, 1.91517s/100 iters), loss = 1.48021
I0409 03:31:37.433007 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.48021 (* 1 = 1.48021 loss)
I0409 03:31:37.433017 13743 sgd_solver.cpp:112] Iteration 3800, lr = 0.01
I0409 03:31:39.345017 13743 solver.cpp:239] Iteration 3900 (52.301 iter/s, 1.91201s/100 iters), loss = 1.60155
I0409 03:31:39.345093 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.60155 (* 1 = 1.60155 loss)
I0409 03:31:39.345101 13743 sgd_solver.cpp:112] Iteration 3900, lr = 0.01
I0409 03:31:41.243381 13743 solver.cpp:347] Iteration 4000, Testing net (#0)
I0409 03:31:41.536339 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:41.551776 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.8279 (* 1 = 1.8279 loss)
I0409 03:31:41.551831 13743 solver.cpp:414]     Test net output #1: accuracy = 0.274833
I0409 03:31:41.568859 13743 solver.cpp:239] Iteration 4000 (44.9686 iter/s, 2.22377s/100 iters), loss = 1.52801
I0409 03:31:41.568907 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.52801 (* 1 = 1.52801 loss)
I0409 03:31:41.568917 13743 sgd_solver.cpp:112] Iteration 4000, lr = 0.01
I0409 03:31:42.202915 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:43.476106 13743 solver.cpp:239] Iteration 4100 (52.4329 iter/s, 1.9072s/100 iters), loss = 1.54926
I0409 03:31:43.476197 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.54926 (* 1 = 1.54926 loss)
I0409 03:31:43.476205 13743 sgd_solver.cpp:112] Iteration 4100, lr = 0.01
I0409 03:31:45.396060 13743 solver.cpp:239] Iteration 4200 (52.087 iter/s, 1.91987s/100 iters), loss = 1.67558
I0409 03:31:45.396133 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.67558 (* 1 = 1.67558 loss)
I0409 03:31:45.396142 13743 sgd_solver.cpp:112] Iteration 4200, lr = 0.01
I0409 03:31:47.316542 13743 solver.cpp:239] Iteration 4300 (52.0721 iter/s, 1.92042s/100 iters), loss = 1.51549
I0409 03:31:47.316608 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.51549 (* 1 = 1.51549 loss)
I0409 03:31:47.316617 13743 sgd_solver.cpp:112] Iteration 4300, lr = 0.01
I0409 03:31:49.230265 13743 solver.cpp:239] Iteration 4400 (52.256 iter/s, 1.91365s/100 iters), loss = 2.12057
I0409 03:31:49.230326 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 2.12057 (* 1 = 2.12057 loss)
I0409 03:31:49.230334 13743 sgd_solver.cpp:112] Iteration 4400, lr = 0.01
I0409 03:31:50.786759 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:31:51.146524 13743 solver.cpp:239] Iteration 4500 (52.1866 iter/s, 1.9162s/100 iters), loss = 1.50258
I0409 03:31:51.146594 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.50258 (* 1 = 1.50258 loss)
I0409 03:31:51.146602 13743 sgd_solver.cpp:112] Iteration 4500, lr = 0.01
I0409 03:31:53.061322 13743 solver.cpp:239] Iteration 4600 (52.2267 iter/s, 1.91473s/100 iters), loss = 1.55728
I0409 03:31:53.061401 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.55728 (* 1 = 1.55728 loss)
I0409 03:31:53.061410 13743 sgd_solver.cpp:112] Iteration 4600, lr = 0.01
I0409 03:31:54.980933 13743 solver.cpp:239] Iteration 4700 (52.0963 iter/s, 1.91952s/100 iters), loss = 1.69157
I0409 03:31:54.981007 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.69157 (* 1 = 1.69157 loss)
I0409 03:31:54.981016 13743 sgd_solver.cpp:112] Iteration 4700, lr = 0.01
I0409 03:31:56.899730 13743 solver.cpp:239] Iteration 4800 (52.118 iter/s, 1.91872s/100 iters), loss = 1.42278
I0409 03:31:56.899808 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.42278 (* 1 = 1.42278 loss)
I0409 03:31:56.899817 13743 sgd_solver.cpp:112] Iteration 4800, lr = 0.01
I0409 03:31:58.815492 13743 solver.cpp:239] Iteration 4900 (52.2006 iter/s, 1.91569s/100 iters), loss = 1.65749
I0409 03:31:58.815553 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.65749 (* 1 = 1.65749 loss)
I0409 03:31:58.815562 13743 sgd_solver.cpp:112] Iteration 4900, lr = 0.01
I0409 03:31:59.396801 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:00.714486 13743 solver.cpp:347] Iteration 5000, Testing net (#0)
I0409 03:32:01.009189 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:01.024628 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.5896 (* 1 = 1.5896 loss)
I0409 03:32:01.024670 13743 solver.cpp:414]     Test net output #1: accuracy = 0.385603
I0409 03:32:01.041815 13743 solver.cpp:239] Iteration 5000 (44.9181 iter/s, 2.22627s/100 iters), loss = 1.44457
I0409 03:32:01.041865 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.44457 (* 1 = 1.44457 loss)
I0409 03:32:01.041877 13743 sgd_solver.cpp:112] Iteration 5000, lr = 0.01
I0409 03:32:02.956593 13743 solver.cpp:239] Iteration 5100 (52.2268 iter/s, 1.91472s/100 iters), loss = 1.61845
I0409 03:32:02.956671 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.61845 (* 1 = 1.61845 loss)
I0409 03:32:02.956681 13743 sgd_solver.cpp:112] Iteration 5100, lr = 0.01
I0409 03:32:04.875948 13743 solver.cpp:239] Iteration 5200 (52.1032 iter/s, 1.91927s/100 iters), loss = 1.36239
I0409 03:32:04.876024 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.36239 (* 1 = 1.36239 loss)
I0409 03:32:04.876034 13743 sgd_solver.cpp:112] Iteration 5200, lr = 0.01
I0409 03:32:06.782543 13743 solver.cpp:239] Iteration 5300 (52.4516 iter/s, 1.90652s/100 iters), loss = 1.59409
I0409 03:32:06.782627 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.59409 (* 1 = 1.59409 loss)
I0409 03:32:06.782639 13743 sgd_solver.cpp:112] Iteration 5300, lr = 0.01
I0409 03:32:08.275207 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:08.688386 13743 solver.cpp:239] Iteration 5400 (52.4725 iter/s, 1.90576s/100 iters), loss = 1.33675
I0409 03:32:08.688465 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.33675 (* 1 = 1.33675 loss)
I0409 03:32:08.688474 13743 sgd_solver.cpp:112] Iteration 5400, lr = 0.01
I0409 03:32:10.594620 13743 solver.cpp:239] Iteration 5500 (52.4616 iter/s, 1.90616s/100 iters), loss = 1.47744
I0409 03:32:10.594697 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.47744 (* 1 = 1.47744 loss)
I0409 03:32:10.594707 13743 sgd_solver.cpp:112] Iteration 5500, lr = 0.01
I0409 03:32:12.510236 13743 solver.cpp:239] Iteration 5600 (52.2045 iter/s, 1.91554s/100 iters), loss = 1.43709
I0409 03:32:12.510300 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.43709 (* 1 = 1.43709 loss)
I0409 03:32:12.510309 13743 sgd_solver.cpp:112] Iteration 5600, lr = 0.01
I0409 03:32:14.425206 13743 solver.cpp:239] Iteration 5700 (52.2219 iter/s, 1.9149s/100 iters), loss = 1.43834
I0409 03:32:14.425282 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.43834 (* 1 = 1.43834 loss)
I0409 03:32:14.425290 13743 sgd_solver.cpp:112] Iteration 5700, lr = 0.01
I0409 03:32:16.334980 13743 solver.cpp:239] Iteration 5800 (52.3646 iter/s, 1.90969s/100 iters), loss = 1.81122
I0409 03:32:16.335065 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.81122 (* 1 = 1.81122 loss)
I0409 03:32:16.335075 13743 sgd_solver.cpp:112] Iteration 5800, lr = 0.01
I0409 03:32:16.855820 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:18.251662 13743 solver.cpp:239] Iteration 5900 (52.1758 iter/s, 1.9166s/100 iters), loss = 1.56636
I0409 03:32:18.251731 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.56636 (* 1 = 1.56636 loss)
I0409 03:32:18.251740 13743 sgd_solver.cpp:112] Iteration 5900, lr = 0.01
I0409 03:32:20.147409 13743 solver.cpp:347] Iteration 6000, Testing net (#0)
I0409 03:32:20.443091 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:20.457139 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.40503 (* 1 = 1.40503 loss)
I0409 03:32:20.457172 13743 solver.cpp:414]     Test net output #1: accuracy = 0.456752
I0409 03:32:20.474421 13743 solver.cpp:239] Iteration 6000 (44.9905 iter/s, 2.22269s/100 iters), loss = 1.5841
I0409 03:32:20.474489 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.5841 (* 1 = 1.5841 loss)
I0409 03:32:20.474501 13743 sgd_solver.cpp:112] Iteration 6000, lr = 0.01
I0409 03:32:22.390688 13743 solver.cpp:239] Iteration 6100 (52.1866 iter/s, 1.9162s/100 iters), loss = 1.87644
I0409 03:32:22.390753 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.87644 (* 1 = 1.87644 loss)
I0409 03:32:22.390763 13743 sgd_solver.cpp:112] Iteration 6100, lr = 0.01
I0409 03:32:24.310293 13743 solver.cpp:239] Iteration 6200 (52.0957 iter/s, 1.91954s/100 iters), loss = 1.65046
I0409 03:32:24.310356 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.65046 (* 1 = 1.65046 loss)
I0409 03:32:24.310365 13743 sgd_solver.cpp:112] Iteration 6200, lr = 0.01
I0409 03:32:25.768968 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:26.223839 13743 solver.cpp:239] Iteration 6300 (52.2606 iter/s, 1.91349s/100 iters), loss = 1.5161
I0409 03:32:26.223903 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.5161 (* 1 = 1.5161 loss)
I0409 03:32:26.223912 13743 sgd_solver.cpp:112] Iteration 6300, lr = 0.01
I0409 03:32:28.139005 13743 solver.cpp:239] Iteration 6400 (52.2165 iter/s, 1.9151s/100 iters), loss = 1.9556
I0409 03:32:28.139081 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.9556 (* 1 = 1.9556 loss)
I0409 03:32:28.139091 13743 sgd_solver.cpp:112] Iteration 6400, lr = 0.01
I0409 03:32:30.057754 13743 solver.cpp:239] Iteration 6500 (52.1192 iter/s, 1.91868s/100 iters), loss = 1.55844
I0409 03:32:30.057811 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.55844 (* 1 = 1.55844 loss)
I0409 03:32:30.057819 13743 sgd_solver.cpp:112] Iteration 6500, lr = 0.01
I0409 03:32:31.976430 13743 solver.cpp:239] Iteration 6600 (52.1215 iter/s, 1.9186s/100 iters), loss = 1.28046
I0409 03:32:31.976507 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.28046 (* 1 = 1.28046 loss)
I0409 03:32:31.976518 13743 sgd_solver.cpp:112] Iteration 6600, lr = 0.01
I0409 03:32:33.890700 13743 solver.cpp:239] Iteration 6700 (52.2414 iter/s, 1.91419s/100 iters), loss = 1.71889
I0409 03:32:33.890779 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.71889 (* 1 = 1.71889 loss)
I0409 03:32:33.890791 13743 sgd_solver.cpp:112] Iteration 6700, lr = 0.01
I0409 03:32:34.354686 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:35.804610 13743 solver.cpp:239] Iteration 6800 (52.2512 iter/s, 1.91383s/100 iters), loss = 1.25073
I0409 03:32:35.804688 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.25073 (* 1 = 1.25073 loss)
I0409 03:32:35.804699 13743 sgd_solver.cpp:112] Iteration 6800, lr = 0.01
I0409 03:32:37.721088 13743 solver.cpp:239] Iteration 6900 (52.1811 iter/s, 1.9164s/100 iters), loss = 1.14701
I0409 03:32:37.721168 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14701 (* 1 = 1.14701 loss)
I0409 03:32:37.721176 13743 sgd_solver.cpp:112] Iteration 6900, lr = 0.01
I0409 03:32:39.614280 13743 solver.cpp:347] Iteration 7000, Testing net (#0)
I0409 03:32:39.906298 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:39.921643 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.37308 (* 1 = 1.37308 loss)
I0409 03:32:39.921670 13743 solver.cpp:414]     Test net output #1: accuracy = 0.481027
I0409 03:32:39.938735 13743 solver.cpp:239] Iteration 7000 (45.0942 iter/s, 2.21758s/100 iters), loss = 1.27316
I0409 03:32:39.938778 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.27316 (* 1 = 1.27316 loss)
I0409 03:32:39.938788 13743 sgd_solver.cpp:112] Iteration 7000, lr = 0.01
I0409 03:32:41.858568 13743 solver.cpp:239] Iteration 7100 (52.0894 iter/s, 1.91978s/100 iters), loss = 1.19083
I0409 03:32:41.858644 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19083 (* 1 = 1.19083 loss)
I0409 03:32:41.858655 13743 sgd_solver.cpp:112] Iteration 7100, lr = 0.01
I0409 03:32:43.257616 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:43.772647 13743 solver.cpp:239] Iteration 7200 (52.2465 iter/s, 1.914s/100 iters), loss = 1.44793
I0409 03:32:43.772714 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.44793 (* 1 = 1.44793 loss)
I0409 03:32:43.772723 13743 sgd_solver.cpp:112] Iteration 7200, lr = 0.01
I0409 03:32:45.691921 13743 solver.cpp:239] Iteration 7300 (52.1048 iter/s, 1.91921s/100 iters), loss = 1.5852
I0409 03:32:45.691985 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.5852 (* 1 = 1.5852 loss)
I0409 03:32:45.691994 13743 sgd_solver.cpp:112] Iteration 7300, lr = 0.01
I0409 03:32:47.612336 13743 solver.cpp:239] Iteration 7400 (52.0738 iter/s, 1.92035s/100 iters), loss = 1.32163
I0409 03:32:47.612408 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.32163 (* 1 = 1.32163 loss)
I0409 03:32:47.612417 13743 sgd_solver.cpp:112] Iteration 7400, lr = 0.01
I0409 03:32:49.524317 13743 solver.cpp:239] Iteration 7500 (52.3038 iter/s, 1.91191s/100 iters), loss = 1.36715
I0409 03:32:49.524435 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.36715 (* 1 = 1.36715 loss)
I0409 03:32:49.524459 13743 sgd_solver.cpp:112] Iteration 7500, lr = 0.01
I0409 03:32:51.439218 13743 solver.cpp:239] Iteration 7600 (52.2253 iter/s, 1.91478s/100 iters), loss = 1.38537
I0409 03:32:51.439309 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.38537 (* 1 = 1.38537 loss)
I0409 03:32:51.439321 13743 sgd_solver.cpp:112] Iteration 7600, lr = 0.01
I0409 03:32:51.845356 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:53.355315 13743 solver.cpp:239] Iteration 7700 (52.1918 iter/s, 1.91601s/100 iters), loss = 1.32532
I0409 03:32:53.355387 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.32532 (* 1 = 1.32532 loss)
I0409 03:32:53.355396 13743 sgd_solver.cpp:112] Iteration 7700, lr = 0.01
I0409 03:32:55.270239 13743 solver.cpp:239] Iteration 7800 (52.2237 iter/s, 1.91484s/100 iters), loss = 1.25419
I0409 03:32:55.270301 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.25419 (* 1 = 1.25419 loss)
I0409 03:32:55.270310 13743 sgd_solver.cpp:112] Iteration 7800, lr = 0.01
I0409 03:32:57.184363 13743 solver.cpp:239] Iteration 7900 (52.2453 iter/s, 1.91405s/100 iters), loss = 1.29469
I0409 03:32:57.184433 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.29469 (* 1 = 1.29469 loss)
I0409 03:32:57.184442 13743 sgd_solver.cpp:112] Iteration 7900, lr = 0.01
I0409 03:32:59.083257 13743 solver.cpp:347] Iteration 8000, Testing net (#0)
I0409 03:32:59.376436 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:32:59.391963 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.36936 (* 1 = 1.36936 loss)
I0409 03:32:59.391999 13743 solver.cpp:414]     Test net output #1: accuracy = 0.483817
I0409 03:32:59.409090 13743 solver.cpp:239] Iteration 8000 (44.9507 iter/s, 2.22466s/100 iters), loss = 1.25304
I0409 03:32:59.409163 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.25304 (* 1 = 1.25304 loss)
I0409 03:32:59.409174 13743 sgd_solver.cpp:112] Iteration 8000, lr = 0.01
I0409 03:33:00.751669 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:01.319774 13743 solver.cpp:239] Iteration 8100 (52.3394 iter/s, 1.91061s/100 iters), loss = 1.19495
I0409 03:33:01.319864 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19495 (* 1 = 1.19495 loss)
I0409 03:33:01.319875 13743 sgd_solver.cpp:112] Iteration 8100, lr = 0.01
I0409 03:33:03.230998 13743 solver.cpp:239] Iteration 8200 (52.3248 iter/s, 1.91114s/100 iters), loss = 1.35815
I0409 03:33:03.231089 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.35815 (* 1 = 1.35815 loss)
I0409 03:33:03.231097 13743 sgd_solver.cpp:112] Iteration 8200, lr = 0.01
I0409 03:33:05.144423 13743 solver.cpp:239] Iteration 8300 (52.2644 iter/s, 1.91335s/100 iters), loss = 1.25871
I0409 03:33:05.144485 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.25871 (* 1 = 1.25871 loss)
I0409 03:33:05.144495 13743 sgd_solver.cpp:112] Iteration 8300, lr = 0.01
I0409 03:33:07.059283 13743 solver.cpp:239] Iteration 8400 (52.2248 iter/s, 1.9148s/100 iters), loss = 1.26308
I0409 03:33:07.059346 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.26308 (* 1 = 1.26308 loss)
I0409 03:33:07.059355 13743 sgd_solver.cpp:112] Iteration 8400, lr = 0.01
I0409 03:33:08.974992 13743 solver.cpp:239] Iteration 8500 (52.2018 iter/s, 1.91564s/100 iters), loss = 1.28875
I0409 03:33:08.975111 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.28875 (* 1 = 1.28875 loss)
I0409 03:33:08.975121 13743 sgd_solver.cpp:112] Iteration 8500, lr = 0.01
I0409 03:33:09.322204 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:10.884959 13743 solver.cpp:239] Iteration 8600 (52.3601 iter/s, 1.90985s/100 iters), loss = 1.28093
I0409 03:33:10.885025 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.28093 (* 1 = 1.28093 loss)
I0409 03:33:10.885035 13743 sgd_solver.cpp:112] Iteration 8600, lr = 0.01
I0409 03:33:12.802474 13743 solver.cpp:239] Iteration 8700 (52.1526 iter/s, 1.91745s/100 iters), loss = 1.5758
I0409 03:33:12.802846 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.5758 (* 1 = 1.5758 loss)
I0409 03:33:12.802881 13743 sgd_solver.cpp:112] Iteration 8700, lr = 0.01
I0409 03:33:14.718786 13743 solver.cpp:239] Iteration 8800 (52.1931 iter/s, 1.91596s/100 iters), loss = 1.26507
I0409 03:33:14.718842 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.26507 (* 1 = 1.26507 loss)
I0409 03:33:14.718852 13743 sgd_solver.cpp:112] Iteration 8800, lr = 0.01
I0409 03:33:16.634120 13743 solver.cpp:239] Iteration 8900 (52.2118 iter/s, 1.91528s/100 iters), loss = 1.2677
I0409 03:33:16.634212 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.2677 (* 1 = 1.2677 loss)
I0409 03:33:16.634222 13743 sgd_solver.cpp:112] Iteration 8900, lr = 0.01
I0409 03:33:17.921386 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:18.533346 13743 solver.cpp:347] Iteration 9000, Testing net (#0)
I0409 03:33:18.828755 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:18.844749 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.44758 (* 1 = 1.44758 loss)
I0409 03:33:18.844774 13743 solver.cpp:414]     Test net output #1: accuracy = 0.482422
I0409 03:33:18.862212 13743 solver.cpp:239] Iteration 9000 (44.883 iter/s, 2.22801s/100 iters), loss = 1.42189
I0409 03:33:18.862255 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.42189 (* 1 = 1.42189 loss)
I0409 03:33:18.862267 13743 sgd_solver.cpp:112] Iteration 9000, lr = 0.01
I0409 03:33:20.777884 13743 solver.cpp:239] Iteration 9100 (52.2022 iter/s, 1.91563s/100 iters), loss = 1.13573
I0409 03:33:20.777958 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13573 (* 1 = 1.13573 loss)
I0409 03:33:20.777968 13743 sgd_solver.cpp:112] Iteration 9100, lr = 0.01
I0409 03:33:22.690165 13743 solver.cpp:239] Iteration 9200 (52.2956 iter/s, 1.91221s/100 iters), loss = 1.22418
I0409 03:33:22.690237 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.22418 (* 1 = 1.22418 loss)
I0409 03:33:22.690245 13743 sgd_solver.cpp:112] Iteration 9200, lr = 0.01
I0409 03:33:24.606089 13743 solver.cpp:239] Iteration 9300 (52.196 iter/s, 1.91585s/100 iters), loss = 1.50046
I0409 03:33:24.606184 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.50046 (* 1 = 1.50046 loss)
I0409 03:33:24.606194 13743 sgd_solver.cpp:112] Iteration 9300, lr = 0.01
I0409 03:33:26.521376 13743 solver.cpp:239] Iteration 9400 (52.214 iter/s, 1.91519s/100 iters), loss = 1.55253
I0409 03:33:26.521466 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.55253 (* 1 = 1.55253 loss)
I0409 03:33:26.521474 13743 sgd_solver.cpp:112] Iteration 9400, lr = 0.01
I0409 03:33:26.830963 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:28.437237 13743 solver.cpp:239] Iteration 9500 (52.1983 iter/s, 1.91577s/100 iters), loss = 1.34063
I0409 03:33:28.437310 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.34063 (* 1 = 1.34063 loss)
I0409 03:33:28.437335 13743 sgd_solver.cpp:112] Iteration 9500, lr = 0.01
I0409 03:33:30.357023 13743 solver.cpp:239] Iteration 9600 (52.091 iter/s, 1.91972s/100 iters), loss = 1.11084
I0409 03:33:30.357085 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.11084 (* 1 = 1.11084 loss)
I0409 03:33:30.357092 13743 sgd_solver.cpp:112] Iteration 9600, lr = 0.01
I0409 03:33:32.277678 13743 solver.cpp:239] Iteration 9700 (52.0676 iter/s, 1.92058s/100 iters), loss = 1.20327
I0409 03:33:32.277810 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20327 (* 1 = 1.20327 loss)
I0409 03:33:32.277818 13743 sgd_solver.cpp:112] Iteration 9700, lr = 0.01
I0409 03:33:34.194454 13743 solver.cpp:239] Iteration 9800 (52.1741 iter/s, 1.91666s/100 iters), loss = 1.48087
I0409 03:33:34.194519 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.48087 (* 1 = 1.48087 loss)
I0409 03:33:34.194527 13743 sgd_solver.cpp:112] Iteration 9800, lr = 0.01
I0409 03:33:35.425071 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:36.109892 13743 solver.cpp:239] Iteration 9900 (52.2091 iter/s, 1.91538s/100 iters), loss = 1.3156
I0409 03:33:36.109969 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.3156 (* 1 = 1.3156 loss)
I0409 03:33:36.109977 13743 sgd_solver.cpp:112] Iteration 9900, lr = 0.01
I0409 03:33:38.006677 13743 solver.cpp:464] Snapshotting to binary proto file ./FaceEmotionNet_model_iter_10000.caffemodel
I0409 03:33:38.110704 13743 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./FaceEmotionNet_model_iter_10000.solverstate
I0409 03:33:38.155772 13743 solver.cpp:347] Iteration 10000, Testing net (#0)
I0409 03:33:38.446110 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:38.461359 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.37026 (* 1 = 1.37026 loss)
I0409 03:33:38.461410 13743 solver.cpp:414]     Test net output #1: accuracy = 0.501674
I0409 03:33:38.478356 13743 solver.cpp:239] Iteration 10000 (42.2226 iter/s, 2.3684s/100 iters), loss = 1.51903
I0409 03:33:38.478402 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.51903 (* 1 = 1.51903 loss)
I0409 03:33:38.478416 13743 sgd_solver.cpp:112] Iteration 10000, lr = 0.01
I0409 03:33:40.390719 13743 solver.cpp:239] Iteration 10100 (52.2932 iter/s, 1.9123s/100 iters), loss = 1.30976
I0409 03:33:40.390841 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.30976 (* 1 = 1.30976 loss)
I0409 03:33:40.390849 13743 sgd_solver.cpp:112] Iteration 10100, lr = 0.01
I0409 03:33:42.308295 13743 solver.cpp:239] Iteration 10200 (52.1533 iter/s, 1.91742s/100 iters), loss = 1.37748
I0409 03:33:42.308425 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.37748 (* 1 = 1.37748 loss)
I0409 03:33:42.308434 13743 sgd_solver.cpp:112] Iteration 10200, lr = 0.01
I0409 03:33:44.226876 13743 solver.cpp:239] Iteration 10300 (52.1253 iter/s, 1.91845s/100 iters), loss = 1.2242
I0409 03:33:44.226954 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.2242 (* 1 = 1.2242 loss)
I0409 03:33:44.226963 13743 sgd_solver.cpp:112] Iteration 10300, lr = 0.01
I0409 03:33:44.481750 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:46.149709 13743 solver.cpp:239] Iteration 10400 (52.0087 iter/s, 1.92275s/100 iters), loss = 1.33621
I0409 03:33:46.149791 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.33621 (* 1 = 1.33621 loss)
I0409 03:33:46.149801 13743 sgd_solver.cpp:112] Iteration 10400, lr = 0.01
I0409 03:33:48.065908 13743 solver.cpp:239] Iteration 10500 (52.1887 iter/s, 1.91612s/100 iters), loss = 1.51658
I0409 03:33:48.065968 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.51658 (* 1 = 1.51658 loss)
I0409 03:33:48.065976 13743 sgd_solver.cpp:112] Iteration 10500, lr = 0.01
I0409 03:33:49.986177 13743 solver.cpp:239] Iteration 10600 (52.0779 iter/s, 1.9202s/100 iters), loss = 1.2491
I0409 03:33:49.986260 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.2491 (* 1 = 1.2491 loss)
I0409 03:33:49.986270 13743 sgd_solver.cpp:112] Iteration 10600, lr = 0.01
I0409 03:33:51.907871 13743 solver.cpp:239] Iteration 10700 (52.0393 iter/s, 1.92162s/100 iters), loss = 1.42661
I0409 03:33:51.907946 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.42661 (* 1 = 1.42661 loss)
I0409 03:33:51.907955 13743 sgd_solver.cpp:112] Iteration 10700, lr = 0.01
I0409 03:33:53.082123 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:53.822782 13743 solver.cpp:239] Iteration 10800 (52.2239 iter/s, 1.91483s/100 iters), loss = 1.52783
I0409 03:33:53.822852 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.52783 (* 1 = 1.52783 loss)
I0409 03:33:53.822870 13743 sgd_solver.cpp:112] Iteration 10800, lr = 0.01
I0409 03:33:55.744529 13743 solver.cpp:239] Iteration 10900 (52.0378 iter/s, 1.92168s/100 iters), loss = 1.23286
I0409 03:33:55.744593 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.23286 (* 1 = 1.23286 loss)
I0409 03:33:55.744603 13743 sgd_solver.cpp:112] Iteration 10900, lr = 0.01
I0409 03:33:57.639202 13743 solver.cpp:347] Iteration 11000, Testing net (#0)
I0409 03:33:57.933923 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:33:57.949656 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.26594 (* 1 = 1.26594 loss)
I0409 03:33:57.949687 13743 solver.cpp:414]     Test net output #1: accuracy = 0.520089
I0409 03:33:57.966961 13743 solver.cpp:239] Iteration 11000 (44.9971 iter/s, 2.22236s/100 iters), loss = 0.954823
I0409 03:33:57.967033 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.954823 (* 1 = 0.954823 loss)
I0409 03:33:57.967062 13743 sgd_solver.cpp:112] Iteration 11000, lr = 0.01
I0409 03:33:59.883304 13743 solver.cpp:239] Iteration 11100 (52.1851 iter/s, 1.91626s/100 iters), loss = 1.18678
I0409 03:33:59.883363 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.18678 (* 1 = 1.18678 loss)
I0409 03:33:59.883373 13743 sgd_solver.cpp:112] Iteration 11100, lr = 0.01
I0409 03:34:01.800312 13743 solver.cpp:239] Iteration 11200 (52.1663 iter/s, 1.91695s/100 iters), loss = 1.25606
I0409 03:34:01.800403 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.25606 (* 1 = 1.25606 loss)
I0409 03:34:01.800412 13743 sgd_solver.cpp:112] Iteration 11200, lr = 0.01
I0409 03:34:01.995712 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:03.717725 13743 solver.cpp:239] Iteration 11300 (52.1561 iter/s, 1.91732s/100 iters), loss = 1.41745
I0409 03:34:03.717800 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.41745 (* 1 = 1.41745 loss)
I0409 03:34:03.717810 13743 sgd_solver.cpp:112] Iteration 11300, lr = 0.01
I0409 03:34:05.633414 13743 solver.cpp:239] Iteration 11400 (52.2022 iter/s, 1.91563s/100 iters), loss = 1.40606
I0409 03:34:05.633489 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.40606 (* 1 = 1.40606 loss)
I0409 03:34:05.633498 13743 sgd_solver.cpp:112] Iteration 11400, lr = 0.01
I0409 03:34:07.549274 13743 solver.cpp:239] Iteration 11500 (52.1979 iter/s, 1.91579s/100 iters), loss = 1.14127
I0409 03:34:07.549335 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14127 (* 1 = 1.14127 loss)
I0409 03:34:07.549345 13743 sgd_solver.cpp:112] Iteration 11500, lr = 0.01
I0409 03:34:09.464104 13743 solver.cpp:239] Iteration 11600 (52.2256 iter/s, 1.91477s/100 iters), loss = 1.13054
I0409 03:34:09.464197 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13054 (* 1 = 1.13054 loss)
I0409 03:34:09.464205 13743 sgd_solver.cpp:112] Iteration 11600, lr = 0.01
I0409 03:34:10.599714 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:11.383554 13743 solver.cpp:239] Iteration 11700 (52.1008 iter/s, 1.91936s/100 iters), loss = 1.32009
I0409 03:34:11.383615 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.32009 (* 1 = 1.32009 loss)
I0409 03:34:11.383622 13743 sgd_solver.cpp:112] Iteration 11700, lr = 0.01
I0409 03:34:13.301456 13743 solver.cpp:239] Iteration 11800 (52.1424 iter/s, 1.91783s/100 iters), loss = 1.09861
I0409 03:34:13.301538 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09861 (* 1 = 1.09861 loss)
I0409 03:34:13.301548 13743 sgd_solver.cpp:112] Iteration 11800, lr = 0.01
I0409 03:34:15.220489 13743 solver.cpp:239] Iteration 11900 (52.1122 iter/s, 1.91894s/100 iters), loss = 1.07148
I0409 03:34:15.220610 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07148 (* 1 = 1.07148 loss)
I0409 03:34:15.220624 13743 sgd_solver.cpp:112] Iteration 11900, lr = 0.01
I0409 03:34:17.118901 13743 solver.cpp:347] Iteration 12000, Testing net (#0)
I0409 03:34:17.418409 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:17.428799 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.27649 (* 1 = 1.27649 loss)
I0409 03:34:17.428831 13743 solver.cpp:414]     Test net output #1: accuracy = 0.526507
I0409 03:34:17.445922 13743 solver.cpp:239] Iteration 12000 (44.9378 iter/s, 2.2253s/100 iters), loss = 1.52607
I0409 03:34:17.446007 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.52607 (* 1 = 1.52607 loss)
I0409 03:34:17.446020 13743 sgd_solver.cpp:112] Iteration 12000, lr = 0.01
I0409 03:34:19.362519 13743 solver.cpp:239] Iteration 12100 (52.1784 iter/s, 1.9165s/100 iters), loss = 1.0067
I0409 03:34:19.362581 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.0067 (* 1 = 1.0067 loss)
I0409 03:34:19.362588 13743 sgd_solver.cpp:112] Iteration 12100, lr = 0.01
I0409 03:34:19.501044 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:21.283205 13743 solver.cpp:239] Iteration 12200 (52.0663 iter/s, 1.92063s/100 iters), loss = 1.41443
I0409 03:34:21.283275 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.41443 (* 1 = 1.41443 loss)
I0409 03:34:21.283283 13743 sgd_solver.cpp:112] Iteration 12200, lr = 0.01
I0409 03:34:23.201241 13743 solver.cpp:239] Iteration 12300 (52.1385 iter/s, 1.91797s/100 iters), loss = 1.31906
I0409 03:34:23.201318 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.31906 (* 1 = 1.31906 loss)
I0409 03:34:23.201328 13743 sgd_solver.cpp:112] Iteration 12300, lr = 0.01
I0409 03:34:25.121731 13743 solver.cpp:239] Iteration 12400 (52.072 iter/s, 1.92042s/100 iters), loss = 1.4549
I0409 03:34:25.121793 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.4549 (* 1 = 1.4549 loss)
I0409 03:34:25.121803 13743 sgd_solver.cpp:112] Iteration 12400, lr = 0.01
I0409 03:34:27.038525 13743 solver.cpp:239] Iteration 12500 (52.1721 iter/s, 1.91673s/100 iters), loss = 0.964
I0409 03:34:27.038586 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.964 (* 1 = 0.964 loss)
I0409 03:34:27.038595 13743 sgd_solver.cpp:112] Iteration 12500, lr = 0.01
I0409 03:34:28.115005 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:28.952275 13743 solver.cpp:239] Iteration 12600 (52.2552 iter/s, 1.91368s/100 iters), loss = 1.3303
I0409 03:34:28.952365 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.3303 (* 1 = 1.3303 loss)
I0409 03:34:28.952373 13743 sgd_solver.cpp:112] Iteration 12600, lr = 0.01
I0409 03:34:30.868403 13743 solver.cpp:239] Iteration 12700 (52.1914 iter/s, 1.91603s/100 iters), loss = 1.12692
I0409 03:34:30.868477 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.12692 (* 1 = 1.12692 loss)
I0409 03:34:30.868485 13743 sgd_solver.cpp:112] Iteration 12700, lr = 0.01
I0409 03:34:32.783815 13743 solver.cpp:239] Iteration 12800 (52.2102 iter/s, 1.91534s/100 iters), loss = 1.10015
I0409 03:34:32.783895 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10015 (* 1 = 1.10015 loss)
I0409 03:34:32.783905 13743 sgd_solver.cpp:112] Iteration 12800, lr = 0.01
I0409 03:34:34.702896 13743 solver.cpp:239] Iteration 12900 (52.1103 iter/s, 1.91901s/100 iters), loss = 1.31406
I0409 03:34:34.703006 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.31406 (* 1 = 1.31406 loss)
I0409 03:34:34.703013 13743 sgd_solver.cpp:112] Iteration 12900, lr = 0.01
I0409 03:34:36.600685 13743 solver.cpp:347] Iteration 13000, Testing net (#0)
I0409 03:34:36.900893 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:36.910748 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.36729 (* 1 = 1.36729 loss)
I0409 03:34:36.910787 13743 solver.cpp:414]     Test net output #1: accuracy = 0.493583
I0409 03:34:36.927866 13743 solver.cpp:239] Iteration 13000 (44.9464 iter/s, 2.22487s/100 iters), loss = 1.19558
I0409 03:34:36.927922 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19558 (* 1 = 1.19558 loss)
I0409 03:34:36.927933 13743 sgd_solver.cpp:112] Iteration 13000, lr = 0.01
I0409 03:34:37.009008 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:38.841869 13743 solver.cpp:239] Iteration 13100 (52.2482 iter/s, 1.91394s/100 iters), loss = 1.23976
I0409 03:34:38.841949 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.23976 (* 1 = 1.23976 loss)
I0409 03:34:38.841958 13743 sgd_solver.cpp:112] Iteration 13100, lr = 0.01
I0409 03:34:40.758155 13743 solver.cpp:239] Iteration 13200 (52.1866 iter/s, 1.9162s/100 iters), loss = 1.41271
I0409 03:34:40.758236 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.41271 (* 1 = 1.41271 loss)
I0409 03:34:40.758246 13743 sgd_solver.cpp:112] Iteration 13200, lr = 0.01
I0409 03:34:42.674036 13743 solver.cpp:239] Iteration 13300 (52.1975 iter/s, 1.9158s/100 iters), loss = 1.6981
I0409 03:34:42.674115 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.6981 (* 1 = 1.6981 loss)
I0409 03:34:42.674124 13743 sgd_solver.cpp:112] Iteration 13300, lr = 0.01
I0409 03:34:44.591792 13743 solver.cpp:239] Iteration 13400 (52.1463 iter/s, 1.91768s/100 iters), loss = 1.20712
I0409 03:34:44.591869 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20712 (* 1 = 1.20712 loss)
I0409 03:34:44.591881 13743 sgd_solver.cpp:112] Iteration 13400, lr = 0.01
I0409 03:34:45.611562 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:46.507261 13743 solver.cpp:239] Iteration 13500 (52.2085 iter/s, 1.9154s/100 iters), loss = 1.23558
I0409 03:34:46.507334 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.23558 (* 1 = 1.23558 loss)
I0409 03:34:46.507342 13743 sgd_solver.cpp:112] Iteration 13500, lr = 0.01
I0409 03:34:48.423435 13743 solver.cpp:239] Iteration 13600 (52.1892 iter/s, 1.9161s/100 iters), loss = 1.43829
I0409 03:34:48.423502 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.43829 (* 1 = 1.43829 loss)
I0409 03:34:48.423511 13743 sgd_solver.cpp:112] Iteration 13600, lr = 0.01
I0409 03:34:50.337318 13743 solver.cpp:239] Iteration 13700 (52.2517 iter/s, 1.91381s/100 iters), loss = 1.18745
I0409 03:34:50.337406 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.18745 (* 1 = 1.18745 loss)
I0409 03:34:50.337414 13743 sgd_solver.cpp:112] Iteration 13700, lr = 0.01
I0409 03:34:52.254869 13743 solver.cpp:239] Iteration 13800 (52.1531 iter/s, 1.91743s/100 iters), loss = 1.12565
I0409 03:34:52.254989 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.12565 (* 1 = 1.12565 loss)
I0409 03:34:52.255002 13743 sgd_solver.cpp:112] Iteration 13800, lr = 0.01
I0409 03:34:54.170228 13743 solver.cpp:239] Iteration 13900 (52.2126 iter/s, 1.91525s/100 iters), loss = 1.20301
I0409 03:34:54.170332 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20301 (* 1 = 1.20301 loss)
I0409 03:34:54.170341 13743 sgd_solver.cpp:112] Iteration 13900, lr = 0.01
I0409 03:34:54.192620 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:56.071286 13743 solver.cpp:347] Iteration 14000, Testing net (#0)
I0409 03:34:56.371181 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:34:56.381378 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.29179 (* 1 = 1.29179 loss)
I0409 03:34:56.381408 13743 solver.cpp:414]     Test net output #1: accuracy = 0.511998
I0409 03:34:56.398789 13743 solver.cpp:239] Iteration 14000 (44.8739 iter/s, 2.22847s/100 iters), loss = 1.33734
I0409 03:34:56.398836 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.33734 (* 1 = 1.33734 loss)
I0409 03:34:56.398847 13743 sgd_solver.cpp:112] Iteration 14000, lr = 0.01
I0409 03:34:58.315831 13743 solver.cpp:239] Iteration 14100 (52.1654 iter/s, 1.91698s/100 iters), loss = 1.071
I0409 03:34:58.315954 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.071 (* 1 = 1.071 loss)
I0409 03:34:58.315984 13743 sgd_solver.cpp:112] Iteration 14100, lr = 0.01
I0409 03:35:00.228947 13743 solver.cpp:239] Iteration 14200 (52.2741 iter/s, 1.91299s/100 iters), loss = 1.22792
I0409 03:35:00.229019 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.22792 (* 1 = 1.22792 loss)
I0409 03:35:00.229028 13743 sgd_solver.cpp:112] Iteration 14200, lr = 0.01
I0409 03:35:02.140869 13743 solver.cpp:239] Iteration 14300 (52.3054 iter/s, 1.91185s/100 iters), loss = 1.48173
I0409 03:35:02.140952 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.48173 (* 1 = 1.48173 loss)
I0409 03:35:02.140961 13743 sgd_solver.cpp:112] Iteration 14300, lr = 0.01
I0409 03:35:03.105756 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:04.058035 13743 solver.cpp:239] Iteration 14400 (52.1625 iter/s, 1.91709s/100 iters), loss = 1.08369
I0409 03:35:04.058094 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.08369 (* 1 = 1.08369 loss)
I0409 03:35:04.058102 13743 sgd_solver.cpp:112] Iteration 14400, lr = 0.01
I0409 03:35:05.974817 13743 solver.cpp:239] Iteration 14500 (52.1729 iter/s, 1.9167s/100 iters), loss = 1.12677
I0409 03:35:05.974912 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.12677 (* 1 = 1.12677 loss)
I0409 03:35:05.974927 13743 sgd_solver.cpp:112] Iteration 14500, lr = 0.01
I0409 03:35:07.895609 13743 solver.cpp:239] Iteration 14600 (52.064 iter/s, 1.92071s/100 iters), loss = 1.40294
I0409 03:35:07.895746 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.40294 (* 1 = 1.40294 loss)
I0409 03:35:07.895756 13743 sgd_solver.cpp:112] Iteration 14600, lr = 0.01
I0409 03:35:09.816665 13743 solver.cpp:239] Iteration 14700 (52.0579 iter/s, 1.92094s/100 iters), loss = 1.29629
I0409 03:35:09.816723 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.29629 (* 1 = 1.29629 loss)
I0409 03:35:09.816732 13743 sgd_solver.cpp:112] Iteration 14700, lr = 0.01
I0409 03:35:11.719064 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:11.735414 13743 solver.cpp:239] Iteration 14800 (52.1187 iter/s, 1.9187s/100 iters), loss = 1.09639
I0409 03:35:11.735461 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09639 (* 1 = 1.09639 loss)
I0409 03:35:11.735471 13743 sgd_solver.cpp:112] Iteration 14800, lr = 0.01
I0409 03:35:13.650017 13743 solver.cpp:239] Iteration 14900 (52.2315 iter/s, 1.91455s/100 iters), loss = 1.33022
I0409 03:35:13.650094 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.33022 (* 1 = 1.33022 loss)
I0409 03:35:13.650104 13743 sgd_solver.cpp:112] Iteration 14900, lr = 0.01
I0409 03:35:15.548741 13743 solver.cpp:347] Iteration 15000, Testing net (#0)
I0409 03:35:15.847625 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:15.857285 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.27381 (* 1 = 1.27381 loss)
I0409 03:35:15.857316 13743 solver.cpp:414]     Test net output #1: accuracy = 0.520368
I0409 03:35:15.874560 13743 solver.cpp:239] Iteration 15000 (44.9544 iter/s, 2.22448s/100 iters), loss = 0.994337
I0409 03:35:15.874609 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.994337 (* 1 = 0.994337 loss)
I0409 03:35:15.874619 13743 sgd_solver.cpp:112] Iteration 15000, lr = 0.01
I0409 03:35:17.795084 13743 solver.cpp:239] Iteration 15100 (52.0705 iter/s, 1.92047s/100 iters), loss = 1.20262
I0409 03:35:17.795161 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20262 (* 1 = 1.20262 loss)
I0409 03:35:17.795171 13743 sgd_solver.cpp:112] Iteration 15100, lr = 0.01
I0409 03:35:19.710924 13743 solver.cpp:239] Iteration 15200 (52.1986 iter/s, 1.91576s/100 iters), loss = 1.13351
I0409 03:35:19.711000 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13351 (* 1 = 1.13351 loss)
I0409 03:35:19.711009 13743 sgd_solver.cpp:112] Iteration 15200, lr = 0.01
I0409 03:35:20.607640 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:21.615834 13743 solver.cpp:239] Iteration 15300 (52.4979 iter/s, 1.90484s/100 iters), loss = 0.988309
I0409 03:35:21.615918 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.988309 (* 1 = 0.988309 loss)
I0409 03:35:21.615927 13743 sgd_solver.cpp:112] Iteration 15300, lr = 0.01
I0409 03:35:23.524582 13743 solver.cpp:239] Iteration 15400 (52.3927 iter/s, 1.90866s/100 iters), loss = 1.16254
I0409 03:35:23.524648 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.16254 (* 1 = 1.16254 loss)
I0409 03:35:23.524659 13743 sgd_solver.cpp:112] Iteration 15400, lr = 0.01
I0409 03:35:25.434903 13743 solver.cpp:239] Iteration 15500 (52.3491 iter/s, 1.91025s/100 iters), loss = 1.35087
I0409 03:35:25.434973 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.35087 (* 1 = 1.35087 loss)
I0409 03:35:25.434983 13743 sgd_solver.cpp:112] Iteration 15500, lr = 0.01
I0409 03:35:27.338893 13743 solver.cpp:239] Iteration 15600 (52.5237 iter/s, 1.9039s/100 iters), loss = 0.98705
I0409 03:35:27.338961 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.98705 (* 1 = 0.98705 loss)
I0409 03:35:27.338969 13743 sgd_solver.cpp:112] Iteration 15600, lr = 0.01
I0409 03:35:29.174854 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:29.248193 13743 solver.cpp:239] Iteration 15700 (52.377 iter/s, 1.90924s/100 iters), loss = 1.45443
I0409 03:35:29.248252 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.45443 (* 1 = 1.45443 loss)
I0409 03:35:29.248261 13743 sgd_solver.cpp:112] Iteration 15700, lr = 0.01
I0409 03:35:31.161015 13743 solver.cpp:239] Iteration 15800 (52.2804 iter/s, 1.91276s/100 iters), loss = 1.19815
I0409 03:35:31.161090 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19815 (* 1 = 1.19815 loss)
I0409 03:35:31.161099 13743 sgd_solver.cpp:112] Iteration 15800, lr = 0.01
I0409 03:35:33.077641 13743 solver.cpp:239] Iteration 15900 (52.177 iter/s, 1.91655s/100 iters), loss = 1.28442
I0409 03:35:33.077704 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.28442 (* 1 = 1.28442 loss)
I0409 03:35:33.077713 13743 sgd_solver.cpp:112] Iteration 15900, lr = 0.01
I0409 03:35:34.981290 13743 solver.cpp:347] Iteration 16000, Testing net (#0)
I0409 03:35:35.281915 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:35.292277 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.37433 (* 1 = 1.37433 loss)
I0409 03:35:35.292315 13743 solver.cpp:414]     Test net output #1: accuracy = 0.494699
I0409 03:35:35.309767 13743 solver.cpp:239] Iteration 16000 (44.8014 iter/s, 2.23207s/100 iters), loss = 1.37278
I0409 03:35:35.309809 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.37278 (* 1 = 1.37278 loss)
I0409 03:35:35.309820 13743 sgd_solver.cpp:112] Iteration 16000, lr = 0.01
I0409 03:35:37.222558 13743 solver.cpp:239] Iteration 16100 (52.2809 iter/s, 1.91275s/100 iters), loss = 1.34052
I0409 03:35:37.222666 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.34052 (* 1 = 1.34052 loss)
I0409 03:35:37.222674 13743 sgd_solver.cpp:112] Iteration 16100, lr = 0.01
I0409 03:35:38.068375 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:39.136240 13743 solver.cpp:239] Iteration 16200 (52.2582 iter/s, 1.91358s/100 iters), loss = 1.31917
I0409 03:35:39.136312 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.31917 (* 1 = 1.31917 loss)
I0409 03:35:39.136322 13743 sgd_solver.cpp:112] Iteration 16200, lr = 0.01
I0409 03:35:41.045473 13743 solver.cpp:239] Iteration 16300 (52.379 iter/s, 1.90916s/100 iters), loss = 1.01133
I0409 03:35:41.045557 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01133 (* 1 = 1.01133 loss)
I0409 03:35:41.045564 13743 sgd_solver.cpp:112] Iteration 16300, lr = 0.01
I0409 03:35:42.965190 13743 solver.cpp:239] Iteration 16400 (52.0937 iter/s, 1.91962s/100 iters), loss = 1.28923
I0409 03:35:42.965272 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.28923 (* 1 = 1.28923 loss)
I0409 03:35:42.965281 13743 sgd_solver.cpp:112] Iteration 16400, lr = 0.01
I0409 03:35:44.881266 13743 solver.cpp:239] Iteration 16500 (52.1923 iter/s, 1.91599s/100 iters), loss = 1.19552
I0409 03:35:44.881340 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19552 (* 1 = 1.19552 loss)
I0409 03:35:44.881348 13743 sgd_solver.cpp:112] Iteration 16500, lr = 0.01
I0409 03:35:46.665067 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:46.795439 13743 solver.cpp:239] Iteration 16600 (52.2443 iter/s, 1.91409s/100 iters), loss = 1.08958
I0409 03:35:46.795529 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.08958 (* 1 = 1.08958 loss)
I0409 03:35:46.795542 13743 sgd_solver.cpp:112] Iteration 16600, lr = 0.01
I0409 03:35:48.714820 13743 solver.cpp:239] Iteration 16700 (52.1024 iter/s, 1.9193s/100 iters), loss = 1.14388
I0409 03:35:48.714887 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14388 (* 1 = 1.14388 loss)
I0409 03:35:48.714896 13743 sgd_solver.cpp:112] Iteration 16700, lr = 0.01
I0409 03:35:50.631300 13743 solver.cpp:239] Iteration 16800 (52.1808 iter/s, 1.91641s/100 iters), loss = 1.2941
I0409 03:35:50.631362 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.2941 (* 1 = 1.2941 loss)
I0409 03:35:50.631373 13743 sgd_solver.cpp:112] Iteration 16800, lr = 0.01
I0409 03:35:52.544621 13743 solver.cpp:239] Iteration 16900 (52.2672 iter/s, 1.91324s/100 iters), loss = 1.22902
I0409 03:35:52.544699 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.22902 (* 1 = 1.22902 loss)
I0409 03:35:52.544708 13743 sgd_solver.cpp:112] Iteration 16900, lr = 0.01
I0409 03:35:54.441170 13743 solver.cpp:347] Iteration 17000, Testing net (#0)
I0409 03:35:54.741680 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:54.752534 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.23644 (* 1 = 1.23644 loss)
I0409 03:35:54.752565 13743 solver.cpp:414]     Test net output #1: accuracy = 0.521205
I0409 03:35:54.769955 13743 solver.cpp:239] Iteration 17000 (44.9384 iter/s, 2.22527s/100 iters), loss = 1.29625
I0409 03:35:54.770002 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.29625 (* 1 = 1.29625 loss)
I0409 03:35:54.770015 13743 sgd_solver.cpp:112] Iteration 17000, lr = 0.01
I0409 03:35:55.563940 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:35:56.689340 13743 solver.cpp:239] Iteration 17100 (52.1013 iter/s, 1.91934s/100 iters), loss = 1.43523
I0409 03:35:56.689399 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.43523 (* 1 = 1.43523 loss)
I0409 03:35:56.689409 13743 sgd_solver.cpp:112] Iteration 17100, lr = 0.01
I0409 03:35:58.606032 13743 solver.cpp:239] Iteration 17200 (52.1753 iter/s, 1.91662s/100 iters), loss = 0.987513
I0409 03:35:58.606168 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.987513 (* 1 = 0.987513 loss)
I0409 03:35:58.606191 13743 sgd_solver.cpp:112] Iteration 17200, lr = 0.01
I0409 03:36:00.526129 13743 solver.cpp:239] Iteration 17300 (52.0843 iter/s, 1.91996s/100 iters), loss = 1.14086
I0409 03:36:00.526204 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14086 (* 1 = 1.14086 loss)
I0409 03:36:00.526213 13743 sgd_solver.cpp:112] Iteration 17300, lr = 0.01
I0409 03:36:02.442947 13743 solver.cpp:239] Iteration 17400 (52.1718 iter/s, 1.91674s/100 iters), loss = 1.28156
I0409 03:36:02.443012 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.28156 (* 1 = 1.28156 loss)
I0409 03:36:02.443020 13743 sgd_solver.cpp:112] Iteration 17400, lr = 0.01
I0409 03:36:04.175312 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:04.364562 13743 solver.cpp:239] Iteration 17500 (52.0413 iter/s, 1.92155s/100 iters), loss = 1.35253
I0409 03:36:04.364632 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.35253 (* 1 = 1.35253 loss)
I0409 03:36:04.364643 13743 sgd_solver.cpp:112] Iteration 17500, lr = 0.01
I0409 03:36:06.278424 13743 solver.cpp:239] Iteration 17600 (52.2523 iter/s, 1.91379s/100 iters), loss = 1.57512
I0409 03:36:06.278489 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.57512 (* 1 = 1.57512 loss)
I0409 03:36:06.278498 13743 sgd_solver.cpp:112] Iteration 17600, lr = 0.01
I0409 03:36:08.198747 13743 solver.cpp:239] Iteration 17700 (52.0763 iter/s, 1.92026s/100 iters), loss = 1.50665
I0409 03:36:08.198832 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.50665 (* 1 = 1.50665 loss)
I0409 03:36:08.198858 13743 sgd_solver.cpp:112] Iteration 17700, lr = 0.01
I0409 03:36:10.117333 13743 solver.cpp:239] Iteration 17800 (52.1235 iter/s, 1.91852s/100 iters), loss = 1.32586
I0409 03:36:10.117408 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.32586 (* 1 = 1.32586 loss)
I0409 03:36:10.117417 13743 sgd_solver.cpp:112] Iteration 17800, lr = 0.01
I0409 03:36:12.032474 13743 solver.cpp:239] Iteration 17900 (52.2175 iter/s, 1.91507s/100 iters), loss = 1.26569
I0409 03:36:12.032541 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.26569 (* 1 = 1.26569 loss)
I0409 03:36:12.032549 13743 sgd_solver.cpp:112] Iteration 17900, lr = 0.01
I0409 03:36:12.781903 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:13.932519 13743 solver.cpp:347] Iteration 18000, Testing net (#0)
I0409 03:36:14.233506 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:14.244060 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.30675 (* 1 = 1.30675 loss)
I0409 03:36:14.244089 13743 solver.cpp:414]     Test net output #1: accuracy = 0.526507
I0409 03:36:14.261363 13743 solver.cpp:239] Iteration 18000 (44.8665 iter/s, 2.22883s/100 iters), loss = 1.18381
I0409 03:36:14.261405 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.18381 (* 1 = 1.18381 loss)
I0409 03:36:14.261416 13743 sgd_solver.cpp:112] Iteration 18000, lr = 0.01
I0409 03:36:16.183897 13743 solver.cpp:239] Iteration 18100 (52.0159 iter/s, 1.92249s/100 iters), loss = 1.17023
I0409 03:36:16.184005 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.17023 (* 1 = 1.17023 loss)
I0409 03:36:16.184013 13743 sgd_solver.cpp:112] Iteration 18100, lr = 0.01
I0409 03:36:18.096101 13743 solver.cpp:239] Iteration 18200 (52.2984 iter/s, 1.91211s/100 iters), loss = 1.35543
I0409 03:36:18.096180 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.35543 (* 1 = 1.35543 loss)
I0409 03:36:18.096191 13743 sgd_solver.cpp:112] Iteration 18200, lr = 0.01
I0409 03:36:20.009446 13743 solver.cpp:239] Iteration 18300 (52.2666 iter/s, 1.91327s/100 iters), loss = 1.20474
I0409 03:36:20.009518 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20474 (* 1 = 1.20474 loss)
I0409 03:36:20.009528 13743 sgd_solver.cpp:112] Iteration 18300, lr = 0.01
I0409 03:36:21.683420 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:21.928489 13743 solver.cpp:239] Iteration 18400 (52.1111 iter/s, 1.91898s/100 iters), loss = 1.33291
I0409 03:36:21.928558 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.33291 (* 1 = 1.33291 loss)
I0409 03:36:21.928567 13743 sgd_solver.cpp:112] Iteration 18400, lr = 0.01
I0409 03:36:23.850472 13743 solver.cpp:239] Iteration 18500 (52.0314 iter/s, 1.92192s/100 iters), loss = 1.2943
I0409 03:36:23.850539 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.2943 (* 1 = 1.2943 loss)
I0409 03:36:23.850548 13743 sgd_solver.cpp:112] Iteration 18500, lr = 0.01
I0409 03:36:25.769146 13743 solver.cpp:239] Iteration 18600 (52.1215 iter/s, 1.9186s/100 iters), loss = 1.4254
I0409 03:36:25.769207 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.4254 (* 1 = 1.4254 loss)
I0409 03:36:25.769217 13743 sgd_solver.cpp:112] Iteration 18600, lr = 0.01
I0409 03:36:27.688050 13743 solver.cpp:239] Iteration 18700 (52.1148 iter/s, 1.91884s/100 iters), loss = 1.15569
I0409 03:36:27.688125 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.15569 (* 1 = 1.15569 loss)
I0409 03:36:27.688134 13743 sgd_solver.cpp:112] Iteration 18700, lr = 0.01
I0409 03:36:29.605023 13743 solver.cpp:239] Iteration 18800 (52.1677 iter/s, 1.9169s/100 iters), loss = 1.19427
I0409 03:36:29.605146 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19427 (* 1 = 1.19427 loss)
I0409 03:36:29.605159 13743 sgd_solver.cpp:112] Iteration 18800, lr = 0.01
I0409 03:36:30.301931 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:31.526509 13743 solver.cpp:239] Iteration 18900 (52.0467 iter/s, 1.92135s/100 iters), loss = 1.33263
I0409 03:36:31.526592 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.33263 (* 1 = 1.33263 loss)
I0409 03:36:31.526602 13743 sgd_solver.cpp:112] Iteration 18900, lr = 0.01
I0409 03:36:33.424532 13743 solver.cpp:347] Iteration 19000, Testing net (#0)
I0409 03:36:33.724491 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:33.735451 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.26825 (* 1 = 1.26825 loss)
I0409 03:36:33.735481 13743 solver.cpp:414]     Test net output #1: accuracy = 0.520647
I0409 03:36:33.752888 13743 solver.cpp:239] Iteration 19000 (44.9174 iter/s, 2.22631s/100 iters), loss = 1.20171
I0409 03:36:33.752933 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20171 (* 1 = 1.20171 loss)
I0409 03:36:33.752948 13743 sgd_solver.cpp:112] Iteration 19000, lr = 0.01
I0409 03:36:35.667376 13743 solver.cpp:239] Iteration 19100 (52.2348 iter/s, 1.91443s/100 iters), loss = 1.16913
I0409 03:36:35.667440 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.16913 (* 1 = 1.16913 loss)
I0409 03:36:35.667448 13743 sgd_solver.cpp:112] Iteration 19100, lr = 0.01
I0409 03:36:37.586047 13743 solver.cpp:239] Iteration 19200 (52.1212 iter/s, 1.9186s/100 iters), loss = 1.21307
I0409 03:36:37.586124 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.21307 (* 1 = 1.21307 loss)
I0409 03:36:37.586133 13743 sgd_solver.cpp:112] Iteration 19200, lr = 0.01
I0409 03:36:39.201325 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:39.503679 13743 solver.cpp:239] Iteration 19300 (52.1498 iter/s, 1.91755s/100 iters), loss = 1.05098
I0409 03:36:39.503762 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05098 (* 1 = 1.05098 loss)
I0409 03:36:39.503772 13743 sgd_solver.cpp:112] Iteration 19300, lr = 0.01
I0409 03:36:41.419708 13743 solver.cpp:239] Iteration 19400 (52.1938 iter/s, 1.91594s/100 iters), loss = 1.236
I0409 03:36:41.419785 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.236 (* 1 = 1.236 loss)
I0409 03:36:41.419793 13743 sgd_solver.cpp:112] Iteration 19400, lr = 0.01
I0409 03:36:43.338753 13743 solver.cpp:239] Iteration 19500 (52.1113 iter/s, 1.91897s/100 iters), loss = 1.21116
I0409 03:36:43.338834 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.21116 (* 1 = 1.21116 loss)
I0409 03:36:43.338842 13743 sgd_solver.cpp:112] Iteration 19500, lr = 0.01
I0409 03:36:45.257169 13743 solver.cpp:239] Iteration 19600 (52.1285 iter/s, 1.91834s/100 iters), loss = 0.845078
I0409 03:36:45.257257 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.845078 (* 1 = 0.845078 loss)
I0409 03:36:45.257269 13743 sgd_solver.cpp:112] Iteration 19600, lr = 0.01
I0409 03:36:47.172628 13743 solver.cpp:239] Iteration 19700 (52.2091 iter/s, 1.91537s/100 iters), loss = 1.071
I0409 03:36:47.172698 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.071 (* 1 = 1.071 loss)
I0409 03:36:47.172709 13743 sgd_solver.cpp:112] Iteration 19700, lr = 0.01
I0409 03:36:47.809614 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:49.088562 13743 solver.cpp:239] Iteration 19800 (52.1957 iter/s, 1.91587s/100 iters), loss = 1.06868
I0409 03:36:49.088626 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06868 (* 1 = 1.06868 loss)
I0409 03:36:49.088635 13743 sgd_solver.cpp:112] Iteration 19800, lr = 0.01
I0409 03:36:51.008821 13743 solver.cpp:239] Iteration 19900 (52.0783 iter/s, 1.92019s/100 iters), loss = 1.20431
I0409 03:36:51.008920 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20431 (* 1 = 1.20431 loss)
I0409 03:36:51.008930 13743 sgd_solver.cpp:112] Iteration 19900, lr = 0.01
I0409 03:36:52.907161 13743 solver.cpp:464] Snapshotting to binary proto file ./FaceEmotionNet_model_iter_20000.caffemodel
I0409 03:36:52.989500 13743 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./FaceEmotionNet_model_iter_20000.solverstate
I0409 03:36:53.034013 13743 solver.cpp:347] Iteration 20000, Testing net (#0)
I0409 03:36:53.329190 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:53.339617 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.21127 (* 1 = 1.21127 loss)
I0409 03:36:53.339645 13743 solver.cpp:414]     Test net output #1: accuracy = 0.5399
I0409 03:36:53.356662 13743 solver.cpp:239] Iteration 20000 (42.5939 iter/s, 2.34775s/100 iters), loss = 1.1542
I0409 03:36:53.356704 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.1542 (* 1 = 1.1542 loss)
I0409 03:36:53.356714 13743 sgd_solver.cpp:112] Iteration 20000, lr = 0.001
I0409 03:36:55.270352 13743 solver.cpp:239] Iteration 20100 (52.2563 iter/s, 1.91365s/100 iters), loss = 1.3071
I0409 03:36:55.270442 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.3071 (* 1 = 1.3071 loss)
I0409 03:36:55.270450 13743 sgd_solver.cpp:112] Iteration 20100, lr = 0.001
I0409 03:36:56.847357 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:36:57.187080 13743 solver.cpp:239] Iteration 20200 (52.1746 iter/s, 1.91664s/100 iters), loss = 1.14169
I0409 03:36:57.187150 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14169 (* 1 = 1.14169 loss)
I0409 03:36:57.187160 13743 sgd_solver.cpp:112] Iteration 20200, lr = 0.001
I0409 03:36:59.102736 13743 solver.cpp:239] Iteration 20300 (52.2032 iter/s, 1.91559s/100 iters), loss = 1.03095
I0409 03:36:59.102838 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03095 (* 1 = 1.03095 loss)
I0409 03:36:59.102849 13743 sgd_solver.cpp:112] Iteration 20300, lr = 0.001
I0409 03:37:01.020676 13743 solver.cpp:239] Iteration 20400 (52.1416 iter/s, 1.91786s/100 iters), loss = 1.30085
I0409 03:37:01.020740 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.30085 (* 1 = 1.30085 loss)
I0409 03:37:01.020750 13743 sgd_solver.cpp:112] Iteration 20400, lr = 0.001
I0409 03:37:02.937053 13743 solver.cpp:239] Iteration 20500 (52.1836 iter/s, 1.91631s/100 iters), loss = 1.20284
I0409 03:37:02.937139 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20284 (* 1 = 1.20284 loss)
I0409 03:37:02.937149 13743 sgd_solver.cpp:112] Iteration 20500, lr = 0.001
I0409 03:37:04.852062 13743 solver.cpp:239] Iteration 20600 (52.2211 iter/s, 1.91493s/100 iters), loss = 1.13379
I0409 03:37:04.852130 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13379 (* 1 = 1.13379 loss)
I0409 03:37:04.852139 13743 sgd_solver.cpp:112] Iteration 20600, lr = 0.001
I0409 03:37:05.434377 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:06.776227 13743 solver.cpp:239] Iteration 20700 (51.9725 iter/s, 1.9241s/100 iters), loss = 1.08236
I0409 03:37:06.776298 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.08236 (* 1 = 1.08236 loss)
I0409 03:37:06.776314 13743 sgd_solver.cpp:112] Iteration 20700, lr = 0.001
I0409 03:37:08.691254 13743 solver.cpp:239] Iteration 20800 (52.2206 iter/s, 1.91495s/100 iters), loss = 1.21834
I0409 03:37:08.691314 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.21834 (* 1 = 1.21834 loss)
I0409 03:37:08.691323 13743 sgd_solver.cpp:112] Iteration 20800, lr = 0.001
I0409 03:37:10.607455 13743 solver.cpp:239] Iteration 20900 (52.1883 iter/s, 1.91614s/100 iters), loss = 1.15198
I0409 03:37:10.607537 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.15198 (* 1 = 1.15198 loss)
I0409 03:37:10.607547 13743 sgd_solver.cpp:112] Iteration 20900, lr = 0.001
I0409 03:37:12.498317 13743 solver.cpp:347] Iteration 21000, Testing net (#0)
I0409 03:37:12.798858 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:12.808605 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.12573 (* 1 = 1.12573 loss)
I0409 03:37:12.808635 13743 solver.cpp:414]     Test net output #1: accuracy = 0.573382
I0409 03:37:12.825521 13743 solver.cpp:239] Iteration 21000 (45.0857 iter/s, 2.218s/100 iters), loss = 1.10812
I0409 03:37:12.825565 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10812 (* 1 = 1.10812 loss)
I0409 03:37:12.825575 13743 sgd_solver.cpp:112] Iteration 21000, lr = 0.001
I0409 03:37:14.337169 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:14.733175 13743 solver.cpp:239] Iteration 21100 (52.4216 iter/s, 1.90761s/100 iters), loss = 0.927554
I0409 03:37:14.733245 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.927554 (* 1 = 0.927554 loss)
I0409 03:37:14.733254 13743 sgd_solver.cpp:112] Iteration 21100, lr = 0.001
I0409 03:37:16.646704 13743 solver.cpp:239] Iteration 21200 (52.2613 iter/s, 1.91346s/100 iters), loss = 0.889786
I0409 03:37:16.646773 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.889786 (* 1 = 0.889786 loss)
I0409 03:37:16.646781 13743 sgd_solver.cpp:112] Iteration 21200, lr = 0.001
I0409 03:37:18.565172 13743 solver.cpp:239] Iteration 21300 (52.1281 iter/s, 1.91835s/100 iters), loss = 0.922499
I0409 03:37:18.565263 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.922499 (* 1 = 0.922499 loss)
I0409 03:37:18.565273 13743 sgd_solver.cpp:112] Iteration 21300, lr = 0.001
I0409 03:37:20.486894 13743 solver.cpp:239] Iteration 21400 (52.039 iter/s, 1.92164s/100 iters), loss = 1.00947
I0409 03:37:20.486961 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00947 (* 1 = 1.00947 loss)
I0409 03:37:20.486969 13743 sgd_solver.cpp:112] Iteration 21400, lr = 0.001
I0409 03:37:22.404603 13743 solver.cpp:239] Iteration 21500 (52.1476 iter/s, 1.91763s/100 iters), loss = 1.36506
I0409 03:37:22.404670 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.36506 (* 1 = 1.36506 loss)
I0409 03:37:22.404680 13743 sgd_solver.cpp:112] Iteration 21500, lr = 0.001
I0409 03:37:22.926332 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:24.318567 13743 solver.cpp:239] Iteration 21600 (52.2495 iter/s, 1.91389s/100 iters), loss = 1.16713
I0409 03:37:24.318642 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.16713 (* 1 = 1.16713 loss)
I0409 03:37:24.318651 13743 sgd_solver.cpp:112] Iteration 21600, lr = 0.001
I0409 03:37:26.233173 13743 solver.cpp:239] Iteration 21700 (52.2326 iter/s, 1.91451s/100 iters), loss = 1.12965
I0409 03:37:26.233264 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.12965 (* 1 = 1.12965 loss)
I0409 03:37:26.233304 13743 sgd_solver.cpp:112] Iteration 21700, lr = 0.001
I0409 03:37:28.146714 13743 solver.cpp:239] Iteration 21800 (52.2616 iter/s, 1.91345s/100 iters), loss = 1.42992
I0409 03:37:28.146792 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.42992 (* 1 = 1.42992 loss)
I0409 03:37:28.146801 13743 sgd_solver.cpp:112] Iteration 21800, lr = 0.001
I0409 03:37:30.065832 13743 solver.cpp:239] Iteration 21900 (52.1094 iter/s, 1.91904s/100 iters), loss = 1.1104
I0409 03:37:30.065922 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.1104 (* 1 = 1.1104 loss)
I0409 03:37:30.065930 13743 sgd_solver.cpp:112] Iteration 21900, lr = 0.001
I0409 03:37:31.527513 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:31.966681 13743 solver.cpp:347] Iteration 22000, Testing net (#0)
I0409 03:37:32.267608 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:32.276202 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.13597 (* 1 = 1.13597 loss)
I0409 03:37:32.276237 13743 solver.cpp:414]     Test net output #1: accuracy = 0.57115
I0409 03:37:32.293445 13743 solver.cpp:239] Iteration 22000 (44.893 iter/s, 2.22752s/100 iters), loss = 1.09535
I0409 03:37:32.293560 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09535 (* 1 = 1.09535 loss)
I0409 03:37:32.293570 13743 sgd_solver.cpp:112] Iteration 22000, lr = 0.001
I0409 03:37:34.211432 13743 solver.cpp:239] Iteration 22100 (52.1407 iter/s, 1.91789s/100 iters), loss = 1.21372
I0409 03:37:34.211513 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.21372 (* 1 = 1.21372 loss)
I0409 03:37:34.211524 13743 sgd_solver.cpp:112] Iteration 22100, lr = 0.001
I0409 03:37:36.121726 13743 solver.cpp:239] Iteration 22200 (52.3501 iter/s, 1.91022s/100 iters), loss = 0.957228
I0409 03:37:36.121788 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.957228 (* 1 = 0.957228 loss)
I0409 03:37:36.121796 13743 sgd_solver.cpp:112] Iteration 22200, lr = 0.001
I0409 03:37:38.033879 13743 solver.cpp:239] Iteration 22300 (52.299 iter/s, 1.91208s/100 iters), loss = 1.04888
I0409 03:37:38.033952 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04888 (* 1 = 1.04888 loss)
I0409 03:37:38.033962 13743 sgd_solver.cpp:112] Iteration 22300, lr = 0.001
I0409 03:37:39.948920 13743 solver.cpp:239] Iteration 22400 (52.2201 iter/s, 1.91497s/100 iters), loss = 1.37741
I0409 03:37:39.949021 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.37741 (* 1 = 1.37741 loss)
I0409 03:37:39.949030 13743 sgd_solver.cpp:112] Iteration 22400, lr = 0.001
I0409 03:37:40.413914 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:41.865576 13743 solver.cpp:239] Iteration 22500 (52.1769 iter/s, 1.91656s/100 iters), loss = 0.6636
I0409 03:37:41.865671 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.6636 (* 1 = 0.6636 loss)
I0409 03:37:41.865696 13743 sgd_solver.cpp:112] Iteration 22500, lr = 0.001
I0409 03:37:43.776753 13743 solver.cpp:239] Iteration 22600 (52.3264 iter/s, 1.91108s/100 iters), loss = 0.953697
I0409 03:37:43.776832 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.953697 (* 1 = 0.953697 loss)
I0409 03:37:43.776841 13743 sgd_solver.cpp:112] Iteration 22600, lr = 0.001
I0409 03:37:45.696266 13743 solver.cpp:239] Iteration 22700 (52.0986 iter/s, 1.91944s/100 iters), loss = 1.03223
I0409 03:37:45.696343 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03223 (* 1 = 1.03223 loss)
I0409 03:37:45.696352 13743 sgd_solver.cpp:112] Iteration 22700, lr = 0.001
I0409 03:37:47.616037 13743 solver.cpp:239] Iteration 22800 (52.0916 iter/s, 1.9197s/100 iters), loss = 0.840499
I0409 03:37:47.616109 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.840499 (* 1 = 0.840499 loss)
I0409 03:37:47.616118 13743 sgd_solver.cpp:112] Iteration 22800, lr = 0.001
I0409 03:37:49.021103 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:49.535411 13743 solver.cpp:239] Iteration 22900 (52.1027 iter/s, 1.91929s/100 iters), loss = 1.15406
I0409 03:37:49.535501 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.15406 (* 1 = 1.15406 loss)
I0409 03:37:49.535511 13743 sgd_solver.cpp:112] Iteration 22900, lr = 0.001
I0409 03:37:51.438377 13743 solver.cpp:347] Iteration 23000, Testing net (#0)
I0409 03:37:51.737037 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:51.747162 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.13853 (* 1 = 1.13853 loss)
I0409 03:37:51.747201 13743 solver.cpp:414]     Test net output #1: accuracy = 0.574498
I0409 03:37:51.764613 13743 solver.cpp:239] Iteration 23000 (44.8609 iter/s, 2.22911s/100 iters), loss = 1.2419
I0409 03:37:51.764654 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.2419 (* 1 = 1.2419 loss)
I0409 03:37:51.764679 13743 sgd_solver.cpp:112] Iteration 23000, lr = 0.001
I0409 03:37:53.685580 13743 solver.cpp:239] Iteration 23100 (52.0584 iter/s, 1.92092s/100 iters), loss = 1.14164
I0409 03:37:53.685658 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14164 (* 1 = 1.14164 loss)
I0409 03:37:53.685683 13743 sgd_solver.cpp:112] Iteration 23100, lr = 0.001
I0409 03:37:55.602147 13743 solver.cpp:239] Iteration 23200 (52.1787 iter/s, 1.91649s/100 iters), loss = 1.05951
I0409 03:37:55.602219 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05951 (* 1 = 1.05951 loss)
I0409 03:37:55.602228 13743 sgd_solver.cpp:112] Iteration 23200, lr = 0.001
I0409 03:37:57.515612 13743 solver.cpp:239] Iteration 23300 (52.2632 iter/s, 1.91339s/100 iters), loss = 1.09957
I0409 03:37:57.515686 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09957 (* 1 = 1.09957 loss)
I0409 03:37:57.515696 13743 sgd_solver.cpp:112] Iteration 23300, lr = 0.001
I0409 03:37:57.942795 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:37:59.432348 13743 solver.cpp:239] Iteration 23400 (52.174 iter/s, 1.91666s/100 iters), loss = 1.03569
I0409 03:37:59.432410 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03569 (* 1 = 1.03569 loss)
I0409 03:37:59.432418 13743 sgd_solver.cpp:112] Iteration 23400, lr = 0.001
I0409 03:38:01.354682 13743 solver.cpp:239] Iteration 23500 (52.0218 iter/s, 1.92227s/100 iters), loss = 0.841755
I0409 03:38:01.354760 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.841755 (* 1 = 0.841755 loss)
I0409 03:38:01.354769 13743 sgd_solver.cpp:112] Iteration 23500, lr = 0.001
I0409 03:38:03.271894 13743 solver.cpp:239] Iteration 23600 (52.1613 iter/s, 1.91713s/100 iters), loss = 1.00109
I0409 03:38:03.271957 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00109 (* 1 = 1.00109 loss)
I0409 03:38:03.271965 13743 sgd_solver.cpp:112] Iteration 23600, lr = 0.001
I0409 03:38:05.187834 13743 solver.cpp:239] Iteration 23700 (52.1954 iter/s, 1.91588s/100 iters), loss = 1.0351
I0409 03:38:05.187903 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.0351 (* 1 = 1.0351 loss)
I0409 03:38:05.187912 13743 sgd_solver.cpp:112] Iteration 23700, lr = 0.001
I0409 03:38:06.530258 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:07.101768 13743 solver.cpp:239] Iteration 23800 (52.2505 iter/s, 1.91386s/100 iters), loss = 1.04138
I0409 03:38:07.101830 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04138 (* 1 = 1.04138 loss)
I0409 03:38:07.101855 13743 sgd_solver.cpp:112] Iteration 23800, lr = 0.001
I0409 03:38:09.014190 13743 solver.cpp:239] Iteration 23900 (52.2914 iter/s, 1.91236s/100 iters), loss = 1.23209
I0409 03:38:09.014256 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.23209 (* 1 = 1.23209 loss)
I0409 03:38:09.014264 13743 sgd_solver.cpp:112] Iteration 23900, lr = 0.001
I0409 03:38:10.915243 13743 solver.cpp:347] Iteration 24000, Testing net (#0)
I0409 03:38:11.214946 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:11.224920 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.12718 (* 1 = 1.12718 loss)
I0409 03:38:11.224947 13743 solver.cpp:414]     Test net output #1: accuracy = 0.575893
I0409 03:38:11.242051 13743 solver.cpp:239] Iteration 24000 (44.8871 iter/s, 2.22781s/100 iters), loss = 0.97906
I0409 03:38:11.242101 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.97906 (* 1 = 0.97906 loss)
I0409 03:38:11.242115 13743 sgd_solver.cpp:112] Iteration 24000, lr = 0.001
I0409 03:38:13.154667 13743 solver.cpp:239] Iteration 24100 (52.2858 iter/s, 1.91256s/100 iters), loss = 0.935916
I0409 03:38:13.154742 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.935916 (* 1 = 0.935916 loss)
I0409 03:38:13.154750 13743 sgd_solver.cpp:112] Iteration 24100, lr = 0.001
I0409 03:38:15.073624 13743 solver.cpp:239] Iteration 24200 (52.1137 iter/s, 1.91888s/100 iters), loss = 1.14858
I0409 03:38:15.073707 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14858 (* 1 = 1.14858 loss)
I0409 03:38:15.073716 13743 sgd_solver.cpp:112] Iteration 24200, lr = 0.001
I0409 03:38:15.442384 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:16.994024 13743 solver.cpp:239] Iteration 24300 (52.0747 iter/s, 1.92032s/100 iters), loss = 1.09764
I0409 03:38:16.994087 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09764 (* 1 = 1.09764 loss)
I0409 03:38:16.994096 13743 sgd_solver.cpp:112] Iteration 24300, lr = 0.001
I0409 03:38:18.910109 13743 solver.cpp:239] Iteration 24400 (52.1917 iter/s, 1.91601s/100 iters), loss = 0.973619
I0409 03:38:18.910209 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.973619 (* 1 = 0.973619 loss)
I0409 03:38:18.910218 13743 sgd_solver.cpp:112] Iteration 24400, lr = 0.001
I0409 03:38:20.829411 13743 solver.cpp:239] Iteration 24500 (52.105 iter/s, 1.9192s/100 iters), loss = 0.914418
I0409 03:38:20.829474 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.914418 (* 1 = 0.914418 loss)
I0409 03:38:20.829483 13743 sgd_solver.cpp:112] Iteration 24500, lr = 0.001
I0409 03:38:22.748394 13743 solver.cpp:239] Iteration 24600 (52.1126 iter/s, 1.91892s/100 iters), loss = 0.9392
I0409 03:38:22.748467 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.9392 (* 1 = 0.9392 loss)
I0409 03:38:22.748476 13743 sgd_solver.cpp:112] Iteration 24600, lr = 0.001
I0409 03:38:24.034401 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:24.661995 13743 solver.cpp:239] Iteration 24700 (52.2594 iter/s, 1.91353s/100 iters), loss = 1.12552
I0409 03:38:24.662056 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.12552 (* 1 = 1.12552 loss)
I0409 03:38:24.662065 13743 sgd_solver.cpp:112] Iteration 24700, lr = 0.001
I0409 03:38:26.577231 13743 solver.cpp:239] Iteration 24800 (52.2145 iter/s, 1.91518s/100 iters), loss = 0.831227
I0409 03:38:26.577292 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.831227 (* 1 = 0.831227 loss)
I0409 03:38:26.577301 13743 sgd_solver.cpp:112] Iteration 24800, lr = 0.001
I0409 03:38:28.496266 13743 solver.cpp:239] Iteration 24900 (52.1116 iter/s, 1.91896s/100 iters), loss = 0.957016
I0409 03:38:28.496385 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.957016 (* 1 = 0.957016 loss)
I0409 03:38:28.496397 13743 sgd_solver.cpp:112] Iteration 24900, lr = 0.001
I0409 03:38:30.401665 13743 solver.cpp:347] Iteration 25000, Testing net (#0)
I0409 03:38:30.709944 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:30.714838 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.11425 (* 1 = 1.11425 loss)
I0409 03:38:30.714886 13743 solver.cpp:414]     Test net output #1: accuracy = 0.578683
I0409 03:38:30.732113 13743 solver.cpp:239] Iteration 25000 (44.7279 iter/s, 2.23574s/100 iters), loss = 1.05734
I0409 03:38:30.732156 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05734 (* 1 = 1.05734 loss)
I0409 03:38:30.732165 13743 sgd_solver.cpp:112] Iteration 25000, lr = 0.001
I0409 03:38:32.652119 13743 solver.cpp:239] Iteration 25100 (52.0843 iter/s, 1.91997s/100 iters), loss = 0.943834
I0409 03:38:32.652209 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.943834 (* 1 = 0.943834 loss)
I0409 03:38:32.652218 13743 sgd_solver.cpp:112] Iteration 25100, lr = 0.001
I0409 03:38:32.963796 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:34.572571 13743 solver.cpp:239] Iteration 25200 (52.0734 iter/s, 1.92037s/100 iters), loss = 0.943666
I0409 03:38:34.572631 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.943666 (* 1 = 0.943666 loss)
I0409 03:38:34.572640 13743 sgd_solver.cpp:112] Iteration 25200, lr = 0.001
I0409 03:38:36.493017 13743 solver.cpp:239] Iteration 25300 (52.0728 iter/s, 1.92039s/100 iters), loss = 1.28396
I0409 03:38:36.493077 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.28396 (* 1 = 1.28396 loss)
I0409 03:38:36.493084 13743 sgd_solver.cpp:112] Iteration 25300, lr = 0.001
I0409 03:38:38.409303 13743 solver.cpp:239] Iteration 25400 (52.1864 iter/s, 1.91621s/100 iters), loss = 0.789487
I0409 03:38:38.409373 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.789487 (* 1 = 0.789487 loss)
I0409 03:38:38.409399 13743 sgd_solver.cpp:112] Iteration 25400, lr = 0.001
I0409 03:38:40.327260 13743 solver.cpp:239] Iteration 25500 (52.1407 iter/s, 1.91789s/100 iters), loss = 1.13454
I0409 03:38:40.327330 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13454 (* 1 = 1.13454 loss)
I0409 03:38:40.327340 13743 sgd_solver.cpp:112] Iteration 25500, lr = 0.001
I0409 03:38:41.554906 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:42.240918 13743 solver.cpp:239] Iteration 25600 (52.2582 iter/s, 1.91358s/100 iters), loss = 1.01187
I0409 03:38:42.241011 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01187 (* 1 = 1.01187 loss)
I0409 03:38:42.241020 13743 sgd_solver.cpp:112] Iteration 25600, lr = 0.001
I0409 03:38:44.154119 13743 solver.cpp:239] Iteration 25700 (52.2711 iter/s, 1.9131s/100 iters), loss = 1.1039
I0409 03:38:44.154207 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.1039 (* 1 = 1.1039 loss)
I0409 03:38:44.154217 13743 sgd_solver.cpp:112] Iteration 25700, lr = 0.001
I0409 03:38:46.071974 13743 solver.cpp:239] Iteration 25800 (52.1439 iter/s, 1.91777s/100 iters), loss = 1.19547
I0409 03:38:46.072037 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19547 (* 1 = 1.19547 loss)
I0409 03:38:46.072047 13743 sgd_solver.cpp:112] Iteration 25800, lr = 0.001
I0409 03:38:47.989823 13743 solver.cpp:239] Iteration 25900 (52.1435 iter/s, 1.91779s/100 iters), loss = 0.945195
I0409 03:38:47.989899 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.945195 (* 1 = 0.945195 loss)
I0409 03:38:47.989909 13743 sgd_solver.cpp:112] Iteration 25900, lr = 0.001
I0409 03:38:49.888597 13743 solver.cpp:347] Iteration 26000, Testing net (#0)
I0409 03:38:50.191051 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:50.195744 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10727 (* 1 = 1.10727 loss)
I0409 03:38:50.195775 13743 solver.cpp:414]     Test net output #1: accuracy = 0.586775
I0409 03:38:50.212776 13743 solver.cpp:239] Iteration 26000 (44.9865 iter/s, 2.22289s/100 iters), loss = 1.09464
I0409 03:38:50.212819 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09464 (* 1 = 1.09464 loss)
I0409 03:38:50.212831 13743 sgd_solver.cpp:112] Iteration 26000, lr = 0.001
I0409 03:38:50.465381 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:52.129534 13743 solver.cpp:239] Iteration 26100 (52.1727 iter/s, 1.91671s/100 iters), loss = 0.939908
I0409 03:38:52.129609 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.939908 (* 1 = 0.939908 loss)
I0409 03:38:52.129618 13743 sgd_solver.cpp:112] Iteration 26100, lr = 0.001
I0409 03:38:54.041682 13743 solver.cpp:239] Iteration 26200 (52.2995 iter/s, 1.91206s/100 iters), loss = 0.919964
I0409 03:38:54.041756 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.919964 (* 1 = 0.919964 loss)
I0409 03:38:54.041765 13743 sgd_solver.cpp:112] Iteration 26200, lr = 0.001
I0409 03:38:55.953653 13743 solver.cpp:239] Iteration 26300 (52.304 iter/s, 1.9119s/100 iters), loss = 1.01259
I0409 03:38:55.953747 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01259 (* 1 = 1.01259 loss)
I0409 03:38:55.953757 13743 sgd_solver.cpp:112] Iteration 26300, lr = 0.001
I0409 03:38:57.870416 13743 solver.cpp:239] Iteration 26400 (52.1739 iter/s, 1.91667s/100 iters), loss = 1.06835
I0409 03:38:57.870482 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06835 (* 1 = 1.06835 loss)
I0409 03:38:57.870491 13743 sgd_solver.cpp:112] Iteration 26400, lr = 0.001
I0409 03:38:59.064538 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:38:59.787111 13743 solver.cpp:239] Iteration 26500 (52.175 iter/s, 1.91663s/100 iters), loss = 1.04983
I0409 03:38:59.787180 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04983 (* 1 = 1.04983 loss)
I0409 03:38:59.787204 13743 sgd_solver.cpp:112] Iteration 26500, lr = 0.001
I0409 03:39:01.703379 13743 solver.cpp:239] Iteration 26600 (52.1868 iter/s, 1.91619s/100 iters), loss = 0.913894
I0409 03:39:01.703477 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.913894 (* 1 = 0.913894 loss)
I0409 03:39:01.703486 13743 sgd_solver.cpp:112] Iteration 26600, lr = 0.001
I0409 03:39:03.619005 13743 solver.cpp:239] Iteration 26700 (52.2049 iter/s, 1.91553s/100 iters), loss = 0.843285
I0409 03:39:03.619081 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.843285 (* 1 = 0.843285 loss)
I0409 03:39:03.619089 13743 sgd_solver.cpp:112] Iteration 26700, lr = 0.001
I0409 03:39:05.541913 13743 solver.cpp:239] Iteration 26800 (52.0065 iter/s, 1.92284s/100 iters), loss = 0.745718
I0409 03:39:05.541976 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.745718 (* 1 = 0.745718 loss)
I0409 03:39:05.541985 13743 sgd_solver.cpp:112] Iteration 26800, lr = 0.001
I0409 03:39:07.460553 13743 solver.cpp:239] Iteration 26900 (52.1225 iter/s, 1.91856s/100 iters), loss = 0.973351
I0409 03:39:07.460680 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.973351 (* 1 = 0.973351 loss)
I0409 03:39:07.460690 13743 sgd_solver.cpp:112] Iteration 26900, lr = 0.001
I0409 03:39:07.654052 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:09.361388 13743 solver.cpp:347] Iteration 27000, Testing net (#0)
I0409 03:39:09.667573 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:09.672315 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.12551 (* 1 = 1.12551 loss)
I0409 03:39:09.672443 13743 solver.cpp:414]     Test net output #1: accuracy = 0.580357
I0409 03:39:09.689616 13743 solver.cpp:239] Iteration 27000 (44.8642 iter/s, 2.22895s/100 iters), loss = 1.13414
I0409 03:39:09.689657 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13414 (* 1 = 1.13414 loss)
I0409 03:39:09.689667 13743 sgd_solver.cpp:112] Iteration 27000, lr = 0.001
I0409 03:39:11.608072 13743 solver.cpp:239] Iteration 27100 (52.1264 iter/s, 1.91841s/100 iters), loss = 1.04398
I0409 03:39:11.608173 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04398 (* 1 = 1.04398 loss)
I0409 03:39:11.608183 13743 sgd_solver.cpp:112] Iteration 27100, lr = 0.001
I0409 03:39:13.525154 13743 solver.cpp:239] Iteration 27200 (52.1653 iter/s, 1.91698s/100 iters), loss = 1.01884
I0409 03:39:13.525218 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01884 (* 1 = 1.01884 loss)
I0409 03:39:13.525226 13743 sgd_solver.cpp:112] Iteration 27200, lr = 0.001
I0409 03:39:15.437667 13743 solver.cpp:239] Iteration 27300 (52.289 iter/s, 1.91245s/100 iters), loss = 0.92359
I0409 03:39:15.437746 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.92359 (* 1 = 0.92359 loss)
I0409 03:39:15.437753 13743 sgd_solver.cpp:112] Iteration 27300, lr = 0.001
I0409 03:39:16.570523 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:17.351398 13743 solver.cpp:239] Iteration 27400 (52.2562 iter/s, 1.91365s/100 iters), loss = 1.03693
I0409 03:39:17.351487 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03693 (* 1 = 1.03693 loss)
I0409 03:39:17.351516 13743 sgd_solver.cpp:112] Iteration 27400, lr = 0.001
I0409 03:39:19.274238 13743 solver.cpp:239] Iteration 27500 (52.0088 iter/s, 1.92275s/100 iters), loss = 1.07323
I0409 03:39:19.274304 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07323 (* 1 = 1.07323 loss)
I0409 03:39:19.274312 13743 sgd_solver.cpp:112] Iteration 27500, lr = 0.001
I0409 03:39:21.193480 13743 solver.cpp:239] Iteration 27600 (52.1057 iter/s, 1.91918s/100 iters), loss = 0.831106
I0409 03:39:21.193542 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.831106 (* 1 = 0.831106 loss)
I0409 03:39:21.193550 13743 sgd_solver.cpp:112] Iteration 27600, lr = 0.001
I0409 03:39:23.110730 13743 solver.cpp:239] Iteration 27700 (52.1597 iter/s, 1.91719s/100 iters), loss = 1.39627
I0409 03:39:23.110817 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.39627 (* 1 = 1.39627 loss)
I0409 03:39:23.110826 13743 sgd_solver.cpp:112] Iteration 27700, lr = 0.001
I0409 03:39:25.030861 13743 solver.cpp:239] Iteration 27800 (52.0822 iter/s, 1.92004s/100 iters), loss = 0.834575
I0409 03:39:25.030964 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.834575 (* 1 = 0.834575 loss)
I0409 03:39:25.030975 13743 sgd_solver.cpp:112] Iteration 27800, lr = 0.001
I0409 03:39:25.168468 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:26.947108 13743 solver.cpp:239] Iteration 27900 (52.188 iter/s, 1.91615s/100 iters), loss = 1.07557
I0409 03:39:26.947165 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07557 (* 1 = 1.07557 loss)
I0409 03:39:26.947172 13743 sgd_solver.cpp:112] Iteration 27900, lr = 0.001
I0409 03:39:28.848333 13743 solver.cpp:347] Iteration 28000, Testing net (#0)
I0409 03:39:29.151723 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:29.156435 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10528 (* 1 = 1.10528 loss)
I0409 03:39:29.156481 13743 solver.cpp:414]     Test net output #1: accuracy = 0.587054
I0409 03:39:29.173568 13743 solver.cpp:239] Iteration 28000 (44.9153 iter/s, 2.22641s/100 iters), loss = 0.935035
I0409 03:39:29.173658 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.935035 (* 1 = 0.935035 loss)
I0409 03:39:29.173669 13743 sgd_solver.cpp:112] Iteration 28000, lr = 0.001
I0409 03:39:31.088973 13743 solver.cpp:239] Iteration 28100 (52.2107 iter/s, 1.91532s/100 iters), loss = 0.983497
I0409 03:39:31.089040 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.983497 (* 1 = 0.983497 loss)
I0409 03:39:31.089051 13743 sgd_solver.cpp:112] Iteration 28100, lr = 0.001
I0409 03:39:33.008322 13743 solver.cpp:239] Iteration 28200 (52.1029 iter/s, 1.91928s/100 iters), loss = 0.844646
I0409 03:39:33.008411 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.844646 (* 1 = 0.844646 loss)
I0409 03:39:33.008421 13743 sgd_solver.cpp:112] Iteration 28200, lr = 0.001
I0409 03:39:34.086020 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:34.926551 13743 solver.cpp:239] Iteration 28300 (52.1339 iter/s, 1.91814s/100 iters), loss = 1.02801
I0409 03:39:34.926641 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.02801 (* 1 = 1.02801 loss)
I0409 03:39:34.926651 13743 sgd_solver.cpp:112] Iteration 28300, lr = 0.001
I0409 03:39:36.845963 13743 solver.cpp:239] Iteration 28400 (52.1017 iter/s, 1.91932s/100 iters), loss = 1.05404
I0409 03:39:36.846048 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05404 (* 1 = 1.05404 loss)
I0409 03:39:36.846057 13743 sgd_solver.cpp:112] Iteration 28400, lr = 0.001
I0409 03:39:38.765987 13743 solver.cpp:239] Iteration 28500 (52.0845 iter/s, 1.91996s/100 iters), loss = 1.07618
I0409 03:39:38.766052 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07618 (* 1 = 1.07618 loss)
I0409 03:39:38.766062 13743 sgd_solver.cpp:112] Iteration 28500, lr = 0.001
I0409 03:39:40.678727 13743 solver.cpp:239] Iteration 28600 (52.2827 iter/s, 1.91268s/100 iters), loss = 0.910725
I0409 03:39:40.678791 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.910725 (* 1 = 0.910725 loss)
I0409 03:39:40.678798 13743 sgd_solver.cpp:112] Iteration 28600, lr = 0.001
I0409 03:39:42.596259 13743 solver.cpp:239] Iteration 28700 (52.1522 iter/s, 1.91747s/100 iters), loss = 0.89413
I0409 03:39:42.596331 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.89413 (* 1 = 0.89413 loss)
I0409 03:39:42.596341 13743 sgd_solver.cpp:112] Iteration 28700, lr = 0.001
I0409 03:39:42.677459 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:44.512954 13743 solver.cpp:239] Iteration 28800 (52.1751 iter/s, 1.91662s/100 iters), loss = 0.92889
I0409 03:39:44.513031 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.92889 (* 1 = 0.92889 loss)
I0409 03:39:44.513039 13743 sgd_solver.cpp:112] Iteration 28800, lr = 0.001
I0409 03:39:46.429098 13743 solver.cpp:239] Iteration 28900 (52.1902 iter/s, 1.91607s/100 iters), loss = 1.07963
I0409 03:39:46.429185 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07963 (* 1 = 1.07963 loss)
I0409 03:39:46.429193 13743 sgd_solver.cpp:112] Iteration 28900, lr = 0.001
I0409 03:39:48.329960 13743 solver.cpp:347] Iteration 29000, Testing net (#0)
I0409 03:39:48.633392 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:48.638391 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.14357 (* 1 = 1.14357 loss)
I0409 03:39:48.638420 13743 solver.cpp:414]     Test net output #1: accuracy = 0.575056
I0409 03:39:48.655601 13743 solver.cpp:239] Iteration 29000 (44.915 iter/s, 2.22643s/100 iters), loss = 1.14334
I0409 03:39:48.655670 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14334 (* 1 = 1.14334 loss)
I0409 03:39:48.655684 13743 sgd_solver.cpp:112] Iteration 29000, lr = 0.001
I0409 03:39:50.570787 13743 solver.cpp:239] Iteration 29100 (52.2162 iter/s, 1.91512s/100 iters), loss = 0.953123
I0409 03:39:50.570858 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.953123 (* 1 = 0.953123 loss)
I0409 03:39:50.570866 13743 sgd_solver.cpp:112] Iteration 29100, lr = 0.001
I0409 03:39:51.591091 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:39:52.491066 13743 solver.cpp:239] Iteration 29200 (52.0776 iter/s, 1.92021s/100 iters), loss = 0.884917
I0409 03:39:52.491142 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.884917 (* 1 = 0.884917 loss)
I0409 03:39:52.491153 13743 sgd_solver.cpp:112] Iteration 29200, lr = 0.001
I0409 03:39:54.409896 13743 solver.cpp:239] Iteration 29300 (52.1172 iter/s, 1.91875s/100 iters), loss = 1.48874
I0409 03:39:54.409988 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.48874 (* 1 = 1.48874 loss)
I0409 03:39:54.409997 13743 sgd_solver.cpp:112] Iteration 29300, lr = 0.001
I0409 03:39:56.329439 13743 solver.cpp:239] Iteration 29400 (52.0982 iter/s, 1.91945s/100 iters), loss = 0.781303
I0409 03:39:56.329612 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.781303 (* 1 = 0.781303 loss)
I0409 03:39:56.329639 13743 sgd_solver.cpp:112] Iteration 29400, lr = 0.001
I0409 03:39:58.248030 13743 solver.cpp:239] Iteration 29500 (52.1263 iter/s, 1.91842s/100 iters), loss = 1.09652
I0409 03:39:58.248100 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09652 (* 1 = 1.09652 loss)
I0409 03:39:58.248111 13743 sgd_solver.cpp:112] Iteration 29500, lr = 0.001
I0409 03:40:00.165244 13743 solver.cpp:239] Iteration 29600 (52.1611 iter/s, 1.91714s/100 iters), loss = 1.02306
I0409 03:40:00.165319 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.02306 (* 1 = 1.02306 loss)
I0409 03:40:00.165328 13743 sgd_solver.cpp:112] Iteration 29600, lr = 0.001
I0409 03:40:00.207079 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:02.082201 13743 solver.cpp:239] Iteration 29700 (52.1677 iter/s, 1.91689s/100 iters), loss = 0.872963
I0409 03:40:02.082275 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.872963 (* 1 = 0.872963 loss)
I0409 03:40:02.082285 13743 sgd_solver.cpp:112] Iteration 29700, lr = 0.001
I0409 03:40:03.997813 13743 solver.cpp:239] Iteration 29800 (52.2045 iter/s, 1.91554s/100 iters), loss = 0.902288
I0409 03:40:03.997900 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.902288 (* 1 = 0.902288 loss)
I0409 03:40:03.997922 13743 sgd_solver.cpp:112] Iteration 29800, lr = 0.001
I0409 03:40:05.919947 13743 solver.cpp:239] Iteration 29900 (52.0277 iter/s, 1.92205s/100 iters), loss = 1.10342
I0409 03:40:05.920039 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10342 (* 1 = 1.10342 loss)
I0409 03:40:05.920065 13743 sgd_solver.cpp:112] Iteration 29900, lr = 0.001
I0409 03:40:07.819672 13743 solver.cpp:464] Snapshotting to binary proto file ./FaceEmotionNet_model_iter_30000.caffemodel
I0409 03:40:07.897167 13743 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./FaceEmotionNet_model_iter_30000.solverstate
I0409 03:40:07.942467 13743 solver.cpp:347] Iteration 30000, Testing net (#0)
I0409 03:40:08.240917 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:08.245591 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10398 (* 1 = 1.10398 loss)
I0409 03:40:08.245622 13743 solver.cpp:414]     Test net output #1: accuracy = 0.589565
I0409 03:40:08.262646 13743 solver.cpp:239] Iteration 30000 (42.6872 iter/s, 2.34262s/100 iters), loss = 1.19988
I0409 03:40:08.262751 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19988 (* 1 = 1.19988 loss)
I0409 03:40:08.262764 13743 sgd_solver.cpp:112] Iteration 30000, lr = 0.001
I0409 03:40:09.223776 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:10.178493 13743 solver.cpp:239] Iteration 30100 (52.1989 iter/s, 1.91575s/100 iters), loss = 0.956585
I0409 03:40:10.178556 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.956585 (* 1 = 0.956585 loss)
I0409 03:40:10.178565 13743 sgd_solver.cpp:112] Iteration 30100, lr = 0.001
I0409 03:40:12.099601 13743 solver.cpp:239] Iteration 30200 (52.0552 iter/s, 1.92104s/100 iters), loss = 1.10035
I0409 03:40:12.099663 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10035 (* 1 = 1.10035 loss)
I0409 03:40:12.099673 13743 sgd_solver.cpp:112] Iteration 30200, lr = 0.001
I0409 03:40:14.019611 13743 solver.cpp:239] Iteration 30300 (52.0851 iter/s, 1.91993s/100 iters), loss = 1.03726
I0409 03:40:14.019693 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03726 (* 1 = 1.03726 loss)
I0409 03:40:14.019701 13743 sgd_solver.cpp:112] Iteration 30300, lr = 0.001
I0409 03:40:15.933274 13743 solver.cpp:239] Iteration 30400 (52.2581 iter/s, 1.91358s/100 iters), loss = 0.948279
I0409 03:40:15.933395 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.948279 (* 1 = 0.948279 loss)
I0409 03:40:15.933404 13743 sgd_solver.cpp:112] Iteration 30400, lr = 0.001
I0409 03:40:17.838953 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:17.855504 13743 solver.cpp:239] Iteration 30500 (52.026 iter/s, 1.92212s/100 iters), loss = 1.12158
I0409 03:40:17.855558 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.12158 (* 1 = 1.12158 loss)
I0409 03:40:17.855571 13743 sgd_solver.cpp:112] Iteration 30500, lr = 0.001
I0409 03:40:19.775331 13743 solver.cpp:239] Iteration 30600 (52.0897 iter/s, 1.91977s/100 iters), loss = 1.24683
I0409 03:40:19.775403 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.24683 (* 1 = 1.24683 loss)
I0409 03:40:19.775410 13743 sgd_solver.cpp:112] Iteration 30600, lr = 0.001
I0409 03:40:21.694440 13743 solver.cpp:239] Iteration 30700 (52.1093 iter/s, 1.91904s/100 iters), loss = 0.758675
I0409 03:40:21.694507 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.758675 (* 1 = 0.758675 loss)
I0409 03:40:21.694515 13743 sgd_solver.cpp:112] Iteration 30700, lr = 0.001
I0409 03:40:23.608748 13743 solver.cpp:239] Iteration 30800 (52.2399 iter/s, 1.91424s/100 iters), loss = 0.976974
I0409 03:40:23.608824 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.976974 (* 1 = 0.976974 loss)
I0409 03:40:23.608834 13743 sgd_solver.cpp:112] Iteration 30800, lr = 0.001
I0409 03:40:25.527273 13743 solver.cpp:239] Iteration 30900 (52.1254 iter/s, 1.91845s/100 iters), loss = 0.909971
I0409 03:40:25.527376 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.909971 (* 1 = 0.909971 loss)
I0409 03:40:25.527400 13743 sgd_solver.cpp:112] Iteration 30900, lr = 0.001
I0409 03:40:26.433297 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:27.426303 13743 solver.cpp:347] Iteration 31000, Testing net (#0)
I0409 03:40:27.729384 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:27.734002 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10283 (* 1 = 1.10283 loss)
I0409 03:40:27.734031 13743 solver.cpp:414]     Test net output #1: accuracy = 0.590123
I0409 03:40:27.751410 13743 solver.cpp:239] Iteration 31000 (44.9628 iter/s, 2.22406s/100 iters), loss = 0.868311
I0409 03:40:27.751456 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.868311 (* 1 = 0.868311 loss)
I0409 03:40:27.751466 13743 sgd_solver.cpp:112] Iteration 31000, lr = 0.001
I0409 03:40:29.672992 13743 solver.cpp:239] Iteration 31100 (52.0417 iter/s, 1.92153s/100 iters), loss = 1.15193
I0409 03:40:29.673122 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.15193 (* 1 = 1.15193 loss)
I0409 03:40:29.673146 13743 sgd_solver.cpp:112] Iteration 31100, lr = 0.001
I0409 03:40:31.582921 13743 solver.cpp:239] Iteration 31200 (52.362 iter/s, 1.90978s/100 iters), loss = 1.00496
I0409 03:40:31.582988 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00496 (* 1 = 1.00496 loss)
I0409 03:40:31.582998 13743 sgd_solver.cpp:112] Iteration 31200, lr = 0.001
I0409 03:40:33.488947 13743 solver.cpp:239] Iteration 31300 (52.467 iter/s, 1.90596s/100 iters), loss = 0.803218
I0409 03:40:33.489012 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.803218 (* 1 = 0.803218 loss)
I0409 03:40:33.489022 13743 sgd_solver.cpp:112] Iteration 31300, lr = 0.001
I0409 03:40:35.326712 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:35.398402 13743 solver.cpp:239] Iteration 31400 (52.3728 iter/s, 1.90939s/100 iters), loss = 1.16977
I0409 03:40:35.398476 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.16977 (* 1 = 1.16977 loss)
I0409 03:40:35.398485 13743 sgd_solver.cpp:112] Iteration 31400, lr = 0.001
I0409 03:40:37.305294 13743 solver.cpp:239] Iteration 31500 (52.4433 iter/s, 1.90682s/100 iters), loss = 1.00754
I0409 03:40:37.305358 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00754 (* 1 = 1.00754 loss)
I0409 03:40:37.305373 13743 sgd_solver.cpp:112] Iteration 31500, lr = 0.001
I0409 03:40:39.214263 13743 solver.cpp:239] Iteration 31600 (52.3861 iter/s, 1.9089s/100 iters), loss = 1.09234
I0409 03:40:39.214341 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09234 (* 1 = 1.09234 loss)
I0409 03:40:39.214350 13743 sgd_solver.cpp:112] Iteration 31600, lr = 0.001
I0409 03:40:41.122249 13743 solver.cpp:239] Iteration 31700 (52.4134 iter/s, 1.90791s/100 iters), loss = 0.919394
I0409 03:40:41.122318 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.919394 (* 1 = 0.919394 loss)
I0409 03:40:41.122328 13743 sgd_solver.cpp:112] Iteration 31700, lr = 0.001
I0409 03:40:43.043498 13743 solver.cpp:239] Iteration 31800 (52.0515 iter/s, 1.92117s/100 iters), loss = 1.2041
I0409 03:40:43.043570 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.2041 (* 1 = 1.2041 loss)
I0409 03:40:43.043579 13743 sgd_solver.cpp:112] Iteration 31800, lr = 0.001
I0409 03:40:43.908627 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:44.958628 13743 solver.cpp:239] Iteration 31900 (52.2178 iter/s, 1.91506s/100 iters), loss = 1.06316
I0409 03:40:44.958711 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06316 (* 1 = 1.06316 loss)
I0409 03:40:44.958722 13743 sgd_solver.cpp:112] Iteration 31900, lr = 0.001
I0409 03:40:46.854061 13743 solver.cpp:347] Iteration 32000, Testing net (#0)
I0409 03:40:47.159231 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:47.163736 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10922 (* 1 = 1.10922 loss)
I0409 03:40:47.163792 13743 solver.cpp:414]     Test net output #1: accuracy = 0.590123
I0409 03:40:47.181040 13743 solver.cpp:239] Iteration 32000 (44.9976 iter/s, 2.22234s/100 iters), loss = 1.02801
I0409 03:40:47.181085 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.02801 (* 1 = 1.02801 loss)
I0409 03:40:47.181097 13743 sgd_solver.cpp:112] Iteration 32000, lr = 0.001
I0409 03:40:49.099625 13743 solver.cpp:239] Iteration 32100 (52.1229 iter/s, 1.91854s/100 iters), loss = 1.00234
I0409 03:40:49.099686 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00234 (* 1 = 1.00234 loss)
I0409 03:40:49.099694 13743 sgd_solver.cpp:112] Iteration 32100, lr = 0.001
I0409 03:40:51.017333 13743 solver.cpp:239] Iteration 32200 (52.1476 iter/s, 1.91763s/100 iters), loss = 1.04432
I0409 03:40:51.017395 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04432 (* 1 = 1.04432 loss)
I0409 03:40:51.017405 13743 sgd_solver.cpp:112] Iteration 32200, lr = 0.001
I0409 03:40:52.804575 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:40:52.934873 13743 solver.cpp:239] Iteration 32300 (52.1518 iter/s, 1.91748s/100 iters), loss = 0.888357
I0409 03:40:52.934942 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.888357 (* 1 = 0.888357 loss)
I0409 03:40:52.934952 13743 sgd_solver.cpp:112] Iteration 32300, lr = 0.001
I0409 03:40:54.849663 13743 solver.cpp:239] Iteration 32400 (52.227 iter/s, 1.91472s/100 iters), loss = 0.986835
I0409 03:40:54.849756 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.986835 (* 1 = 0.986835 loss)
I0409 03:40:54.849766 13743 sgd_solver.cpp:112] Iteration 32400, lr = 0.001
I0409 03:40:56.767688 13743 solver.cpp:239] Iteration 32500 (52.1393 iter/s, 1.91794s/100 iters), loss = 1.08972
I0409 03:40:56.767765 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.08972 (* 1 = 1.08972 loss)
I0409 03:40:56.767772 13743 sgd_solver.cpp:112] Iteration 32500, lr = 0.001
I0409 03:40:58.684346 13743 solver.cpp:239] Iteration 32600 (52.1767 iter/s, 1.91657s/100 iters), loss = 0.969386
I0409 03:40:58.684425 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.969386 (* 1 = 0.969386 loss)
I0409 03:40:58.684434 13743 sgd_solver.cpp:112] Iteration 32600, lr = 0.001
I0409 03:41:00.602982 13743 solver.cpp:239] Iteration 32700 (52.1224 iter/s, 1.91856s/100 iters), loss = 1.01765
I0409 03:41:00.603037 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01765 (* 1 = 1.01765 loss)
I0409 03:41:00.603045 13743 sgd_solver.cpp:112] Iteration 32700, lr = 0.001
I0409 03:41:01.412088 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:02.518981 13743 solver.cpp:239] Iteration 32800 (52.1935 iter/s, 1.91595s/100 iters), loss = 1.3113
I0409 03:41:02.519088 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.3113 (* 1 = 1.3113 loss)
I0409 03:41:02.519096 13743 sgd_solver.cpp:112] Iteration 32800, lr = 0.001
I0409 03:41:04.434733 13743 solver.cpp:239] Iteration 32900 (52.2013 iter/s, 1.91566s/100 iters), loss = 0.874609
I0409 03:41:04.434799 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.874609 (* 1 = 0.874609 loss)
I0409 03:41:04.434808 13743 sgd_solver.cpp:112] Iteration 32900, lr = 0.001
I0409 03:41:06.337556 13743 solver.cpp:347] Iteration 33000, Testing net (#0)
I0409 03:41:06.642544 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:06.647413 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.1225 (* 1 = 1.1225 loss)
I0409 03:41:06.647441 13743 solver.cpp:414]     Test net output #1: accuracy = 0.583984
I0409 03:41:06.664525 13743 solver.cpp:239] Iteration 33000 (44.8483 iter/s, 2.22974s/100 iters), loss = 1.07958
I0409 03:41:06.664564 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07958 (* 1 = 1.07958 loss)
I0409 03:41:06.664574 13743 sgd_solver.cpp:112] Iteration 33000, lr = 0.001
I0409 03:41:08.580502 13743 solver.cpp:239] Iteration 33100 (52.1938 iter/s, 1.91594s/100 iters), loss = 1.07613
I0409 03:41:08.580565 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07613 (* 1 = 1.07613 loss)
I0409 03:41:08.580574 13743 sgd_solver.cpp:112] Iteration 33100, lr = 0.001
I0409 03:41:10.311254 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:10.497555 13743 solver.cpp:239] Iteration 33200 (52.1652 iter/s, 1.91699s/100 iters), loss = 1.06965
I0409 03:41:10.497632 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06965 (* 1 = 1.06965 loss)
I0409 03:41:10.497640 13743 sgd_solver.cpp:112] Iteration 33200, lr = 0.001
I0409 03:41:12.416091 13743 solver.cpp:239] Iteration 33300 (52.1251 iter/s, 1.91846s/100 iters), loss = 1.26704
I0409 03:41:12.416167 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.26704 (* 1 = 1.26704 loss)
I0409 03:41:12.416175 13743 sgd_solver.cpp:112] Iteration 33300, lr = 0.001
I0409 03:41:14.336161 13743 solver.cpp:239] Iteration 33400 (52.0837 iter/s, 1.91999s/100 iters), loss = 1.19323
I0409 03:41:14.336251 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19323 (* 1 = 1.19323 loss)
I0409 03:41:14.336275 13743 sgd_solver.cpp:112] Iteration 33400, lr = 0.001
I0409 03:41:16.256026 13743 solver.cpp:239] Iteration 33500 (52.0894 iter/s, 1.91978s/100 iters), loss = 1.26831
I0409 03:41:16.256089 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.26831 (* 1 = 1.26831 loss)
I0409 03:41:16.256098 13743 sgd_solver.cpp:112] Iteration 33500, lr = 0.001
I0409 03:41:18.177315 13743 solver.cpp:239] Iteration 33600 (52.0502 iter/s, 1.92122s/100 iters), loss = 0.940857
I0409 03:41:18.177392 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.940857 (* 1 = 0.940857 loss)
I0409 03:41:18.177417 13743 sgd_solver.cpp:112] Iteration 33600, lr = 0.001
I0409 03:41:18.932514 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:20.099623 13743 solver.cpp:239] Iteration 33700 (52.0231 iter/s, 1.92222s/100 iters), loss = 1.00487
I0409 03:41:20.099732 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00487 (* 1 = 1.00487 loss)
I0409 03:41:20.099742 13743 sgd_solver.cpp:112] Iteration 33700, lr = 0.001
I0409 03:41:22.017714 13743 solver.cpp:239] Iteration 33800 (52.138 iter/s, 1.91799s/100 iters), loss = 0.799732
I0409 03:41:22.017781 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.799732 (* 1 = 0.799732 loss)
I0409 03:41:22.017789 13743 sgd_solver.cpp:112] Iteration 33800, lr = 0.001
I0409 03:41:23.936864 13743 solver.cpp:239] Iteration 33900 (52.1083 iter/s, 1.91908s/100 iters), loss = 1.07712
I0409 03:41:23.936940 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07712 (* 1 = 1.07712 loss)
I0409 03:41:23.936952 13743 sgd_solver.cpp:112] Iteration 33900, lr = 0.001
I0409 03:41:25.837343 13743 solver.cpp:347] Iteration 34000, Testing net (#0)
I0409 03:41:26.141801 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:26.146431 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10459 (* 1 = 1.10459 loss)
I0409 03:41:26.146474 13743 solver.cpp:414]     Test net output #1: accuracy = 0.592355
I0409 03:41:26.163858 13743 solver.cpp:239] Iteration 34000 (44.9048 iter/s, 2.22693s/100 iters), loss = 0.943811
I0409 03:41:26.163913 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.943811 (* 1 = 0.943811 loss)
I0409 03:41:26.163923 13743 sgd_solver.cpp:112] Iteration 34000, lr = 0.001
I0409 03:41:27.838140 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:28.083747 13743 solver.cpp:239] Iteration 34100 (52.0879 iter/s, 1.91983s/100 iters), loss = 1.13137
I0409 03:41:28.083827 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13137 (* 1 = 1.13137 loss)
I0409 03:41:28.083837 13743 sgd_solver.cpp:112] Iteration 34100, lr = 0.001
I0409 03:41:30.007136 13743 solver.cpp:239] Iteration 34200 (51.9938 iter/s, 1.92331s/100 iters), loss = 1.00802
I0409 03:41:30.007210 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00802 (* 1 = 1.00802 loss)
I0409 03:41:30.007220 13743 sgd_solver.cpp:112] Iteration 34200, lr = 0.001
I0409 03:41:31.919767 13743 solver.cpp:239] Iteration 34300 (52.2861 iter/s, 1.91255s/100 iters), loss = 1.10638
I0409 03:41:31.919843 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10638 (* 1 = 1.10638 loss)
I0409 03:41:31.919852 13743 sgd_solver.cpp:112] Iteration 34300, lr = 0.001
I0409 03:41:33.835651 13743 solver.cpp:239] Iteration 34400 (52.1977 iter/s, 1.91579s/100 iters), loss = 0.783888
I0409 03:41:33.835728 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.783888 (* 1 = 0.783888 loss)
I0409 03:41:33.835760 13743 sgd_solver.cpp:112] Iteration 34400, lr = 0.001
I0409 03:41:35.754477 13743 solver.cpp:239] Iteration 34500 (52.1172 iter/s, 1.91875s/100 iters), loss = 0.864888
I0409 03:41:35.754544 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.864888 (* 1 = 0.864888 loss)
I0409 03:41:35.754551 13743 sgd_solver.cpp:112] Iteration 34500, lr = 0.001
I0409 03:41:36.447669 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:37.670688 13743 solver.cpp:239] Iteration 34600 (52.188 iter/s, 1.91615s/100 iters), loss = 1.15244
I0409 03:41:37.670748 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.15244 (* 1 = 1.15244 loss)
I0409 03:41:37.670758 13743 sgd_solver.cpp:112] Iteration 34600, lr = 0.001
I0409 03:41:39.593152 13743 solver.cpp:239] Iteration 34700 (52.0181 iter/s, 1.92241s/100 iters), loss = 1.04604
I0409 03:41:39.593214 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04604 (* 1 = 1.04604 loss)
I0409 03:41:39.593222 13743 sgd_solver.cpp:112] Iteration 34700, lr = 0.001
I0409 03:41:41.514971 13743 solver.cpp:239] Iteration 34800 (52.0357 iter/s, 1.92176s/100 iters), loss = 0.936657
I0409 03:41:41.515048 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.936657 (* 1 = 0.936657 loss)
I0409 03:41:41.515056 13743 sgd_solver.cpp:112] Iteration 34800, lr = 0.001
I0409 03:41:43.432718 13743 solver.cpp:239] Iteration 34900 (52.147 iter/s, 1.91765s/100 iters), loss = 1.00416
I0409 03:41:43.432782 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00416 (* 1 = 1.00416 loss)
I0409 03:41:43.432791 13743 sgd_solver.cpp:112] Iteration 34900, lr = 0.001
I0409 03:41:45.066799 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:45.332938 13743 solver.cpp:347] Iteration 35000, Testing net (#0)
I0409 03:41:45.637922 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:45.642385 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10564 (* 1 = 1.10564 loss)
I0409 03:41:45.642416 13743 solver.cpp:414]     Test net output #1: accuracy = 0.59096
I0409 03:41:45.659576 13743 solver.cpp:239] Iteration 35000 (44.9074 iter/s, 2.2268s/100 iters), loss = 0.964284
I0409 03:41:45.659623 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.964284 (* 1 = 0.964284 loss)
I0409 03:41:45.659649 13743 sgd_solver.cpp:112] Iteration 35000, lr = 0.001
I0409 03:41:47.575687 13743 solver.cpp:239] Iteration 35100 (52.1903 iter/s, 1.91606s/100 iters), loss = 0.852537
I0409 03:41:47.575754 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.852537 (* 1 = 0.852537 loss)
I0409 03:41:47.575763 13743 sgd_solver.cpp:112] Iteration 35100, lr = 0.001
I0409 03:41:49.489953 13743 solver.cpp:239] Iteration 35200 (52.2414 iter/s, 1.91419s/100 iters), loss = 1.12117
I0409 03:41:49.490041 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.12117 (* 1 = 1.12117 loss)
I0409 03:41:49.490049 13743 sgd_solver.cpp:112] Iteration 35200, lr = 0.001
I0409 03:41:51.409530 13743 solver.cpp:239] Iteration 35300 (52.0975 iter/s, 1.91948s/100 iters), loss = 1.0053
I0409 03:41:51.409605 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.0053 (* 1 = 1.0053 loss)
I0409 03:41:51.409613 13743 sgd_solver.cpp:112] Iteration 35300, lr = 0.001
I0409 03:41:53.331066 13743 solver.cpp:239] Iteration 35400 (52.0437 iter/s, 1.92146s/100 iters), loss = 0.894949
I0409 03:41:53.331146 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.894949 (* 1 = 0.894949 loss)
I0409 03:41:53.331156 13743 sgd_solver.cpp:112] Iteration 35400, lr = 0.001
I0409 03:41:53.968544 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:41:55.251535 13743 solver.cpp:239] Iteration 35500 (52.0727 iter/s, 1.92039s/100 iters), loss = 0.875999
I0409 03:41:55.251602 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.875999 (* 1 = 0.875999 loss)
I0409 03:41:55.251612 13743 sgd_solver.cpp:112] Iteration 35500, lr = 0.001
I0409 03:41:57.174875 13743 solver.cpp:239] Iteration 35600 (51.9947 iter/s, 1.92327s/100 iters), loss = 1.18797
I0409 03:41:57.174943 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.18797 (* 1 = 1.18797 loss)
I0409 03:41:57.174952 13743 sgd_solver.cpp:112] Iteration 35600, lr = 0.001
I0409 03:41:59.090636 13743 solver.cpp:239] Iteration 35700 (52.2003 iter/s, 1.9157s/100 iters), loss = 0.989393
I0409 03:41:59.090711 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.989393 (* 1 = 0.989393 loss)
I0409 03:41:59.090720 13743 sgd_solver.cpp:112] Iteration 35700, lr = 0.001
I0409 03:42:01.011441 13743 solver.cpp:239] Iteration 35800 (52.0636 iter/s, 1.92073s/100 iters), loss = 1.1687
I0409 03:42:01.011508 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.1687 (* 1 = 1.1687 loss)
I0409 03:42:01.011518 13743 sgd_solver.cpp:112] Iteration 35800, lr = 0.001
I0409 03:42:02.585652 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:02.927500 13743 solver.cpp:239] Iteration 35900 (52.1925 iter/s, 1.91598s/100 iters), loss = 1.09776
I0409 03:42:02.927572 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09776 (* 1 = 1.09776 loss)
I0409 03:42:02.927582 13743 sgd_solver.cpp:112] Iteration 35900, lr = 0.001
I0409 03:42:04.821321 13743 solver.cpp:347] Iteration 36000, Testing net (#0)
I0409 03:42:05.131332 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:05.134387 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10368 (* 1 = 1.10368 loss)
I0409 03:42:05.134414 13743 solver.cpp:414]     Test net output #1: accuracy = 0.587054
I0409 03:42:05.151571 13743 solver.cpp:239] Iteration 36000 (44.9638 iter/s, 2.22401s/100 iters), loss = 0.96884
I0409 03:42:05.151633 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.96884 (* 1 = 0.96884 loss)
I0409 03:42:05.151643 13743 sgd_solver.cpp:112] Iteration 36000, lr = 0.001
I0409 03:42:07.068225 13743 solver.cpp:239] Iteration 36100 (52.1758 iter/s, 1.9166s/100 iters), loss = 1.09012
I0409 03:42:07.068316 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09012 (* 1 = 1.09012 loss)
I0409 03:42:07.068325 13743 sgd_solver.cpp:112] Iteration 36100, lr = 0.001
I0409 03:42:08.984720 13743 solver.cpp:239] Iteration 36200 (52.181 iter/s, 1.91641s/100 iters), loss = 1.10481
I0409 03:42:08.984783 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10481 (* 1 = 1.10481 loss)
I0409 03:42:08.984791 13743 sgd_solver.cpp:112] Iteration 36200, lr = 0.001
I0409 03:42:10.899984 13743 solver.cpp:239] Iteration 36300 (52.2138 iter/s, 1.9152s/100 iters), loss = 1.08271
I0409 03:42:10.900089 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.08271 (* 1 = 1.08271 loss)
I0409 03:42:10.900099 13743 sgd_solver.cpp:112] Iteration 36300, lr = 0.001
I0409 03:42:11.482076 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:12.820118 13743 solver.cpp:239] Iteration 36400 (52.0825 iter/s, 1.92003s/100 iters), loss = 0.952947
I0409 03:42:12.820183 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.952947 (* 1 = 0.952947 loss)
I0409 03:42:12.820192 13743 sgd_solver.cpp:112] Iteration 36400, lr = 0.001
I0409 03:42:14.738811 13743 solver.cpp:239] Iteration 36500 (52.1205 iter/s, 1.91863s/100 iters), loss = 1.31678
I0409 03:42:14.738875 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.31678 (* 1 = 1.31678 loss)
I0409 03:42:14.738898 13743 sgd_solver.cpp:112] Iteration 36500, lr = 0.001
I0409 03:42:16.653988 13743 solver.cpp:239] Iteration 36600 (52.2162 iter/s, 1.91511s/100 iters), loss = 0.986921
I0409 03:42:16.654054 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.986921 (* 1 = 0.986921 loss)
I0409 03:42:16.654064 13743 sgd_solver.cpp:112] Iteration 36600, lr = 0.001
I0409 03:42:18.561877 13743 solver.cpp:239] Iteration 36700 (52.4158 iter/s, 1.90782s/100 iters), loss = 1.20948
I0409 03:42:18.561962 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20948 (* 1 = 1.20948 loss)
I0409 03:42:18.561971 13743 sgd_solver.cpp:112] Iteration 36700, lr = 0.001
I0409 03:42:20.072325 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:20.467761 13743 solver.cpp:239] Iteration 36800 (52.4715 iter/s, 1.9058s/100 iters), loss = 1.12034
I0409 03:42:20.467837 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.12034 (* 1 = 1.12034 loss)
I0409 03:42:20.467846 13743 sgd_solver.cpp:112] Iteration 36800, lr = 0.001
I0409 03:42:22.375738 13743 solver.cpp:239] Iteration 36900 (52.4137 iter/s, 1.9079s/100 iters), loss = 0.818922
I0409 03:42:22.375831 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.818922 (* 1 = 0.818922 loss)
I0409 03:42:22.375840 13743 sgd_solver.cpp:112] Iteration 36900, lr = 0.001
I0409 03:42:24.275409 13743 solver.cpp:347] Iteration 37000, Testing net (#0)
I0409 03:42:24.582682 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:24.587175 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10508 (* 1 = 1.10508 loss)
I0409 03:42:24.587227 13743 solver.cpp:414]     Test net output #1: accuracy = 0.591518
I0409 03:42:24.604441 13743 solver.cpp:239] Iteration 37000 (44.8708 iter/s, 2.22862s/100 iters), loss = 1.05085
I0409 03:42:24.604501 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05085 (* 1 = 1.05085 loss)
I0409 03:42:24.604511 13743 sgd_solver.cpp:112] Iteration 37000, lr = 0.001
I0409 03:42:26.525015 13743 solver.cpp:239] Iteration 37100 (52.069 iter/s, 1.92053s/100 iters), loss = 0.861302
I0409 03:42:26.525092 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.861302 (* 1 = 0.861302 loss)
I0409 03:42:26.525101 13743 sgd_solver.cpp:112] Iteration 37100, lr = 0.001
I0409 03:42:28.444586 13743 solver.cpp:239] Iteration 37200 (52.0972 iter/s, 1.91949s/100 iters), loss = 1.09955
I0409 03:42:28.444670 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.09955 (* 1 = 1.09955 loss)
I0409 03:42:28.444681 13743 sgd_solver.cpp:112] Iteration 37200, lr = 0.001
I0409 03:42:28.965844 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:30.368984 13743 solver.cpp:239] Iteration 37300 (51.9669 iter/s, 1.9243s/100 iters), loss = 1.02776
I0409 03:42:30.369061 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.02776 (* 1 = 1.02776 loss)
I0409 03:42:30.369071 13743 sgd_solver.cpp:112] Iteration 37300, lr = 0.001
I0409 03:42:32.287184 13743 solver.cpp:239] Iteration 37400 (52.1353 iter/s, 1.91808s/100 iters), loss = 1.10259
I0409 03:42:32.287307 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10259 (* 1 = 1.10259 loss)
I0409 03:42:32.287325 13743 sgd_solver.cpp:112] Iteration 37400, lr = 0.001
I0409 03:42:34.202025 13743 solver.cpp:239] Iteration 37500 (52.2271 iter/s, 1.91471s/100 iters), loss = 1.20901
I0409 03:42:34.202098 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.20901 (* 1 = 1.20901 loss)
I0409 03:42:34.202107 13743 sgd_solver.cpp:112] Iteration 37500, lr = 0.001
I0409 03:42:36.116734 13743 solver.cpp:239] Iteration 37600 (52.2293 iter/s, 1.91464s/100 iters), loss = 1.19132
I0409 03:42:36.116806 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.19132 (* 1 = 1.19132 loss)
I0409 03:42:36.116816 13743 sgd_solver.cpp:112] Iteration 37600, lr = 0.001
I0409 03:42:37.580351 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:38.032644 13743 solver.cpp:239] Iteration 37700 (52.1964 iter/s, 1.91584s/100 iters), loss = 1.0752
I0409 03:42:38.032711 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.0752 (* 1 = 1.0752 loss)
I0409 03:42:38.032719 13743 sgd_solver.cpp:112] Iteration 37700, lr = 0.001
I0409 03:42:39.949259 13743 solver.cpp:239] Iteration 37800 (52.1771 iter/s, 1.91655s/100 iters), loss = 1.23552
I0409 03:42:39.949323 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.23552 (* 1 = 1.23552 loss)
I0409 03:42:39.949331 13743 sgd_solver.cpp:112] Iteration 37800, lr = 0.001
I0409 03:42:41.870185 13743 solver.cpp:239] Iteration 37900 (52.0603 iter/s, 1.92085s/100 iters), loss = 1.00545
I0409 03:42:41.870263 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00545 (* 1 = 1.00545 loss)
I0409 03:42:41.870275 13743 sgd_solver.cpp:112] Iteration 37900, lr = 0.001
I0409 03:42:43.778690 13743 solver.cpp:347] Iteration 38000, Testing net (#0)
I0409 03:42:44.089577 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.15432 (* 1 = 1.15432 loss)
I0409 03:42:44.089632 13743 solver.cpp:414]     Test net output #1: accuracy = 0.577009
I0409 03:42:44.106824 13743 solver.cpp:239] Iteration 38000 (44.7114 iter/s, 2.23657s/100 iters), loss = 1.02761
I0409 03:42:44.106881 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.02761 (* 1 = 1.02761 loss)
I0409 03:42:44.106900 13743 sgd_solver.cpp:112] Iteration 38000, lr = 0.001
I0409 03:42:46.022831 13743 solver.cpp:239] Iteration 38100 (52.193 iter/s, 1.91597s/100 iters), loss = 1.3104
I0409 03:42:46.022912 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.3104 (* 1 = 1.3104 loss)
I0409 03:42:46.022922 13743 sgd_solver.cpp:112] Iteration 38100, lr = 0.001
I0409 03:42:46.506953 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:47.942289 13743 solver.cpp:239] Iteration 38200 (52.1004 iter/s, 1.91937s/100 iters), loss = 0.590333
I0409 03:42:47.942365 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.590333 (* 1 = 0.590333 loss)
I0409 03:42:47.942411 13743 sgd_solver.cpp:112] Iteration 38200, lr = 0.001
I0409 03:42:49.859078 13743 solver.cpp:239] Iteration 38300 (52.1727 iter/s, 1.91671s/100 iters), loss = 0.954431
I0409 03:42:49.859172 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.954431 (* 1 = 0.954431 loss)
I0409 03:42:49.859182 13743 sgd_solver.cpp:112] Iteration 38300, lr = 0.001
I0409 03:42:51.777897 13743 solver.cpp:239] Iteration 38400 (52.1181 iter/s, 1.91872s/100 iters), loss = 0.830886
I0409 03:42:51.777982 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.830886 (* 1 = 0.830886 loss)
I0409 03:42:51.777993 13743 sgd_solver.cpp:112] Iteration 38400, lr = 0.001
I0409 03:42:53.696751 13743 solver.cpp:239] Iteration 38500 (52.1166 iter/s, 1.91877s/100 iters), loss = 0.811509
I0409 03:42:53.696826 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.811509 (* 1 = 0.811509 loss)
I0409 03:42:53.696835 13743 sgd_solver.cpp:112] Iteration 38500, lr = 0.001
I0409 03:42:55.102768 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:42:55.616081 13743 solver.cpp:239] Iteration 38600 (52.1034 iter/s, 1.91926s/100 iters), loss = 1.24612
I0409 03:42:55.616156 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.24612 (* 1 = 1.24612 loss)
I0409 03:42:55.616165 13743 sgd_solver.cpp:112] Iteration 38600, lr = 0.001
I0409 03:42:57.530263 13743 solver.cpp:239] Iteration 38700 (52.2441 iter/s, 1.91409s/100 iters), loss = 1.05057
I0409 03:42:57.530339 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05057 (* 1 = 1.05057 loss)
I0409 03:42:57.530346 13743 sgd_solver.cpp:112] Iteration 38700, lr = 0.001
I0409 03:42:59.455134 13743 solver.cpp:239] Iteration 38800 (51.9535 iter/s, 1.9248s/100 iters), loss = 0.957531
I0409 03:42:59.455260 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.957531 (* 1 = 0.957531 loss)
I0409 03:42:59.455286 13743 sgd_solver.cpp:112] Iteration 38800, lr = 0.001
I0409 03:43:01.375258 13743 solver.cpp:239] Iteration 38900 (52.0834 iter/s, 1.92s/100 iters), loss = 1.14131
I0409 03:43:01.375336 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14131 (* 1 = 1.14131 loss)
I0409 03:43:01.375346 13743 sgd_solver.cpp:112] Iteration 38900, lr = 0.001
I0409 03:43:03.277019 13743 solver.cpp:347] Iteration 39000, Testing net (#0)
I0409 03:43:03.278693 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:03.588203 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.11016 (* 1 = 1.11016 loss)
I0409 03:43:03.588279 13743 solver.cpp:414]     Test net output #1: accuracy = 0.591239
I0409 03:43:03.605502 13743 solver.cpp:239] Iteration 39000 (44.8394 iter/s, 2.23018s/100 iters), loss = 0.97755
I0409 03:43:03.605543 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.97755 (* 1 = 0.97755 loss)
I0409 03:43:03.605554 13743 sgd_solver.cpp:112] Iteration 39000, lr = 0.001
I0409 03:43:04.033185 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:05.524919 13743 solver.cpp:239] Iteration 39100 (52.1005 iter/s, 1.91937s/100 iters), loss = 0.95522
I0409 03:43:05.524999 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.95522 (* 1 = 0.95522 loss)
I0409 03:43:05.525008 13743 sgd_solver.cpp:112] Iteration 39100, lr = 0.001
I0409 03:43:07.443251 13743 solver.cpp:239] Iteration 39200 (52.1308 iter/s, 1.91825s/100 iters), loss = 0.901982
I0409 03:43:07.443327 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.901982 (* 1 = 0.901982 loss)
I0409 03:43:07.443337 13743 sgd_solver.cpp:112] Iteration 39200, lr = 0.001
I0409 03:43:09.362498 13743 solver.cpp:239] Iteration 39300 (52.1058 iter/s, 1.91917s/100 iters), loss = 1.06892
I0409 03:43:09.362582 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06892 (* 1 = 1.06892 loss)
I0409 03:43:09.362591 13743 sgd_solver.cpp:112] Iteration 39300, lr = 0.001
I0409 03:43:11.281675 13743 solver.cpp:239] Iteration 39400 (52.1079 iter/s, 1.91909s/100 iters), loss = 0.946841
I0409 03:43:11.281739 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.946841 (* 1 = 0.946841 loss)
I0409 03:43:11.281749 13743 sgd_solver.cpp:112] Iteration 39400, lr = 0.001
I0409 03:43:12.629855 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:13.198362 13743 solver.cpp:239] Iteration 39500 (52.1756 iter/s, 1.91661s/100 iters), loss = 1.05268
I0409 03:43:13.198467 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05268 (* 1 = 1.05268 loss)
I0409 03:43:13.198477 13743 sgd_solver.cpp:112] Iteration 39500, lr = 0.001
I0409 03:43:15.117225 13743 solver.cpp:239] Iteration 39600 (52.1169 iter/s, 1.91876s/100 iters), loss = 1.10344
I0409 03:43:15.117298 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10344 (* 1 = 1.10344 loss)
I0409 03:43:15.117347 13743 sgd_solver.cpp:112] Iteration 39600, lr = 0.001
I0409 03:43:17.034386 13743 solver.cpp:239] Iteration 39700 (52.1621 iter/s, 1.9171s/100 iters), loss = 0.912053
I0409 03:43:17.034479 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.912053 (* 1 = 0.912053 loss)
I0409 03:43:17.034504 13743 sgd_solver.cpp:112] Iteration 39700, lr = 0.001
I0409 03:43:18.951068 13743 solver.cpp:239] Iteration 39800 (52.1761 iter/s, 1.91659s/100 iters), loss = 0.904092
I0409 03:43:18.951140 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.904092 (* 1 = 0.904092 loss)
I0409 03:43:18.951148 13743 sgd_solver.cpp:112] Iteration 39800, lr = 0.001
I0409 03:43:20.868242 13743 solver.cpp:239] Iteration 39900 (52.1621 iter/s, 1.9171s/100 iters), loss = 0.922965
I0409 03:43:20.868333 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.922965 (* 1 = 0.922965 loss)
I0409 03:43:20.868342 13743 sgd_solver.cpp:112] Iteration 39900, lr = 0.001
I0409 03:43:21.237483 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:22.770645 13743 solver.cpp:464] Snapshotting to binary proto file ./FaceEmotionNet_model_iter_40000.caffemodel
I0409 03:43:22.847802 13743 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./FaceEmotionNet_model_iter_40000.solverstate
I0409 03:43:22.892944 13743 solver.cpp:347] Iteration 40000, Testing net (#0)
I0409 03:43:22.894167 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:23.200824 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.13018 (* 1 = 1.13018 loss)
I0409 03:43:23.200862 13743 solver.cpp:414]     Test net output #1: accuracy = 0.588728
I0409 03:43:23.217877 13743 solver.cpp:239] Iteration 40000 (42.5612 iter/s, 2.34956s/100 iters), loss = 1.03368
I0409 03:43:23.217931 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03368 (* 1 = 1.03368 loss)
I0409 03:43:23.217941 13743 sgd_solver.cpp:112] Iteration 40000, lr = 0.0001
I0409 03:43:25.135741 13743 solver.cpp:239] Iteration 40100 (52.1427 iter/s, 1.91781s/100 iters), loss = 0.878928
I0409 03:43:25.135820 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.878928 (* 1 = 0.878928 loss)
I0409 03:43:25.135828 13743 sgd_solver.cpp:112] Iteration 40100, lr = 0.0001
I0409 03:43:27.053043 13743 solver.cpp:239] Iteration 40200 (52.1588 iter/s, 1.91722s/100 iters), loss = 0.666588
I0409 03:43:27.053113 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.666588 (* 1 = 0.666588 loss)
I0409 03:43:27.053123 13743 sgd_solver.cpp:112] Iteration 40200, lr = 0.0001
I0409 03:43:28.967993 13743 solver.cpp:239] Iteration 40300 (52.2226 iter/s, 1.91488s/100 iters), loss = 0.996871
I0409 03:43:28.968065 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.996871 (* 1 = 0.996871 loss)
I0409 03:43:28.968075 13743 sgd_solver.cpp:112] Iteration 40300, lr = 0.0001
I0409 03:43:30.270323 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:30.874004 13743 solver.cpp:239] Iteration 40400 (52.4676 iter/s, 1.90594s/100 iters), loss = 1.00827
I0409 03:43:30.874086 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00827 (* 1 = 1.00827 loss)
I0409 03:43:30.874096 13743 sgd_solver.cpp:112] Iteration 40400, lr = 0.0001
I0409 03:43:32.776008 13743 solver.cpp:239] Iteration 40500 (52.5793 iter/s, 1.90189s/100 iters), loss = 0.747924
I0409 03:43:32.776124 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.747924 (* 1 = 0.747924 loss)
I0409 03:43:32.776139 13743 sgd_solver.cpp:112] Iteration 40500, lr = 0.0001
I0409 03:43:34.693171 13743 solver.cpp:239] Iteration 40600 (52.1634 iter/s, 1.91705s/100 iters), loss = 0.935756
I0409 03:43:34.693248 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.935756 (* 1 = 0.935756 loss)
I0409 03:43:34.693256 13743 sgd_solver.cpp:112] Iteration 40600, lr = 0.0001
I0409 03:43:36.610774 13743 solver.cpp:239] Iteration 40700 (52.1505 iter/s, 1.91753s/100 iters), loss = 1.00637
I0409 03:43:36.610838 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00637 (* 1 = 1.00637 loss)
I0409 03:43:36.610847 13743 sgd_solver.cpp:112] Iteration 40700, lr = 0.0001
I0409 03:43:38.529862 13743 solver.cpp:239] Iteration 40800 (52.1098 iter/s, 1.91902s/100 iters), loss = 0.853053
I0409 03:43:38.529940 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.853053 (* 1 = 0.853053 loss)
I0409 03:43:38.529950 13743 sgd_solver.cpp:112] Iteration 40800, lr = 0.0001
I0409 03:43:38.840167 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:40.446238 13743 solver.cpp:239] Iteration 40900 (52.1839 iter/s, 1.9163s/100 iters), loss = 0.855172
I0409 03:43:40.446338 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.855172 (* 1 = 0.855172 loss)
I0409 03:43:40.446349 13743 sgd_solver.cpp:112] Iteration 40900, lr = 0.0001
I0409 03:43:42.350267 13743 solver.cpp:347] Iteration 41000, Testing net (#0)
I0409 03:43:42.351943 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:42.660930 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09198 (* 1 = 1.09198 loss)
I0409 03:43:42.660974 13743 solver.cpp:414]     Test net output #1: accuracy = 0.603237
I0409 03:43:42.677987 13743 solver.cpp:239] Iteration 41000 (44.8097 iter/s, 2.23166s/100 iters), loss = 1.16808
I0409 03:43:42.678050 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.16808 (* 1 = 1.16808 loss)
I0409 03:43:42.678062 13743 sgd_solver.cpp:112] Iteration 41000, lr = 0.0001
I0409 03:43:44.594905 13743 solver.cpp:239] Iteration 41100 (52.1692 iter/s, 1.91684s/100 iters), loss = 0.710459
I0409 03:43:44.594975 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.710459 (* 1 = 0.710459 loss)
I0409 03:43:44.594985 13743 sgd_solver.cpp:112] Iteration 41100, lr = 0.0001
I0409 03:43:46.510349 13743 solver.cpp:239] Iteration 41200 (52.209 iter/s, 1.91538s/100 iters), loss = 1.00005
I0409 03:43:46.510433 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00005 (* 1 = 1.00005 loss)
I0409 03:43:46.510457 13743 sgd_solver.cpp:112] Iteration 41200, lr = 0.0001
I0409 03:43:47.757736 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:48.424600 13743 solver.cpp:239] Iteration 41300 (52.242 iter/s, 1.91417s/100 iters), loss = 0.993496
I0409 03:43:48.424670 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.993496 (* 1 = 0.993496 loss)
I0409 03:43:48.424679 13743 sgd_solver.cpp:112] Iteration 41300, lr = 0.0001
I0409 03:43:50.346562 13743 solver.cpp:239] Iteration 41400 (52.032 iter/s, 1.92189s/100 iters), loss = 0.955992
I0409 03:43:50.346629 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.955992 (* 1 = 0.955992 loss)
I0409 03:43:50.346638 13743 sgd_solver.cpp:112] Iteration 41400, lr = 0.0001
I0409 03:43:52.267048 13743 solver.cpp:239] Iteration 41500 (52.072 iter/s, 1.92042s/100 iters), loss = 1.01481
I0409 03:43:52.267143 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01481 (* 1 = 1.01481 loss)
I0409 03:43:52.267153 13743 sgd_solver.cpp:112] Iteration 41500, lr = 0.0001
I0409 03:43:54.186669 13743 solver.cpp:239] Iteration 41600 (52.0957 iter/s, 1.91954s/100 iters), loss = 0.945216
I0409 03:43:54.186736 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.945216 (* 1 = 0.945216 loss)
I0409 03:43:54.186745 13743 sgd_solver.cpp:112] Iteration 41600, lr = 0.0001
I0409 03:43:56.105243 13743 solver.cpp:239] Iteration 41700 (52.1238 iter/s, 1.91851s/100 iters), loss = 0.986466
I0409 03:43:56.105337 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.986466 (* 1 = 0.986466 loss)
I0409 03:43:56.105346 13743 sgd_solver.cpp:112] Iteration 41700, lr = 0.0001
I0409 03:43:56.359186 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:43:58.023592 13743 solver.cpp:239] Iteration 41800 (52.1302 iter/s, 1.91828s/100 iters), loss = 0.836588
I0409 03:43:58.023656 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.836588 (* 1 = 0.836588 loss)
I0409 03:43:58.023664 13743 sgd_solver.cpp:112] Iteration 41800, lr = 0.0001
I0409 03:43:59.939260 13743 solver.cpp:239] Iteration 41900 (52.204 iter/s, 1.91556s/100 iters), loss = 0.704556
I0409 03:43:59.939342 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.704556 (* 1 = 0.704556 loss)
I0409 03:43:59.939350 13743 sgd_solver.cpp:112] Iteration 41900, lr = 0.0001
I0409 03:44:01.838471 13743 solver.cpp:347] Iteration 42000, Testing net (#0)
I0409 03:44:01.840250 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:02.147812 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09189 (* 1 = 1.09189 loss)
I0409 03:44:02.147871 13743 solver.cpp:414]     Test net output #1: accuracy = 0.601283
I0409 03:44:02.165189 13743 solver.cpp:239] Iteration 42000 (44.9265 iter/s, 2.22586s/100 iters), loss = 1.02013
I0409 03:44:02.165235 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.02013 (* 1 = 1.02013 loss)
I0409 03:44:02.165252 13743 sgd_solver.cpp:112] Iteration 42000, lr = 0.0001
I0409 03:44:04.081228 13743 solver.cpp:239] Iteration 42100 (52.1923 iter/s, 1.91599s/100 iters), loss = 1.05811
I0409 03:44:04.081297 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05811 (* 1 = 1.05811 loss)
I0409 03:44:04.081318 13743 sgd_solver.cpp:112] Iteration 42100, lr = 0.0001
I0409 03:44:05.272146 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:05.995478 13743 solver.cpp:239] Iteration 42200 (52.2415 iter/s, 1.91419s/100 iters), loss = 1.07944
I0409 03:44:05.995539 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07944 (* 1 = 1.07944 loss)
I0409 03:44:05.995548 13743 sgd_solver.cpp:112] Iteration 42200, lr = 0.0001
I0409 03:44:07.914145 13743 solver.cpp:239] Iteration 42300 (52.1212 iter/s, 1.9186s/100 iters), loss = 0.864785
I0409 03:44:07.914227 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.864785 (* 1 = 0.864785 loss)
I0409 03:44:07.914242 13743 sgd_solver.cpp:112] Iteration 42300, lr = 0.0001
I0409 03:44:09.829663 13743 solver.cpp:239] Iteration 42400 (52.2076 iter/s, 1.91543s/100 iters), loss = 0.8091
I0409 03:44:09.829742 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.8091 (* 1 = 0.8091 loss)
I0409 03:44:09.829756 13743 sgd_solver.cpp:112] Iteration 42400, lr = 0.0001
I0409 03:44:11.749384 13743 solver.cpp:239] Iteration 42500 (52.093 iter/s, 1.91964s/100 iters), loss = 0.737769
I0409 03:44:11.749464 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.737769 (* 1 = 0.737769 loss)
I0409 03:44:11.749478 13743 sgd_solver.cpp:112] Iteration 42500, lr = 0.0001
I0409 03:44:13.668081 13743 solver.cpp:239] Iteration 42600 (52.1208 iter/s, 1.91862s/100 iters), loss = 0.856245
I0409 03:44:13.668157 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.856245 (* 1 = 0.856245 loss)
I0409 03:44:13.668166 13743 sgd_solver.cpp:112] Iteration 42600, lr = 0.0001
I0409 03:44:13.863570 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:15.588135 13743 solver.cpp:239] Iteration 42700 (52.0848 iter/s, 1.91995s/100 iters), loss = 0.987131
I0409 03:44:15.588225 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.987131 (* 1 = 0.987131 loss)
I0409 03:44:15.588233 13743 sgd_solver.cpp:112] Iteration 42700, lr = 0.0001
I0409 03:44:17.506047 13743 solver.cpp:239] Iteration 42800 (52.1426 iter/s, 1.91782s/100 iters), loss = 0.965979
I0409 03:44:17.506112 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.965979 (* 1 = 0.965979 loss)
I0409 03:44:17.506121 13743 sgd_solver.cpp:112] Iteration 42800, lr = 0.0001
I0409 03:44:19.421411 13743 solver.cpp:239] Iteration 42900 (52.2115 iter/s, 1.91529s/100 iters), loss = 0.876244
I0409 03:44:19.421531 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.876244 (* 1 = 0.876244 loss)
I0409 03:44:19.421557 13743 sgd_solver.cpp:112] Iteration 42900, lr = 0.0001
I0409 03:44:21.320345 13743 solver.cpp:347] Iteration 43000, Testing net (#0)
I0409 03:44:21.321846 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:21.630177 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09293 (* 1 = 1.09293 loss)
I0409 03:44:21.630215 13743 solver.cpp:414]     Test net output #1: accuracy = 0.599888
I0409 03:44:21.647594 13743 solver.cpp:239] Iteration 43000 (44.9221 iter/s, 2.22608s/100 iters), loss = 0.890641
I0409 03:44:21.647637 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.890641 (* 1 = 0.890641 loss)
I0409 03:44:21.647648 13743 sgd_solver.cpp:112] Iteration 43000, lr = 0.0001
I0409 03:44:22.783958 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:23.567498 13743 solver.cpp:239] Iteration 43100 (52.0871 iter/s, 1.91986s/100 iters), loss = 0.89571
I0409 03:44:23.567559 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.89571 (* 1 = 0.89571 loss)
I0409 03:44:23.567569 13743 sgd_solver.cpp:112] Iteration 43100, lr = 0.0001
I0409 03:44:25.484702 13743 solver.cpp:239] Iteration 43200 (52.1611 iter/s, 1.91714s/100 iters), loss = 1.04746
I0409 03:44:25.484791 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04746 (* 1 = 1.04746 loss)
I0409 03:44:25.484802 13743 sgd_solver.cpp:112] Iteration 43200, lr = 0.0001
I0409 03:44:27.400106 13743 solver.cpp:239] Iteration 43300 (52.2112 iter/s, 1.9153s/100 iters), loss = 0.950467
I0409 03:44:27.400177 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.950467 (* 1 = 0.950467 loss)
I0409 03:44:27.400185 13743 sgd_solver.cpp:112] Iteration 43300, lr = 0.0001
I0409 03:44:29.315415 13743 solver.cpp:239] Iteration 43400 (52.2127 iter/s, 1.91524s/100 iters), loss = 1.23819
I0409 03:44:29.315475 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.23819 (* 1 = 1.23819 loss)
I0409 03:44:29.315485 13743 sgd_solver.cpp:112] Iteration 43400, lr = 0.0001
I0409 03:44:31.239106 13743 solver.cpp:239] Iteration 43500 (51.985 iter/s, 1.92363s/100 iters), loss = 0.875555
I0409 03:44:31.239167 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.875555 (* 1 = 0.875555 loss)
I0409 03:44:31.239178 13743 sgd_solver.cpp:112] Iteration 43500, lr = 0.0001
I0409 03:44:31.394728 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:33.154564 13743 solver.cpp:239] Iteration 43600 (52.2084 iter/s, 1.9154s/100 iters), loss = 0.967266
I0409 03:44:33.154623 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.967266 (* 1 = 0.967266 loss)
I0409 03:44:33.154631 13743 sgd_solver.cpp:112] Iteration 43600, lr = 0.0001
I0409 03:44:35.076562 13743 solver.cpp:239] Iteration 43700 (52.0316 iter/s, 1.92191s/100 iters), loss = 0.897457
I0409 03:44:35.076650 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.897457 (* 1 = 0.897457 loss)
I0409 03:44:35.076661 13743 sgd_solver.cpp:112] Iteration 43700, lr = 0.0001
I0409 03:44:36.989910 13743 solver.cpp:239] Iteration 43800 (52.2669 iter/s, 1.91326s/100 iters), loss = 0.971696
I0409 03:44:36.989974 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.971696 (* 1 = 0.971696 loss)
I0409 03:44:36.989984 13743 sgd_solver.cpp:112] Iteration 43800, lr = 0.0001
I0409 03:44:38.905735 13743 solver.cpp:239] Iteration 43900 (52.1985 iter/s, 1.91576s/100 iters), loss = 0.692933
I0409 03:44:38.905802 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.692933 (* 1 = 0.692933 loss)
I0409 03:44:38.905812 13743 sgd_solver.cpp:112] Iteration 43900, lr = 0.0001
I0409 03:44:39.982595 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:40.798812 13743 solver.cpp:347] Iteration 44000, Testing net (#0)
I0409 03:44:40.800990 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:41.109851 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09534 (* 1 = 1.09534 loss)
I0409 03:44:41.109887 13743 solver.cpp:414]     Test net output #1: accuracy = 0.601283
I0409 03:44:41.127144 13743 solver.cpp:239] Iteration 44000 (45.0179 iter/s, 2.22134s/100 iters), loss = 0.914382
I0409 03:44:41.127216 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.914382 (* 1 = 0.914382 loss)
I0409 03:44:41.127243 13743 sgd_solver.cpp:112] Iteration 44000, lr = 0.0001
I0409 03:44:43.050917 13743 solver.cpp:239] Iteration 44100 (51.9828 iter/s, 1.92371s/100 iters), loss = 0.911195
I0409 03:44:43.050987 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.911195 (* 1 = 0.911195 loss)
I0409 03:44:43.050995 13743 sgd_solver.cpp:112] Iteration 44100, lr = 0.0001
I0409 03:44:44.967924 13743 solver.cpp:239] Iteration 44200 (52.1667 iter/s, 1.91693s/100 iters), loss = 1.0141
I0409 03:44:44.968003 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.0141 (* 1 = 1.0141 loss)
I0409 03:44:44.968013 13743 sgd_solver.cpp:112] Iteration 44200, lr = 0.0001
I0409 03:44:46.887908 13743 solver.cpp:239] Iteration 44300 (52.0862 iter/s, 1.91989s/100 iters), loss = 0.955602
I0409 03:44:46.887977 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.955602 (* 1 = 0.955602 loss)
I0409 03:44:46.887986 13743 sgd_solver.cpp:112] Iteration 44300, lr = 0.0001
I0409 03:44:48.803252 13743 solver.cpp:239] Iteration 44400 (52.212 iter/s, 1.91527s/100 iters), loss = 0.81627
I0409 03:44:48.803342 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.81627 (* 1 = 0.81627 loss)
I0409 03:44:48.803351 13743 sgd_solver.cpp:112] Iteration 44400, lr = 0.0001
I0409 03:44:48.902559 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:50.724419 13743 solver.cpp:239] Iteration 44500 (52.0543 iter/s, 1.92107s/100 iters), loss = 0.92469
I0409 03:44:50.724493 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.92469 (* 1 = 0.92469 loss)
I0409 03:44:50.724515 13743 sgd_solver.cpp:112] Iteration 44500, lr = 0.0001
I0409 03:44:52.641232 13743 solver.cpp:239] Iteration 44600 (52.1718 iter/s, 1.91674s/100 iters), loss = 0.937699
I0409 03:44:52.641304 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.937699 (* 1 = 0.937699 loss)
I0409 03:44:52.641312 13743 sgd_solver.cpp:112] Iteration 44600, lr = 0.0001
I0409 03:44:54.555394 13743 solver.cpp:239] Iteration 44700 (52.2441 iter/s, 1.91409s/100 iters), loss = 1.1521
I0409 03:44:54.555485 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.1521 (* 1 = 1.1521 loss)
I0409 03:44:54.555496 13743 sgd_solver.cpp:112] Iteration 44700, lr = 0.0001
I0409 03:44:56.472852 13743 solver.cpp:239] Iteration 44800 (52.1548 iter/s, 1.91737s/100 iters), loss = 0.988548
I0409 03:44:56.472928 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.988548 (* 1 = 0.988548 loss)
I0409 03:44:56.472939 13743 sgd_solver.cpp:112] Iteration 44800, lr = 0.0001
I0409 03:44:57.497216 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:44:58.394275 13743 solver.cpp:239] Iteration 44900 (52.0468 iter/s, 1.92135s/100 iters), loss = 0.7883
I0409 03:44:58.394351 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.7883 (* 1 = 0.7883 loss)
I0409 03:44:58.394359 13743 sgd_solver.cpp:112] Iteration 44900, lr = 0.0001
I0409 03:45:00.293220 13743 solver.cpp:347] Iteration 45000, Testing net (#0)
I0409 03:45:00.294122 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:00.601860 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.0954 (* 1 = 1.0954 loss)
I0409 03:45:00.601907 13743 solver.cpp:414]     Test net output #1: accuracy = 0.600167
I0409 03:45:00.619191 13743 solver.cpp:239] Iteration 45000 (44.9468 iter/s, 2.22485s/100 iters), loss = 1.24899
I0409 03:45:00.619237 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.24899 (* 1 = 1.24899 loss)
I0409 03:45:00.619258 13743 sgd_solver.cpp:112] Iteration 45000, lr = 0.0001
I0409 03:45:02.536867 13743 solver.cpp:239] Iteration 45100 (52.1476 iter/s, 1.91763s/100 iters), loss = 0.830647
I0409 03:45:02.536934 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.830647 (* 1 = 0.830647 loss)
I0409 03:45:02.536947 13743 sgd_solver.cpp:112] Iteration 45100, lr = 0.0001
I0409 03:45:04.452883 13743 solver.cpp:239] Iteration 45200 (52.1933 iter/s, 1.91595s/100 iters), loss = 0.80881
I0409 03:45:04.452960 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.80881 (* 1 = 0.80881 loss)
I0409 03:45:04.452972 13743 sgd_solver.cpp:112] Iteration 45200, lr = 0.0001
I0409 03:45:06.369477 13743 solver.cpp:239] Iteration 45300 (52.1779 iter/s, 1.91652s/100 iters), loss = 0.911938
I0409 03:45:06.369544 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.911938 (* 1 = 0.911938 loss)
I0409 03:45:06.369557 13743 sgd_solver.cpp:112] Iteration 45300, lr = 0.0001
I0409 03:45:06.412353 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:08.284250 13743 solver.cpp:239] Iteration 45400 (52.2274 iter/s, 1.9147s/100 iters), loss = 0.957988
I0409 03:45:08.284325 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.957988 (* 1 = 0.957988 loss)
I0409 03:45:08.284335 13743 sgd_solver.cpp:112] Iteration 45400, lr = 0.0001
I0409 03:45:10.201162 13743 solver.cpp:239] Iteration 45500 (52.1695 iter/s, 1.91683s/100 iters), loss = 1.00555
I0409 03:45:10.201236 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00555 (* 1 = 1.00555 loss)
I0409 03:45:10.201248 13743 sgd_solver.cpp:112] Iteration 45500, lr = 0.0001
I0409 03:45:12.120420 13743 solver.cpp:239] Iteration 45600 (52.1057 iter/s, 1.91918s/100 iters), loss = 0.841431
I0409 03:45:12.120483 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.841431 (* 1 = 0.841431 loss)
I0409 03:45:12.120509 13743 sgd_solver.cpp:112] Iteration 45600, lr = 0.0001
I0409 03:45:14.039155 13743 solver.cpp:239] Iteration 45700 (52.12 iter/s, 1.91865s/100 iters), loss = 1.04638
I0409 03:45:14.039283 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04638 (* 1 = 1.04638 loss)
I0409 03:45:14.039295 13743 sgd_solver.cpp:112] Iteration 45700, lr = 0.0001
I0409 03:45:15.002154 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:15.958796 13743 solver.cpp:239] Iteration 45800 (52.0965 iter/s, 1.91952s/100 iters), loss = 0.808918
I0409 03:45:15.958878 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.808918 (* 1 = 0.808918 loss)
I0409 03:45:15.958887 13743 sgd_solver.cpp:112] Iteration 45800, lr = 0.0001
I0409 03:45:17.879926 13743 solver.cpp:239] Iteration 45900 (52.055 iter/s, 1.92105s/100 iters), loss = 1.04008
I0409 03:45:17.880012 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04008 (* 1 = 1.04008 loss)
I0409 03:45:17.880023 13743 sgd_solver.cpp:112] Iteration 45900, lr = 0.0001
I0409 03:45:19.780092 13743 solver.cpp:347] Iteration 46000, Testing net (#0)
I0409 03:45:19.782681 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:20.092661 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10043 (* 1 = 1.10043 loss)
I0409 03:45:20.092730 13743 solver.cpp:414]     Test net output #1: accuracy = 0.597377
I0409 03:45:20.110106 13743 solver.cpp:239] Iteration 46000 (44.8412 iter/s, 2.23009s/100 iters), loss = 0.945714
I0409 03:45:20.110149 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.945714 (* 1 = 0.945714 loss)
I0409 03:45:20.110160 13743 sgd_solver.cpp:112] Iteration 46000, lr = 0.0001
I0409 03:45:22.026296 13743 solver.cpp:239] Iteration 46100 (52.1881 iter/s, 1.91615s/100 iters), loss = 0.731193
I0409 03:45:22.026372 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.731193 (* 1 = 0.731193 loss)
I0409 03:45:22.026382 13743 sgd_solver.cpp:112] Iteration 46100, lr = 0.0001
I0409 03:45:23.929589 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:23.945982 13743 solver.cpp:239] Iteration 46200 (52.0942 iter/s, 1.9196s/100 iters), loss = 0.898871
I0409 03:45:23.946072 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.898871 (* 1 = 0.898871 loss)
I0409 03:45:23.946097 13743 sgd_solver.cpp:112] Iteration 46200, lr = 0.0001
I0409 03:45:25.867939 13743 solver.cpp:239] Iteration 46300 (52.0324 iter/s, 1.92188s/100 iters), loss = 1.05517
I0409 03:45:25.868005 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05517 (* 1 = 1.05517 loss)
I0409 03:45:25.868014 13743 sgd_solver.cpp:112] Iteration 46300, lr = 0.0001
I0409 03:45:27.782951 13743 solver.cpp:239] Iteration 46400 (52.2212 iter/s, 1.91493s/100 iters), loss = 0.813578
I0409 03:45:27.783033 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.813578 (* 1 = 0.813578 loss)
I0409 03:45:27.783042 13743 sgd_solver.cpp:112] Iteration 46400, lr = 0.0001
I0409 03:45:29.693446 13743 solver.cpp:239] Iteration 46500 (52.3447 iter/s, 1.91041s/100 iters), loss = 0.82192
I0409 03:45:29.693517 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.82192 (* 1 = 0.82192 loss)
I0409 03:45:29.693526 13743 sgd_solver.cpp:112] Iteration 46500, lr = 0.0001
I0409 03:45:31.610103 13743 solver.cpp:239] Iteration 46600 (52.1762 iter/s, 1.91658s/100 iters), loss = 0.818558
I0409 03:45:31.610177 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.818558 (* 1 = 0.818558 loss)
I0409 03:45:31.610186 13743 sgd_solver.cpp:112] Iteration 46600, lr = 0.0001
I0409 03:45:32.534003 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:33.525569 13743 solver.cpp:239] Iteration 46700 (52.2086 iter/s, 1.91539s/100 iters), loss = 0.901863
I0409 03:45:33.525656 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.901863 (* 1 = 0.901863 loss)
I0409 03:45:33.525666 13743 sgd_solver.cpp:112] Iteration 46700, lr = 0.0001
I0409 03:45:35.444337 13743 solver.cpp:239] Iteration 46800 (52.1194 iter/s, 1.91867s/100 iters), loss = 1.14052
I0409 03:45:35.444423 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14052 (* 1 = 1.14052 loss)
I0409 03:45:35.444432 13743 sgd_solver.cpp:112] Iteration 46800, lr = 0.0001
I0409 03:45:37.358203 13743 solver.cpp:239] Iteration 46900 (52.2527 iter/s, 1.91378s/100 iters), loss = 0.98263
I0409 03:45:37.358278 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.98263 (* 1 = 0.98263 loss)
I0409 03:45:37.358287 13743 sgd_solver.cpp:112] Iteration 46900, lr = 0.0001
I0409 03:45:39.260177 13743 solver.cpp:347] Iteration 47000, Testing net (#0)
I0409 03:45:39.264261 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:39.570207 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09833 (* 1 = 1.09833 loss)
I0409 03:45:39.570282 13743 solver.cpp:414]     Test net output #1: accuracy = 0.601283
I0409 03:45:39.587507 13743 solver.cpp:239] Iteration 47000 (44.8583 iter/s, 2.22924s/100 iters), loss = 0.695673
I0409 03:45:39.587558 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.695673 (* 1 = 0.695673 loss)
I0409 03:45:39.587569 13743 sgd_solver.cpp:112] Iteration 47000, lr = 0.0001
I0409 03:45:41.427743 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:41.499848 13743 solver.cpp:239] Iteration 47100 (52.2933 iter/s, 1.91229s/100 iters), loss = 0.89461
I0409 03:45:41.499930 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.89461 (* 1 = 0.89461 loss)
I0409 03:45:41.499940 13743 sgd_solver.cpp:112] Iteration 47100, lr = 0.0001
I0409 03:45:43.405679 13743 solver.cpp:239] Iteration 47200 (52.4729 iter/s, 1.90575s/100 iters), loss = 0.908807
I0409 03:45:43.405753 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.908807 (* 1 = 0.908807 loss)
I0409 03:45:43.405762 13743 sgd_solver.cpp:112] Iteration 47200, lr = 0.0001
I0409 03:45:45.313122 13743 solver.cpp:239] Iteration 47300 (52.4282 iter/s, 1.90737s/100 iters), loss = 0.995664
I0409 03:45:45.313205 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.995664 (* 1 = 0.995664 loss)
I0409 03:45:45.313213 13743 sgd_solver.cpp:112] Iteration 47300, lr = 0.0001
I0409 03:45:47.217941 13743 solver.cpp:239] Iteration 47400 (52.5007 iter/s, 1.90474s/100 iters), loss = 0.891542
I0409 03:45:47.218009 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.891542 (* 1 = 0.891542 loss)
I0409 03:45:47.218019 13743 sgd_solver.cpp:112] Iteration 47400, lr = 0.0001
I0409 03:45:49.124964 13743 solver.cpp:239] Iteration 47500 (52.4396 iter/s, 1.90696s/100 iters), loss = 0.985277
I0409 03:45:49.125027 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.985277 (* 1 = 0.985277 loss)
I0409 03:45:49.125036 13743 sgd_solver.cpp:112] Iteration 47500, lr = 0.0001
I0409 03:45:49.986148 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:51.032470 13743 solver.cpp:239] Iteration 47600 (52.4262 iter/s, 1.90744s/100 iters), loss = 0.809574
I0409 03:45:51.032560 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.809574 (* 1 = 0.809574 loss)
I0409 03:45:51.032570 13743 sgd_solver.cpp:112] Iteration 47600, lr = 0.0001
I0409 03:45:52.952891 13743 solver.cpp:239] Iteration 47700 (52.0742 iter/s, 1.92034s/100 iters), loss = 1.15302
I0409 03:45:52.952982 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.15302 (* 1 = 1.15302 loss)
I0409 03:45:52.952993 13743 sgd_solver.cpp:112] Iteration 47700, lr = 0.0001
I0409 03:45:54.877470 13743 solver.cpp:239] Iteration 47800 (51.9623 iter/s, 1.92447s/100 iters), loss = 0.962879
I0409 03:45:54.877564 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.962879 (* 1 = 0.962879 loss)
I0409 03:45:54.877576 13743 sgd_solver.cpp:112] Iteration 47800, lr = 0.0001
I0409 03:45:56.791945 13743 solver.cpp:239] Iteration 47900 (52.2362 iter/s, 1.91438s/100 iters), loss = 0.917546
I0409 03:45:56.792026 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.917546 (* 1 = 0.917546 loss)
I0409 03:45:56.792035 13743 sgd_solver.cpp:112] Iteration 47900, lr = 0.0001
I0409 03:45:58.578083 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:58.690042 13743 solver.cpp:347] Iteration 48000, Testing net (#0)
I0409 03:45:58.692373 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:45:58.997917 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09936 (* 1 = 1.09936 loss)
I0409 03:45:58.997993 13743 solver.cpp:414]     Test net output #1: accuracy = 0.602958
I0409 03:45:59.015417 13743 solver.cpp:239] Iteration 48000 (44.9765 iter/s, 2.22338s/100 iters), loss = 0.905911
I0409 03:45:59.015512 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.905911 (* 1 = 0.905911 loss)
I0409 03:45:59.015527 13743 sgd_solver.cpp:112] Iteration 48000, lr = 0.0001
I0409 03:46:00.932696 13743 solver.cpp:239] Iteration 48100 (52.1598 iter/s, 1.91718s/100 iters), loss = 0.854288
I0409 03:46:00.932770 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.854288 (* 1 = 0.854288 loss)
I0409 03:46:00.932780 13743 sgd_solver.cpp:112] Iteration 48100, lr = 0.0001
I0409 03:46:02.845219 13743 solver.cpp:239] Iteration 48200 (52.2895 iter/s, 1.91243s/100 iters), loss = 1.06029
I0409 03:46:02.845294 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06029 (* 1 = 1.06029 loss)
I0409 03:46:02.845306 13743 sgd_solver.cpp:112] Iteration 48200, lr = 0.0001
I0409 03:46:04.764772 13743 solver.cpp:239] Iteration 48300 (52.0974 iter/s, 1.91948s/100 iters), loss = 0.90105
I0409 03:46:04.764849 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.90105 (* 1 = 0.90105 loss)
I0409 03:46:04.764859 13743 sgd_solver.cpp:112] Iteration 48300, lr = 0.0001
I0409 03:46:06.683099 13743 solver.cpp:239] Iteration 48400 (52.1308 iter/s, 1.91825s/100 iters), loss = 1.01568
I0409 03:46:06.683161 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01568 (* 1 = 1.01568 loss)
I0409 03:46:06.683171 13743 sgd_solver.cpp:112] Iteration 48400, lr = 0.0001
I0409 03:46:07.493459 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:08.599117 13743 solver.cpp:239] Iteration 48500 (52.1934 iter/s, 1.91595s/100 iters), loss = 1.14789
I0409 03:46:08.599193 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.14789 (* 1 = 1.14789 loss)
I0409 03:46:08.599205 13743 sgd_solver.cpp:112] Iteration 48500, lr = 0.0001
I0409 03:46:10.517874 13743 solver.cpp:239] Iteration 48600 (52.1191 iter/s, 1.91868s/100 iters), loss = 0.944698
I0409 03:46:10.517951 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.944698 (* 1 = 0.944698 loss)
I0409 03:46:10.517959 13743 sgd_solver.cpp:112] Iteration 48600, lr = 0.0001
I0409 03:46:12.438980 13743 solver.cpp:239] Iteration 48700 (52.0553 iter/s, 1.92103s/100 iters), loss = 0.965862
I0409 03:46:12.439046 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.965862 (* 1 = 0.965862 loss)
I0409 03:46:12.439055 13743 sgd_solver.cpp:112] Iteration 48700, lr = 0.0001
I0409 03:46:14.361840 13743 solver.cpp:239] Iteration 48800 (52.0077 iter/s, 1.92279s/100 iters), loss = 0.91074
I0409 03:46:14.361935 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.91074 (* 1 = 0.91074 loss)
I0409 03:46:14.361945 13743 sgd_solver.cpp:112] Iteration 48800, lr = 0.0001
I0409 03:46:16.112082 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:16.280724 13743 solver.cpp:239] Iteration 48900 (52.1161 iter/s, 1.91879s/100 iters), loss = 1.0471
I0409 03:46:16.280807 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.0471 (* 1 = 1.0471 loss)
I0409 03:46:16.280815 13743 sgd_solver.cpp:112] Iteration 48900, lr = 0.0001
I0409 03:46:18.184651 13743 solver.cpp:347] Iteration 49000, Testing net (#0)
I0409 03:46:18.187680 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:18.492300 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09385 (* 1 = 1.09385 loss)
I0409 03:46:18.492395 13743 solver.cpp:414]     Test net output #1: accuracy = 0.605748
I0409 03:46:18.509549 13743 solver.cpp:239] Iteration 49000 (44.8682 iter/s, 2.22875s/100 iters), loss = 1.16607
I0409 03:46:18.509604 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.16607 (* 1 = 1.16607 loss)
I0409 03:46:18.509635 13743 sgd_solver.cpp:112] Iteration 49000, lr = 0.0001
I0409 03:46:20.432307 13743 solver.cpp:239] Iteration 49100 (52.0098 iter/s, 1.92271s/100 iters), loss = 1.16486
I0409 03:46:20.432373 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.16486 (* 1 = 1.16486 loss)
I0409 03:46:20.432381 13743 sgd_solver.cpp:112] Iteration 49100, lr = 0.0001
I0409 03:46:22.349292 13743 solver.cpp:239] Iteration 49200 (52.1671 iter/s, 1.91692s/100 iters), loss = 0.987316
I0409 03:46:22.349368 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.987316 (* 1 = 0.987316 loss)
I0409 03:46:22.349380 13743 sgd_solver.cpp:112] Iteration 49200, lr = 0.0001
I0409 03:46:24.268040 13743 solver.cpp:239] Iteration 49300 (52.1193 iter/s, 1.91868s/100 iters), loss = 1.11542
I0409 03:46:24.268101 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.11542 (* 1 = 1.11542 loss)
I0409 03:46:24.268110 13743 sgd_solver.cpp:112] Iteration 49300, lr = 0.0001
I0409 03:46:25.018123 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:26.181237 13743 solver.cpp:239] Iteration 49400 (52.2706 iter/s, 1.91312s/100 iters), loss = 1.03152
I0409 03:46:26.181310 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03152 (* 1 = 1.03152 loss)
I0409 03:46:26.181319 13743 sgd_solver.cpp:112] Iteration 49400, lr = 0.0001
I0409 03:46:28.096259 13743 solver.cpp:239] Iteration 49500 (52.2207 iter/s, 1.91495s/100 iters), loss = 0.870421
I0409 03:46:28.096330 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.870421 (* 1 = 0.870421 loss)
I0409 03:46:28.096339 13743 sgd_solver.cpp:112] Iteration 49500, lr = 0.0001
I0409 03:46:30.015070 13743 solver.cpp:239] Iteration 49600 (52.1174 iter/s, 1.91874s/100 iters), loss = 0.924791
I0409 03:46:30.015136 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.924791 (* 1 = 0.924791 loss)
I0409 03:46:30.015143 13743 sgd_solver.cpp:112] Iteration 49600, lr = 0.0001
I0409 03:46:31.935683 13743 solver.cpp:239] Iteration 49700 (52.0687 iter/s, 1.92054s/100 iters), loss = 0.941788
I0409 03:46:31.935766 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.941788 (* 1 = 0.941788 loss)
I0409 03:46:31.935776 13743 sgd_solver.cpp:112] Iteration 49700, lr = 0.0001
I0409 03:46:33.626219 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:33.853246 13743 solver.cpp:239] Iteration 49800 (52.1518 iter/s, 1.91748s/100 iters), loss = 1.07581
I0409 03:46:33.853313 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07581 (* 1 = 1.07581 loss)
I0409 03:46:33.853322 13743 sgd_solver.cpp:112] Iteration 49800, lr = 0.0001
I0409 03:46:35.770309 13743 solver.cpp:239] Iteration 49900 (52.165 iter/s, 1.91699s/100 iters), loss = 0.852725
I0409 03:46:35.770385 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.852725 (* 1 = 0.852725 loss)
I0409 03:46:35.770393 13743 sgd_solver.cpp:112] Iteration 49900, lr = 0.0001
I0409 03:46:37.669294 13743 solver.cpp:464] Snapshotting to binary proto file ./FaceEmotionNet_model_iter_50000.caffemodel
I0409 03:46:37.750509 13743 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./FaceEmotionNet_model_iter_50000.solverstate
I0409 03:46:37.795698 13743 solver.cpp:347] Iteration 50000, Testing net (#0)
I0409 03:46:37.797040 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:38.103648 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09887 (* 1 = 1.09887 loss)
I0409 03:46:38.103689 13743 solver.cpp:414]     Test net output #1: accuracy = 0.597098
I0409 03:46:38.120890 13743 solver.cpp:239] Iteration 50000 (42.5438 iter/s, 2.35052s/100 iters), loss = 1.00517
I0409 03:46:38.120944 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.00517 (* 1 = 1.00517 loss)
I0409 03:46:38.120954 13743 sgd_solver.cpp:112] Iteration 50000, lr = 0.0001
I0409 03:46:40.036484 13743 solver.cpp:239] Iteration 50100 (52.2056 iter/s, 1.91551s/100 iters), loss = 0.830899
I0409 03:46:40.036573 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.830899 (* 1 = 0.830899 loss)
I0409 03:46:40.036582 13743 sgd_solver.cpp:112] Iteration 50100, lr = 0.0001
I0409 03:46:41.953794 13743 solver.cpp:239] Iteration 50200 (52.1591 iter/s, 1.91721s/100 iters), loss = 1.01217
I0409 03:46:41.953858 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01217 (* 1 = 1.01217 loss)
I0409 03:46:41.953868 13743 sgd_solver.cpp:112] Iteration 50200, lr = 0.0001
I0409 03:46:42.649509 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:43.872642 13743 solver.cpp:239] Iteration 50300 (52.1164 iter/s, 1.91878s/100 iters), loss = 0.945591
I0409 03:46:43.872740 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.945591 (* 1 = 0.945591 loss)
I0409 03:46:43.872750 13743 sgd_solver.cpp:112] Iteration 50300, lr = 0.0001
I0409 03:46:45.791769 13743 solver.cpp:239] Iteration 50400 (52.1096 iter/s, 1.91903s/100 iters), loss = 0.767289
I0409 03:46:45.791832 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.767289 (* 1 = 0.767289 loss)
I0409 03:46:45.791841 13743 sgd_solver.cpp:112] Iteration 50400, lr = 0.0001
I0409 03:46:47.709055 13743 solver.cpp:239] Iteration 50500 (52.1587 iter/s, 1.91722s/100 iters), loss = 0.916885
I0409 03:46:47.709120 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.916885 (* 1 = 0.916885 loss)
I0409 03:46:47.709146 13743 sgd_solver.cpp:112] Iteration 50500, lr = 0.0001
I0409 03:46:49.622642 13743 solver.cpp:239] Iteration 50600 (52.2598 iter/s, 1.91352s/100 iters), loss = 0.929555
I0409 03:46:49.622733 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.929555 (* 1 = 0.929555 loss)
I0409 03:46:49.622742 13743 sgd_solver.cpp:112] Iteration 50600, lr = 0.0001
I0409 03:46:51.252511 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:51.534813 13743 solver.cpp:239] Iteration 50700 (52.299 iter/s, 1.91208s/100 iters), loss = 0.884459
I0409 03:46:51.534898 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.884459 (* 1 = 0.884459 loss)
I0409 03:46:51.534917 13743 sgd_solver.cpp:112] Iteration 50700, lr = 0.0001
I0409 03:46:53.451908 13743 solver.cpp:239] Iteration 50800 (52.1647 iter/s, 1.91701s/100 iters), loss = 0.707567
I0409 03:46:53.451977 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.707567 (* 1 = 0.707567 loss)
I0409 03:46:53.451987 13743 sgd_solver.cpp:112] Iteration 50800, lr = 0.0001
I0409 03:46:55.371605 13743 solver.cpp:239] Iteration 50900 (52.0934 iter/s, 1.91963s/100 iters), loss = 1.01766
I0409 03:46:55.371675 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01766 (* 1 = 1.01766 loss)
I0409 03:46:55.371683 13743 sgd_solver.cpp:112] Iteration 50900, lr = 0.0001
I0409 03:46:57.277070 13743 solver.cpp:347] Iteration 51000, Testing net (#0)
I0409 03:46:57.278827 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:46:57.587690 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10613 (* 1 = 1.10613 loss)
I0409 03:46:57.587730 13743 solver.cpp:414]     Test net output #1: accuracy = 0.596819
I0409 03:46:57.605062 13743 solver.cpp:239] Iteration 51000 (44.7748 iter/s, 2.2334s/100 iters), loss = 1.08498
I0409 03:46:57.605108 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.08498 (* 1 = 1.08498 loss)
I0409 03:46:57.605119 13743 sgd_solver.cpp:112] Iteration 51000, lr = 0.0001
I0409 03:46:59.524281 13743 solver.cpp:239] Iteration 51100 (52.1058 iter/s, 1.91917s/100 iters), loss = 0.695486
I0409 03:46:59.524351 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.695486 (* 1 = 0.695486 loss)
I0409 03:46:59.524361 13743 sgd_solver.cpp:112] Iteration 51100, lr = 0.0001
I0409 03:47:00.160456 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:01.438629 13743 solver.cpp:239] Iteration 51200 (52.2389 iter/s, 1.91428s/100 iters), loss = 0.702177
I0409 03:47:01.438689 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.702177 (* 1 = 0.702177 loss)
I0409 03:47:01.438701 13743 sgd_solver.cpp:112] Iteration 51200, lr = 0.0001
I0409 03:47:03.359747 13743 solver.cpp:239] Iteration 51300 (52.055 iter/s, 1.92105s/100 iters), loss = 0.952665
I0409 03:47:03.359812 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.952665 (* 1 = 0.952665 loss)
I0409 03:47:03.359822 13743 sgd_solver.cpp:112] Iteration 51300, lr = 0.0001
I0409 03:47:05.275676 13743 solver.cpp:239] Iteration 51400 (52.1963 iter/s, 1.91585s/100 iters), loss = 0.961489
I0409 03:47:05.275755 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.961489 (* 1 = 0.961489 loss)
I0409 03:47:05.275764 13743 sgd_solver.cpp:112] Iteration 51400, lr = 0.0001
I0409 03:47:07.191476 13743 solver.cpp:239] Iteration 51500 (52.1996 iter/s, 1.91572s/100 iters), loss = 1.03659
I0409 03:47:07.191563 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03659 (* 1 = 1.03659 loss)
I0409 03:47:07.191573 13743 sgd_solver.cpp:112] Iteration 51500, lr = 0.0001
I0409 03:47:08.770678 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:09.111276 13743 solver.cpp:239] Iteration 51600 (52.0911 iter/s, 1.91971s/100 iters), loss = 0.868592
I0409 03:47:09.111351 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.868592 (* 1 = 0.868592 loss)
I0409 03:47:09.111361 13743 sgd_solver.cpp:112] Iteration 51600, lr = 0.0001
I0409 03:47:11.026688 13743 solver.cpp:239] Iteration 51700 (52.2102 iter/s, 1.91534s/100 iters), loss = 0.929463
I0409 03:47:11.026760 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.929463 (* 1 = 0.929463 loss)
I0409 03:47:11.026770 13743 sgd_solver.cpp:112] Iteration 51700, lr = 0.0001
I0409 03:47:12.945333 13743 solver.cpp:239] Iteration 51800 (52.1221 iter/s, 1.91857s/100 iters), loss = 1.11407
I0409 03:47:12.945405 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.11407 (* 1 = 1.11407 loss)
I0409 03:47:12.945413 13743 sgd_solver.cpp:112] Iteration 51800, lr = 0.0001
I0409 03:47:14.862426 13743 solver.cpp:239] Iteration 51900 (52.1642 iter/s, 1.91702s/100 iters), loss = 1.02036
I0409 03:47:14.862485 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.02036 (* 1 = 1.02036 loss)
I0409 03:47:14.862493 13743 sgd_solver.cpp:112] Iteration 51900, lr = 0.0001
I0409 03:47:16.764466 13743 solver.cpp:347] Iteration 52000, Testing net (#0)
I0409 03:47:16.771222 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:17.073087 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09687 (* 1 = 1.09687 loss)
I0409 03:47:17.073148 13743 solver.cpp:414]     Test net output #1: accuracy = 0.595703
I0409 03:47:17.090314 13743 solver.cpp:239] Iteration 52000 (44.8865 iter/s, 2.22784s/100 iters), loss = 0.870722
I0409 03:47:17.090358 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.870722 (* 1 = 0.870722 loss)
I0409 03:47:17.090370 13743 sgd_solver.cpp:112] Iteration 52000, lr = 0.0001
I0409 03:47:17.689312 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:19.011813 13743 solver.cpp:239] Iteration 52100 (52.0439 iter/s, 1.92146s/100 iters), loss = 1.07633
I0409 03:47:19.011873 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.07633 (* 1 = 1.07633 loss)
I0409 03:47:19.011881 13743 sgd_solver.cpp:112] Iteration 52100, lr = 0.0001
I0409 03:47:20.930636 13743 solver.cpp:239] Iteration 52200 (52.117 iter/s, 1.91876s/100 iters), loss = 0.908493
I0409 03:47:20.930725 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.908493 (* 1 = 0.908493 loss)
I0409 03:47:20.930734 13743 sgd_solver.cpp:112] Iteration 52200, lr = 0.0001
I0409 03:47:22.840672 13743 solver.cpp:239] Iteration 52300 (52.3575 iter/s, 1.90995s/100 iters), loss = 0.941682
I0409 03:47:22.840749 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.941682 (* 1 = 0.941682 loss)
I0409 03:47:22.840759 13743 sgd_solver.cpp:112] Iteration 52300, lr = 0.0001
I0409 03:47:24.745602 13743 solver.cpp:239] Iteration 52400 (52.4975 iter/s, 1.90485s/100 iters), loss = 1.06391
I0409 03:47:24.745676 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06391 (* 1 = 1.06391 loss)
I0409 03:47:24.745683 13743 sgd_solver.cpp:112] Iteration 52400, lr = 0.0001
I0409 03:47:26.253363 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:26.649796 13743 solver.cpp:239] Iteration 52500 (52.5177 iter/s, 1.90412s/100 iters), loss = 1.16911
I0409 03:47:26.649865 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.16911 (* 1 = 1.16911 loss)
I0409 03:47:26.649873 13743 sgd_solver.cpp:112] Iteration 52500, lr = 0.0001
I0409 03:47:28.563458 13743 solver.cpp:239] Iteration 52600 (52.2578 iter/s, 1.91359s/100 iters), loss = 0.883894
I0409 03:47:28.563554 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.883894 (* 1 = 0.883894 loss)
I0409 03:47:28.563562 13743 sgd_solver.cpp:112] Iteration 52600, lr = 0.0001
I0409 03:47:30.482384 13743 solver.cpp:239] Iteration 52700 (52.1151 iter/s, 1.91883s/100 iters), loss = 0.983286
I0409 03:47:30.482462 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.983286 (* 1 = 0.983286 loss)
I0409 03:47:30.482471 13743 sgd_solver.cpp:112] Iteration 52700, lr = 0.0001
I0409 03:47:32.401358 13743 solver.cpp:239] Iteration 52800 (52.1133 iter/s, 1.91889s/100 iters), loss = 0.942858
I0409 03:47:32.401499 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.942858 (* 1 = 0.942858 loss)
I0409 03:47:32.401506 13743 sgd_solver.cpp:112] Iteration 52800, lr = 0.0001
I0409 03:47:34.316674 13743 solver.cpp:239] Iteration 52900 (52.2144 iter/s, 1.91518s/100 iters), loss = 0.949316
I0409 03:47:34.316740 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.949316 (* 1 = 0.949316 loss)
I0409 03:47:34.316748 13743 sgd_solver.cpp:112] Iteration 52900, lr = 0.0001
I0409 03:47:34.857458 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:36.220634 13743 solver.cpp:347] Iteration 53000, Testing net (#0)
I0409 03:47:36.227385 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:36.528882 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.0964 (* 1 = 1.0964 loss)
I0409 03:47:36.528957 13743 solver.cpp:414]     Test net output #1: accuracy = 0.605748
I0409 03:47:36.546187 13743 solver.cpp:239] Iteration 53000 (44.8542 iter/s, 2.22944s/100 iters), loss = 1.05325
I0409 03:47:36.546248 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05325 (* 1 = 1.05325 loss)
I0409 03:47:36.546265 13743 sgd_solver.cpp:112] Iteration 53000, lr = 0.0001
I0409 03:47:38.465957 13743 solver.cpp:239] Iteration 53100 (52.0913 iter/s, 1.91971s/100 iters), loss = 0.996786
I0409 03:47:38.466055 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.996786 (* 1 = 0.996786 loss)
I0409 03:47:38.466071 13743 sgd_solver.cpp:112] Iteration 53100, lr = 0.0001
I0409 03:47:40.379595 13743 solver.cpp:239] Iteration 53200 (52.2589 iter/s, 1.91355s/100 iters), loss = 1.06743
I0409 03:47:40.379693 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06743 (* 1 = 1.06743 loss)
I0409 03:47:40.379701 13743 sgd_solver.cpp:112] Iteration 53200, lr = 0.0001
I0409 03:47:42.295836 13743 solver.cpp:239] Iteration 53300 (52.188 iter/s, 1.91615s/100 iters), loss = 1.03021
I0409 03:47:42.295895 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03021 (* 1 = 1.03021 loss)
I0409 03:47:42.295912 13743 sgd_solver.cpp:112] Iteration 53300, lr = 0.0001
I0409 03:47:43.756808 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:44.214395 13743 solver.cpp:239] Iteration 53400 (52.1242 iter/s, 1.91849s/100 iters), loss = 1.11694
I0409 03:47:44.214473 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.11694 (* 1 = 1.11694 loss)
I0409 03:47:44.214481 13743 sgd_solver.cpp:112] Iteration 53400, lr = 0.0001
I0409 03:47:46.134634 13743 solver.cpp:239] Iteration 53500 (52.0789 iter/s, 1.92017s/100 iters), loss = 1.26468
I0409 03:47:46.134711 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.26468 (* 1 = 1.26468 loss)
I0409 03:47:46.134719 13743 sgd_solver.cpp:112] Iteration 53500, lr = 0.0001
I0409 03:47:48.048668 13743 solver.cpp:239] Iteration 53600 (52.2478 iter/s, 1.91396s/100 iters), loss = 0.909959
I0409 03:47:48.048735 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.909959 (* 1 = 0.909959 loss)
I0409 03:47:48.048744 13743 sgd_solver.cpp:112] Iteration 53600, lr = 0.0001
I0409 03:47:49.960703 13743 solver.cpp:239] Iteration 53700 (52.3021 iter/s, 1.91197s/100 iters), loss = 1.03561
I0409 03:47:49.960772 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.03561 (* 1 = 1.03561 loss)
I0409 03:47:49.960781 13743 sgd_solver.cpp:112] Iteration 53700, lr = 0.0001
I0409 03:47:51.874047 13743 solver.cpp:239] Iteration 53800 (52.2664 iter/s, 1.91327s/100 iters), loss = 0.966857
I0409 03:47:51.874123 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.966857 (* 1 = 0.966857 loss)
I0409 03:47:51.874133 13743 sgd_solver.cpp:112] Iteration 53800, lr = 0.0001
I0409 03:47:52.357836 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:53.791427 13743 solver.cpp:239] Iteration 53900 (52.1566 iter/s, 1.9173s/100 iters), loss = 0.72255
I0409 03:47:53.791499 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.72255 (* 1 = 0.72255 loss)
I0409 03:47:53.791509 13743 sgd_solver.cpp:112] Iteration 53900, lr = 0.0001
I0409 03:47:55.689011 13743 solver.cpp:347] Iteration 54000, Testing net (#0)
I0409 03:47:55.695860 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:47:55.999222 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09602 (* 1 = 1.09602 loss)
I0409 03:47:55.999267 13743 solver.cpp:414]     Test net output #1: accuracy = 0.604632
I0409 03:47:56.016666 13743 solver.cpp:239] Iteration 54000 (44.9402 iter/s, 2.22518s/100 iters), loss = 0.786977
I0409 03:47:56.016710 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.786977 (* 1 = 0.786977 loss)
I0409 03:47:56.016721 13743 sgd_solver.cpp:112] Iteration 54000, lr = 0.0001
I0409 03:47:57.935394 13743 solver.cpp:239] Iteration 54100 (52.1191 iter/s, 1.91868s/100 iters), loss = 0.822127
I0409 03:47:57.935464 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.822127 (* 1 = 0.822127 loss)
I0409 03:47:57.935473 13743 sgd_solver.cpp:112] Iteration 54100, lr = 0.0001
I0409 03:47:59.846482 13743 solver.cpp:239] Iteration 54200 (52.3286 iter/s, 1.911s/100 iters), loss = 0.841605
I0409 03:47:59.846606 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.841605 (* 1 = 0.841605 loss)
I0409 03:47:59.846616 13743 sgd_solver.cpp:112] Iteration 54200, lr = 0.0001
I0409 03:48:01.253541 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:01.766327 13743 solver.cpp:239] Iteration 54300 (52.0911 iter/s, 1.91971s/100 iters), loss = 0.974233
I0409 03:48:01.766433 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.974233 (* 1 = 0.974233 loss)
I0409 03:48:01.766443 13743 sgd_solver.cpp:112] Iteration 54300, lr = 0.0001
I0409 03:48:03.680104 13743 solver.cpp:239] Iteration 54400 (52.2559 iter/s, 1.91366s/100 iters), loss = 1.11048
I0409 03:48:03.680171 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.11048 (* 1 = 1.11048 loss)
I0409 03:48:03.680179 13743 sgd_solver.cpp:112] Iteration 54400, lr = 0.0001
I0409 03:48:05.597365 13743 solver.cpp:239] Iteration 54500 (52.1599 iter/s, 1.91718s/100 iters), loss = 0.848224
I0409 03:48:05.597435 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.848224 (* 1 = 0.848224 loss)
I0409 03:48:05.597445 13743 sgd_solver.cpp:112] Iteration 54500, lr = 0.0001
I0409 03:48:07.512840 13743 solver.cpp:239] Iteration 54600 (52.2082 iter/s, 1.91541s/100 iters), loss = 0.920097
I0409 03:48:07.512964 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.920097 (* 1 = 0.920097 loss)
I0409 03:48:07.512974 13743 sgd_solver.cpp:112] Iteration 54600, lr = 0.0001
I0409 03:48:09.431129 13743 solver.cpp:239] Iteration 54700 (52.133 iter/s, 1.91817s/100 iters), loss = 0.845253
I0409 03:48:09.431193 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.845253 (* 1 = 0.845253 loss)
I0409 03:48:09.431202 13743 sgd_solver.cpp:112] Iteration 54700, lr = 0.0001
I0409 03:48:09.857357 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:11.352996 13743 solver.cpp:239] Iteration 54800 (52.0345 iter/s, 1.9218s/100 iters), loss = 0.862427
I0409 03:48:11.353061 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.862427 (* 1 = 0.862427 loss)
I0409 03:48:11.353070 13743 sgd_solver.cpp:112] Iteration 54800, lr = 0.0001
I0409 03:48:13.266458 13743 solver.cpp:239] Iteration 54900 (52.2631 iter/s, 1.9134s/100 iters), loss = 0.918883
I0409 03:48:13.266530 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.918883 (* 1 = 0.918883 loss)
I0409 03:48:13.266538 13743 sgd_solver.cpp:112] Iteration 54900, lr = 0.0001
I0409 03:48:15.165946 13743 solver.cpp:347] Iteration 55000, Testing net (#0)
I0409 03:48:15.173055 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:15.476860 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.0981 (* 1 = 1.0981 loss)
I0409 03:48:15.476912 13743 solver.cpp:414]     Test net output #1: accuracy = 0.599051
I0409 03:48:15.494331 13743 solver.cpp:239] Iteration 55000 (44.8875 iter/s, 2.22779s/100 iters), loss = 0.902707
I0409 03:48:15.494401 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.902707 (* 1 = 0.902707 loss)
I0409 03:48:15.494411 13743 sgd_solver.cpp:112] Iteration 55000, lr = 0.0001
I0409 03:48:17.418398 13743 solver.cpp:239] Iteration 55100 (51.9752 iter/s, 1.92399s/100 iters), loss = 0.931871
I0409 03:48:17.418543 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.931871 (* 1 = 0.931871 loss)
I0409 03:48:17.418561 13743 sgd_solver.cpp:112] Iteration 55100, lr = 0.0001
I0409 03:48:18.783318 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:19.336146 13743 solver.cpp:239] Iteration 55200 (52.1472 iter/s, 1.91765s/100 iters), loss = 0.957542
I0409 03:48:19.336207 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.957542 (* 1 = 0.957542 loss)
I0409 03:48:19.336216 13743 sgd_solver.cpp:112] Iteration 55200, lr = 0.0001
I0409 03:48:21.250973 13743 solver.cpp:239] Iteration 55300 (52.2258 iter/s, 1.91476s/100 iters), loss = 1.06578
I0409 03:48:21.251076 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.06578 (* 1 = 1.06578 loss)
I0409 03:48:21.251085 13743 sgd_solver.cpp:112] Iteration 55300, lr = 0.0001
I0409 03:48:23.168478 13743 solver.cpp:239] Iteration 55400 (52.1539 iter/s, 1.9174s/100 iters), loss = 0.812422
I0409 03:48:23.168555 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.812422 (* 1 = 0.812422 loss)
I0409 03:48:23.168566 13743 sgd_solver.cpp:112] Iteration 55400, lr = 0.0001
I0409 03:48:25.089220 13743 solver.cpp:239] Iteration 55500 (52.0653 iter/s, 1.92067s/100 iters), loss = 0.906304
I0409 03:48:25.089280 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.906304 (* 1 = 0.906304 loss)
I0409 03:48:25.089289 13743 sgd_solver.cpp:112] Iteration 55500, lr = 0.0001
I0409 03:48:27.009346 13743 solver.cpp:239] Iteration 55600 (52.0815 iter/s, 1.92007s/100 iters), loss = 0.820241
I0409 03:48:27.009418 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.820241 (* 1 = 0.820241 loss)
I0409 03:48:27.009426 13743 sgd_solver.cpp:112] Iteration 55600, lr = 0.0001
I0409 03:48:27.380758 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:28.927784 13743 solver.cpp:239] Iteration 55700 (52.1277 iter/s, 1.91837s/100 iters), loss = 1.01366
I0409 03:48:28.927857 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01366 (* 1 = 1.01366 loss)
I0409 03:48:28.927866 13743 sgd_solver.cpp:112] Iteration 55700, lr = 0.0001
I0409 03:48:30.843781 13743 solver.cpp:239] Iteration 55800 (52.1946 iter/s, 1.91591s/100 iters), loss = 0.78759
I0409 03:48:30.843869 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.78759 (* 1 = 0.78759 loss)
I0409 03:48:30.843883 13743 sgd_solver.cpp:112] Iteration 55800, lr = 0.0001
I0409 03:48:32.754154 13743 solver.cpp:239] Iteration 55900 (52.3488 iter/s, 1.91026s/100 iters), loss = 0.96599
I0409 03:48:32.754288 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.96599 (* 1 = 0.96599 loss)
I0409 03:48:32.754297 13743 sgd_solver.cpp:112] Iteration 55900, lr = 0.0001
I0409 03:48:34.647647 13743 solver.cpp:347] Iteration 56000, Testing net (#0)
I0409 03:48:34.654040 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:34.956380 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.09833 (* 1 = 1.09833 loss)
I0409 03:48:34.956426 13743 solver.cpp:414]     Test net output #1: accuracy = 0.6024
I0409 03:48:34.973852 13743 solver.cpp:239] Iteration 56000 (45.0536 iter/s, 2.21958s/100 iters), loss = 1.04965
I0409 03:48:34.973896 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.04965 (* 1 = 1.04965 loss)
I0409 03:48:34.973999 13743 sgd_solver.cpp:112] Iteration 56000, lr = 0.0001
I0409 03:48:36.284091 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:36.892323 13743 solver.cpp:239] Iteration 56100 (52.1262 iter/s, 1.91842s/100 iters), loss = 0.870063
I0409 03:48:36.892405 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.870063 (* 1 = 0.870063 loss)
I0409 03:48:36.892416 13743 sgd_solver.cpp:112] Iteration 56100, lr = 0.0001
I0409 03:48:38.809092 13743 solver.cpp:239] Iteration 56200 (52.1735 iter/s, 1.91668s/100 iters), loss = 0.844239
I0409 03:48:38.809175 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.844239 (* 1 = 0.844239 loss)
I0409 03:48:38.809185 13743 sgd_solver.cpp:112] Iteration 56200, lr = 0.0001
I0409 03:48:40.724439 13743 solver.cpp:239] Iteration 56300 (52.2121 iter/s, 1.91526s/100 iters), loss = 0.680047
I0409 03:48:40.724521 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.680047 (* 1 = 0.680047 loss)
I0409 03:48:40.724530 13743 sgd_solver.cpp:112] Iteration 56300, lr = 0.0001
I0409 03:48:42.639447 13743 solver.cpp:239] Iteration 56400 (52.2213 iter/s, 1.91493s/100 iters), loss = 0.911106
I0409 03:48:42.639533 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.911106 (* 1 = 0.911106 loss)
I0409 03:48:42.639542 13743 sgd_solver.cpp:112] Iteration 56400, lr = 0.0001
I0409 03:48:44.556289 13743 solver.cpp:239] Iteration 56500 (52.1716 iter/s, 1.91675s/100 iters), loss = 0.827478
I0409 03:48:44.556375 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.827478 (* 1 = 0.827478 loss)
I0409 03:48:44.556385 13743 sgd_solver.cpp:112] Iteration 56500, lr = 0.0001
I0409 03:48:44.866364 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:46.478013 13743 solver.cpp:239] Iteration 56600 (52.0391 iter/s, 1.92163s/100 iters), loss = 0.740181
I0409 03:48:46.478096 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.740181 (* 1 = 0.740181 loss)
I0409 03:48:46.478106 13743 sgd_solver.cpp:112] Iteration 56600, lr = 0.0001
I0409 03:48:48.396248 13743 solver.cpp:239] Iteration 56700 (52.1339 iter/s, 1.91814s/100 iters), loss = 1.18383
I0409 03:48:48.396309 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.18383 (* 1 = 1.18383 loss)
I0409 03:48:48.396317 13743 sgd_solver.cpp:112] Iteration 56700, lr = 0.0001
I0409 03:48:50.314887 13743 solver.cpp:239] Iteration 56800 (52.1219 iter/s, 1.91858s/100 iters), loss = 0.997289
I0409 03:48:50.314956 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.997289 (* 1 = 0.997289 loss)
I0409 03:48:50.314965 13743 sgd_solver.cpp:112] Iteration 56800, lr = 0.0001
I0409 03:48:52.230408 13743 solver.cpp:239] Iteration 56900 (52.207 iter/s, 1.91545s/100 iters), loss = 0.953094
I0409 03:48:52.230487 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.953094 (* 1 = 0.953094 loss)
I0409 03:48:52.230497 13743 sgd_solver.cpp:112] Iteration 56900, lr = 0.0001
I0409 03:48:53.481426 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:54.129385 13743 solver.cpp:347] Iteration 57000, Testing net (#0)
I0409 03:48:54.136541 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:48:54.437660 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10504 (* 1 = 1.10504 loss)
I0409 03:48:54.437703 13743 solver.cpp:414]     Test net output #1: accuracy = 0.600167
I0409 03:48:54.454921 13743 solver.cpp:239] Iteration 57000 (44.9551 iter/s, 2.22444s/100 iters), loss = 0.94501
I0409 03:48:54.454969 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.94501 (* 1 = 0.94501 loss)
I0409 03:48:54.454982 13743 sgd_solver.cpp:112] Iteration 57000, lr = 0.0001
I0409 03:48:56.373564 13743 solver.cpp:239] Iteration 57100 (52.1215 iter/s, 1.91859s/100 iters), loss = 1.05261
I0409 03:48:56.373684 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.05261 (* 1 = 1.05261 loss)
I0409 03:48:56.373693 13743 sgd_solver.cpp:112] Iteration 57100, lr = 0.0001
I0409 03:48:58.290979 13743 solver.cpp:239] Iteration 57200 (52.1563 iter/s, 1.91732s/100 iters), loss = 0.949747
I0409 03:48:58.291030 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.949747 (* 1 = 0.949747 loss)
I0409 03:48:58.291038 13743 sgd_solver.cpp:112] Iteration 57200, lr = 0.0001
I0409 03:49:00.209319 13743 solver.cpp:239] Iteration 57300 (52.1299 iter/s, 1.91829s/100 iters), loss = 0.931761
I0409 03:49:00.209394 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.931761 (* 1 = 0.931761 loss)
I0409 03:49:00.209405 13743 sgd_solver.cpp:112] Iteration 57300, lr = 0.0001
I0409 03:49:02.129407 13743 solver.cpp:239] Iteration 57400 (52.083 iter/s, 1.92001s/100 iters), loss = 0.872211
I0409 03:49:02.129503 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.872211 (* 1 = 0.872211 loss)
I0409 03:49:02.129513 13743 sgd_solver.cpp:112] Iteration 57400, lr = 0.0001
I0409 03:49:02.382056 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:04.047121 13743 solver.cpp:239] Iteration 57500 (52.1482 iter/s, 1.91761s/100 iters), loss = 0.857764
I0409 03:49:04.047201 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.857764 (* 1 = 0.857764 loss)
I0409 03:49:04.047210 13743 sgd_solver.cpp:112] Iteration 57500, lr = 0.0001
I0409 03:49:05.967475 13743 solver.cpp:239] Iteration 57600 (52.0758 iter/s, 1.92028s/100 iters), loss = 0.745572
I0409 03:49:05.967572 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.745572 (* 1 = 0.745572 loss)
I0409 03:49:05.967581 13743 sgd_solver.cpp:112] Iteration 57600, lr = 0.0001
I0409 03:49:07.886044 13743 solver.cpp:239] Iteration 57700 (52.1239 iter/s, 1.9185s/100 iters), loss = 0.846616
I0409 03:49:07.886129 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.846616 (* 1 = 0.846616 loss)
I0409 03:49:07.886138 13743 sgd_solver.cpp:112] Iteration 57700, lr = 0.0001
I0409 03:49:09.806545 13743 solver.cpp:239] Iteration 57800 (52.0719 iter/s, 1.92042s/100 iters), loss = 0.826644
I0409 03:49:09.806609 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.826644 (* 1 = 0.826644 loss)
I0409 03:49:09.806617 13743 sgd_solver.cpp:112] Iteration 57800, lr = 0.0001
I0409 03:49:10.998919 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:11.724434 13743 solver.cpp:239] Iteration 57900 (52.1425 iter/s, 1.91782s/100 iters), loss = 1.0205
I0409 03:49:11.724510 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.0205 (* 1 = 1.0205 loss)
I0409 03:49:11.724519 13743 sgd_solver.cpp:112] Iteration 57900, lr = 0.0001
I0409 03:49:13.620740 13743 solver.cpp:347] Iteration 58000, Testing net (#0)
I0409 03:49:13.628105 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:13.928369 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10213 (* 1 = 1.10213 loss)
I0409 03:49:13.928413 13743 solver.cpp:414]     Test net output #1: accuracy = 0.596819
I0409 03:49:13.945739 13743 solver.cpp:239] Iteration 58000 (45.0199 iter/s, 2.22124s/100 iters), loss = 0.887578
I0409 03:49:13.945785 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.887578 (* 1 = 0.887578 loss)
I0409 03:49:13.945796 13743 sgd_solver.cpp:112] Iteration 58000, lr = 0.0001
I0409 03:49:15.862381 13743 solver.cpp:239] Iteration 58100 (52.1759 iter/s, 1.91659s/100 iters), loss = 0.816546
I0409 03:49:15.862488 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.816546 (* 1 = 0.816546 loss)
I0409 03:49:15.862498 13743 sgd_solver.cpp:112] Iteration 58100, lr = 0.0001
I0409 03:49:17.779814 13743 solver.cpp:239] Iteration 58200 (52.1555 iter/s, 1.91734s/100 iters), loss = 0.651012
I0409 03:49:17.779872 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.651012 (* 1 = 0.651012 loss)
I0409 03:49:17.779881 13743 sgd_solver.cpp:112] Iteration 58200, lr = 0.0001
I0409 03:49:19.696983 13743 solver.cpp:239] Iteration 58300 (52.1619 iter/s, 1.91711s/100 iters), loss = 0.953017
I0409 03:49:19.697065 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.953017 (* 1 = 0.953017 loss)
I0409 03:49:19.697074 13743 sgd_solver.cpp:112] Iteration 58300, lr = 0.0001
I0409 03:49:19.911324 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:21.614696 13743 solver.cpp:239] Iteration 58400 (52.1475 iter/s, 1.91764s/100 iters), loss = 1.13325
I0409 03:49:21.614763 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13325 (* 1 = 1.13325 loss)
I0409 03:49:21.614773 13743 sgd_solver.cpp:112] Iteration 58400, lr = 0.0001
I0409 03:49:23.533545 13743 solver.cpp:239] Iteration 58500 (52.1164 iter/s, 1.91878s/100 iters), loss = 1.01583
I0409 03:49:23.533625 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01583 (* 1 = 1.01583 loss)
I0409 03:49:23.533634 13743 sgd_solver.cpp:112] Iteration 58500, lr = 0.0001
I0409 03:49:25.449779 13743 solver.cpp:239] Iteration 58600 (52.1882 iter/s, 1.91614s/100 iters), loss = 0.8793
I0409 03:49:25.449849 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.8793 (* 1 = 0.8793 loss)
I0409 03:49:25.449858 13743 sgd_solver.cpp:112] Iteration 58600, lr = 0.0001
I0409 03:49:27.366776 13743 solver.cpp:239] Iteration 58700 (52.1668 iter/s, 1.91693s/100 iters), loss = 0.856153
I0409 03:49:27.366847 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.856153 (* 1 = 0.856153 loss)
I0409 03:49:27.366854 13743 sgd_solver.cpp:112] Iteration 58700, lr = 0.0001
I0409 03:49:28.501206 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:29.281875 13743 solver.cpp:239] Iteration 58800 (52.2185 iter/s, 1.91503s/100 iters), loss = 0.858189
I0409 03:49:29.281945 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.858189 (* 1 = 0.858189 loss)
I0409 03:49:29.281955 13743 sgd_solver.cpp:112] Iteration 58800, lr = 0.0001
I0409 03:49:31.195595 13743 solver.cpp:239] Iteration 58900 (52.2567 iter/s, 1.91363s/100 iters), loss = 1.01537
I0409 03:49:31.195669 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.01537 (* 1 = 1.01537 loss)
I0409 03:49:31.195678 13743 sgd_solver.cpp:112] Iteration 58900, lr = 0.0001
I0409 03:49:33.095028 13743 solver.cpp:347] Iteration 59000, Testing net (#0)
I0409 03:49:33.101491 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:33.405151 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10047 (* 1 = 1.10047 loss)
I0409 03:49:33.405228 13743 solver.cpp:414]     Test net output #1: accuracy = 0.600167
I0409 03:49:33.422261 13743 solver.cpp:239] Iteration 59000 (44.9119 iter/s, 2.22658s/100 iters), loss = 0.814903
I0409 03:49:33.422336 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.814903 (* 1 = 0.814903 loss)
I0409 03:49:33.422348 13743 sgd_solver.cpp:112] Iteration 59000, lr = 0.0001
I0409 03:49:35.340641 13743 solver.cpp:239] Iteration 59100 (52.1293 iter/s, 1.91831s/100 iters), loss = 1.13327
I0409 03:49:35.340698 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.13327 (* 1 = 1.13327 loss)
I0409 03:49:35.340706 13743 sgd_solver.cpp:112] Iteration 59100, lr = 0.0001
I0409 03:49:37.256748 13743 solver.cpp:239] Iteration 59200 (52.1908 iter/s, 1.91605s/100 iters), loss = 0.93925
I0409 03:49:37.256846 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.93925 (* 1 = 0.93925 loss)
I0409 03:49:37.256860 13743 sgd_solver.cpp:112] Iteration 59200, lr = 0.0001
I0409 03:49:37.412470 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:39.171716 13743 solver.cpp:239] Iteration 59300 (52.2231 iter/s, 1.91486s/100 iters), loss = 0.842425
I0409 03:49:39.171813 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.842425 (* 1 = 0.842425 loss)
I0409 03:49:39.171823 13743 sgd_solver.cpp:112] Iteration 59300, lr = 0.0001
I0409 03:49:41.082726 13743 solver.cpp:239] Iteration 59400 (52.3309 iter/s, 1.91092s/100 iters), loss = 0.744871
I0409 03:49:41.082793 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.744871 (* 1 = 0.744871 loss)
I0409 03:49:41.082803 13743 sgd_solver.cpp:112] Iteration 59400, lr = 0.0001
I0409 03:49:42.999606 13743 solver.cpp:239] Iteration 59500 (52.1699 iter/s, 1.91681s/100 iters), loss = 0.850158
I0409 03:49:42.999671 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.850158 (* 1 = 0.850158 loss)
I0409 03:49:42.999680 13743 sgd_solver.cpp:112] Iteration 59500, lr = 0.0001
I0409 03:49:44.918699 13743 solver.cpp:239] Iteration 59600 (52.1102 iter/s, 1.91901s/100 iters), loss = 0.785573
I0409 03:49:44.918773 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.785573 (* 1 = 0.785573 loss)
I0409 03:49:44.918782 13743 sgd_solver.cpp:112] Iteration 59600, lr = 0.0001
I0409 03:49:45.996670 13756 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:46.834648 13743 solver.cpp:239] Iteration 59700 (52.1963 iter/s, 1.91585s/100 iters), loss = 0.815371
I0409 03:49:46.834733 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.815371 (* 1 = 0.815371 loss)
I0409 03:49:46.834744 13743 sgd_solver.cpp:112] Iteration 59700, lr = 0.0001
I0409 03:49:48.753783 13743 solver.cpp:239] Iteration 59800 (52.1093 iter/s, 1.91904s/100 iters), loss = 0.955625
I0409 03:49:48.753861 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 0.955625 (* 1 = 0.955625 loss)
I0409 03:49:48.753873 13743 sgd_solver.cpp:112] Iteration 59800, lr = 0.0001
I0409 03:49:50.664139 13743 solver.cpp:239] Iteration 59900 (52.3484 iter/s, 1.91028s/100 iters), loss = 1.10353
I0409 03:49:50.664207 13743 solver.cpp:258]     Train net output #0: Softmax_loss = 1.10353 (* 1 = 1.10353 loss)
I0409 03:49:50.664216 13743 sgd_solver.cpp:112] Iteration 59900, lr = 0.0001
I0409 03:49:52.557472 13743 solver.cpp:464] Snapshotting to binary proto file ./FaceEmotionNet_model_iter_60000.caffemodel
I0409 03:49:52.636936 13743 sgd_solver.cpp:284] Snapshotting solver state to binary proto file ./FaceEmotionNet_model_iter_60000.solverstate
I0409 03:49:52.688279 13743 solver.cpp:327] Iteration 60000, loss = 0.936102
I0409 03:49:52.688330 13743 solver.cpp:347] Iteration 60000, Testing net (#0)
I0409 03:49:52.694361 13757 data_layer.cpp:73] Restarting data prefetching from start.
I0409 03:49:52.996387 13743 solver.cpp:414]     Test net output #0: Softmax_loss = 1.10138 (* 1 = 1.10138 loss)
I0409 03:49:52.996445 13743 solver.cpp:414]     Test net output #1: accuracy = 0.600725
I0409 03:49:52.996454 13743 solver.cpp:332] Optimization Done.
